{
    "took" : 20,
    "timed_out" : false,
    "_shards" : {
      "total" : 2,
      "successful" : 2,
      "skipped" : 0,
      "failed" : 0
    },
    "hits" : {
      "total" : {
        "value" : 14,
        "relation" : "eq"
      },
      "max_score" : 1.0,
      "hits" : [
        {
          "_index" : "articleindex",
          "_id" : "16",
          "_score" : 1.0,
          "_source" : {
            "title" : "A prototype implementation of an orthographic software modeling environment",
            "samary" : "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe speciﬁc sets ofviews, a concrete OSM environment has to be speciﬁc aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototypeOSM environment, nAOMi, that supports the views deﬁnedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
            "authors" : "Colin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\n",
            "institutions" : "",
            "integralText" : "1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses — (a) that it is feasible to inte-\ngrate the many diﬀerent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for proﬁt or commercial advantage and that copies\nbear this notice and the full citation on the ﬁrst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speciﬁc\npermission and/or a fee.\nVAO ’13, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an eﬃcient and scalable way of support-\ning these views by generating them dynamically, on-the-ﬂy,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\n<image: DeviceRGB, width: 789, height: 272, bpc: 8>Figure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to deﬁne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of “dimensions”, each containing\nwell deﬁned choices (or so called “dimension elements”) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply deﬁning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\n<image: CalRGB, width: 1003, height: 1004, bpc: 8><image: DeviceRGB, width: 707, height: 297, bpc: 8><image: DeviceRGB, width: 185, height: 81, bpc: 8>SUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\noﬀered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent “dimensions” which\nreﬂect diﬀerent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the “most orthogonal” sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions deﬁned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages — one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\n<image: DeviceRGB, width: 166, height: 57, bpc: 8>KobrA2\n<image: DeviceRGB, width: 52, height: 27, bpc: 8>Transformation\n<image: DeviceRGB, width: 27, height: 27, bpc: 8>SUM\n<image: DeviceRGB, width: 27, height: 27, bpc: 8>Views\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel — the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple “data type” objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeciﬁc part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is suﬃcient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\n<image: DeviceRGB, width: 449, height: 188, bpc: 8><image: DeviceRGB, width: 205, height: 33, bpc: 8>KobrA2::SUM::Constraint::Behavioral\n<image: DeviceRGB, width: 176, height: 33, bpc: 8>KobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\n<image: DeviceRGB, width: 134, height: 33, bpc: 8>KobrA2::SUM::Constraint::Common\n<image: DeviceRGB, width: 193, height: 253, bpc: 8><image: DeviceRGB, width: 181, height: 33, bpc: 8>KobrA2::SUM::Behavior::ProtocolStateMachines\n<image: DeviceRGB, width: 157, height: 37, bpc: 8>KobrA2::SUM::Behavior::Common\n<image: DeviceRGB, width: 130, height: 35, bpc: 8>KobrA2::SUM::Behavior::Activities\n<image: DeviceRGB, width: 123, height: 36, bpc: 8>KobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\n<image: DeviceRGB, width: 245, height: 253, bpc: 8><image: DeviceRGB, width: 193, height: 37, bpc: 8>KobrA2::SUM::Structure::Classes\n<image: DeviceRGB, width: 156, height: 35, bpc: 8>KobrA2::SUM::Structure::Types\n<image: DeviceRGB, width: 153, height: 35, bpc: 8>KobrA2::SUM::Structure::Instances\n<image: DeviceRGB, width: 131, height: 35, bpc: 8>KobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\n<image: DeviceRGB, width: 156, height: 33, bpc: 8>KobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speciﬁed in the form of\nUML\nState Diagrams (deﬁning acceptable operation invocation\nsequences), and in the form of Activities (deﬁning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\n<image: DeviceRGB, width: 450, height: 360, bpc: 8><image: DeviceRGB, width: 67, height: 252, bpc: 8>Class\nKobrA2::SUM::Structure::Classes\n<image: DeviceRGB, width: 67, height: 17, bpc: 8>GeneralizationSet\n<image: DeviceRGB, width: 67, height: 16, bpc: 8>AssociationClass\n<image: DeviceRGB, width: 67, height: 16, bpc: 8>ComponentClass\n<image: DeviceRGB, width: 59, height: 42, bpc: 8>Property\n<image: DeviceRGB, width: 46, height: 55, bpc: 8>Usage\n<image: DeviceRGB, width: 55, height: 16, bpc: 8>Association\n<image: DeviceRGB, width: 40, height: 50, bpc: 8>Operation\n<image: DeviceRGB, width: 51, height: 23, bpc: 8>Packageable\nElement\n<image: DeviceRGB, width: 43, height: 16, bpc: 8>Parameter\n<image: DeviceRGB, width: 37, height: 16, bpc: 8>Acquires\n<image: DeviceRGB, width: 34, height: 16, bpc: 8>Creates\n<image: DeviceRGB, width: 26, height: 16, bpc: 8>Nests\n<image: DeviceRGB, width: 197, height: 16, bpc: 8>UML::Component::PackagingComponents::Component\n<image: DeviceRGB, width: 180, height: 17, bpc: 8>UML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views deﬁned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big diﬀerence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package reﬂects the types\nand organization of the KobrA views according to the view\n“dimensions” supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speciﬁcation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been deﬁned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassiﬁer)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\n<image: DeviceRGB, width: 423, height: 478, bpc: 8><image: DeviceRGB, width: 254, height: 165, bpc: 8><image: DeviceRGB, width: 173, height: 79, bpc: 8><image: DeviceRGB, width: 80, height: 56, bpc: 8>Class\n<image: DeviceRGB, width: 35, height: 32, bpc: 8>Service\n<image: DeviceRGB, width: 32, height: 32, bpc: 8>Type\n<image: DeviceRGB, width: 77, height: 56, bpc: 8>Instance\n<image: DeviceRGB, width: 35, height: 32, bpc: 8>Service\n<image: DeviceRGB, width: 32, height: 32, bpc: 8>Type\nStructural\nSpecification\n<image: DeviceRGB, width: 80, height: 58, bpc: 8>Operational\n<image: DeviceRGB, width: 35, height: 32, bpc: 8>Service\n<image: DeviceRGB, width: 32, height: 32, bpc: 8>Type\n<image: DeviceRGB, width: 72, height: 79, bpc: 8><image: DeviceRGB, width: 57, height: 32, bpc: 8>Protocol\nBehavioral\n<image: DeviceRGB, width: 252, height: 64, bpc: 8>KobrA2::Views::Derived\n<image: DeviceRGB, width: 118, height: 32, bpc: 8>ComponentClassDependencies\n<image: DeviceRGB, width: 94, height: 32, bpc: 8>OperationDependencies\n<image: DeviceRGB, width: 240, height: 169, bpc: 8><image: DeviceRGB, width: 165, height: 79, bpc: 8><image: DeviceRGB, width: 78, height: 58, bpc: 8>Instance\n<image: DeviceRGB, width: 35, height: 33, bpc: 8>Service\n<image: DeviceRGB, width: 32, height: 33, bpc: 8>Type\n<image: DeviceRGB, width: 73, height: 58, bpc: 8>Class\n<image: DeviceRGB, width: 35, height: 33, bpc: 8>Service\n<image: DeviceRGB, width: 32, height: 33, bpc: 8>Type\nStructural\nRealization\n<image: DeviceRGB, width: 79, height: 56, bpc: 8>Operational\n<image: DeviceRGB, width: 35, height: 32, bpc: 8>Service\n<image: DeviceRGB, width: 32, height: 32, bpc: 8>Type\n<image: DeviceRGB, width: 56, height: 79, bpc: 8>Behavioral\n<image: DeviceRGB, width: 43, height: 33, bpc: 8>Algorithm\nViews\n<image: DeviceRGB, width: 65, height: 32, bpc: 8>ConcreteSyntax\n<image: DeviceRGB, width: 35, height: 32, bpc: 8>Subject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is reﬂected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package’s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\n<image: DeviceRGB, width: 448, height: 239, bpc: 8>KobrA2::Transformation::Common::AllViews\n<image: DeviceRGB, width: 126, height: 70, bpc: 8>Abstraction\n<image: DeviceRGB, width: 111, height: 18, bpc: 8>TransformationExpression\n<image: DeviceRGB, width: 58, height: 18, bpc: 8>ViewElement\n<image: DeviceRGB, width: 55, height: 18, bpc: 8>SumElement\n<image: DeviceRGB, width: 27, height: 18, bpc: 8>View\n<image: DeviceRGB, width: 181, height: 18, bpc: 8>KobrA2::SUM::Structure::Elements::Element\n<image: DeviceRGB, width: 165, height: 18, bpc: 8>KobrA2::Views::ConcreteSyntax::Element\n<image: DeviceRGB, width: 165, height: 26, bpc: 8>KobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\n<image: DeviceRGB, width: 123, height: 18, bpc: 8>KobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speciﬁed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor’s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (’acquires ’)\ninv: ve. hasStereotype (’acquires ’)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (’\nnests ’)\ninv: ve. hasStereotype (’nests ’)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(’creates ’)\ninv: ve. hasStereotype (’creates ’)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The ﬁrst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe ﬁrst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\nﬁcation for the implementation of a view. Individual CASE\ntools can use diﬀerent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\n<image: DeviceRGB, width: 450, height: 161, bpc: 8>KobrA2::Transformation::Specification::Structural::Class::Service\n<image: DeviceRGB, width: 124, height: 19, bpc: 8>ComponentClassAbstraction\n<image: DeviceRGB, width: 272, height: 19, bpc: 8>KobrA2::Transformation::Common::Feature::OperationAbstraction\n<image: DeviceRGB, width: 238, height: 19, bpc: 8>KobrA2::Transformation::Common::AllViews::Abstraction\n<image: DeviceRGB, width: 213, height: 19, bpc: 8>KobrA2::SUM::Structure::Classes::ComponentClass\n<image: DeviceRGB, width: 182, height: 19, bpc: 8>KobrA2::SUM::Structure::Classes::Operation\n<image: DeviceRGB, width: 165, height: 18, bpc: 8>KobrA2::SUM::Structure::Classes::Class\n<image: DeviceRGB, width: 93, height: 19, bpc: 8>OperationAbstraction\n<image: DeviceRGB, width: 76, height: 18, bpc: 8>ClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speciﬁcation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (’ComponentClass ’)\ninv: se.isSubject\nimplies (ve. hasStereotype (’subject\n’) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.‘inv ’ = se.‘inv ’\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\niﬁed in the ﬁrst rule which deﬁnes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function deﬁned in the SUM\nwhich computes the black box types by selecting the types\nof the subject’s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndiﬀerences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(‘Enumeration ’) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (’subject ’)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: ‘ve.inv ’ = ‘se.inv ’\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (’subject ’)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today’s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of diﬀerent tools there is\ninvariably a large number of diﬀerent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML ﬁles, conﬁguration ﬁles ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeciﬁcally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a diﬀer-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\n<image: DeviceRGB, width: 726, height: 410, bpc: 8>Figure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is ﬁxed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we deﬁned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speciﬁc model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeciﬁc points in time. The Component dimension, which\nhas dynamic dimension elements deﬁned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two ﬁxed ele-\nments, supports the distinction between Speciﬁcation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the ﬁxed elements Structural,\nOperational and Behavioral covers the diﬀerent information\ntypes. The Granularity dimension provides a ﬁner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very diﬃcult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween diﬀerent choices in diﬀerent dimensions, so that the\ndecisions made in one dimensions may aﬀect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\nﬁned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speciﬁed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\n<image: DeviceRGB, width: 3000, height: 3527, bpc: 8>Figure 10: Speciﬁcation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the “Abstraction Level” (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may inﬂuence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-ﬂy from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is ﬁnished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\n<image: DeviceRGB, width: 2196, height: 901, bpc: 8>Figure 11: addProduct() Operation Speciﬁcation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\n<image: DeviceRGB, width: 3000, height: 3353, bpc: 8>Figure 12: Speciﬁcation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signiﬁcant diﬀerences. The focus of the op-\nerational view is on a precise formal deﬁnition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be deﬁned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identiﬁed three funda-\nmental hypothesis upon which the notion of OSM is based\n— (a) that it is feasible to integrate the many diﬀerent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an eﬃ-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-ﬂy, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the ﬁrst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nciﬁc aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a ﬁsheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the ﬁsh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be deﬁned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which oﬀers two orthogonal ”dimensions” for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle“dimension”, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speciﬁc in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this ﬁrst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already deﬁned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels fulﬁlled the two core requirements of SUM-based en-\nvironments — (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take oﬀ, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uniﬁed metamodel will be\nrequired.\n",
            "pdfUrl" : "",
            "reference" : "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W¨ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206–219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speciﬁcations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uniﬁed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn eﬀective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). Oﬃcial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
            "keyWords" : "Orthographic Software Modeling, View-based Modeling\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "18",
          "_score" : 1.0,
          "_source" : {
            "title" : "Framing the News:  From Human Perception to Large Language Model Inferences ",
            "samary" : "Identifying the frames of news is important to understand the arti-cles’ vision, intention, message to be conveyed, and which aspectsof the news are emphasized. Framing is a widely studied conceptin journalism, and has emerged as a new topic in computing, withthe potential to automate processes and facilitate the work of jour-nalism professionals. In this paper, we study this issue with articlesrelated to the Covid-19 anti-vaccine movement. First, to under-stand the perspectives used to treat this theme, we developed aprotocol for human labeling of frames for 1786 headlines of No-Vax movement articles of European newspapers from 5 countries.Headlines are key units in the written press, and worth of analysisas many people only read headlines (or use them to guide theirdecision for further reading.) Second, considering advances in Nat-ural Language Processing (NLP) with large language models, weinvestigated two approaches for frame inference of news headlines:first with a GPT-3.5 fine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work contributes to the study andanalysis of the performance that these models have to facilitatejournalistic tasks like classification of frames, while understandingwhether the models are able to replicate human perception in theidentification of these frames.",
            "authors" : "David Alonso del Barrio\nddbarrio@idiap.ch\nIdiap Research Institute\nSwitzerland\nDaniel Gatica-Perez\ngatica@idiap.ch\nIdiap Research Institute and EPFL\nSwitzerland\n",
            "institutions" : "",
            "integralText" : "1\nINTRODUCTION\nIn recent years, there has been a proliferation in the use of concepts\nsuch as data journalism, computational journalism, and computer-\nassisted reporting [15] [29], which all share the vision of bridging\njournalism and technology. The progress made in NLP has been\ngradually integrated into the journalistic field [5][8][54]. More\nspecifically, machine learning models based on transformers have\nbeen integrated in the media sector in different tasks [41] such as\nthe creation of headlines with generative languages models [17],\nsummarization of news articles [28][27], false news detection [49],\nand topic modeling and sentiment analysis [25]. The development of\nlarge language models such as GPT-3 [9], BLOOM [51] or ChatGPT\nshow a clear trend towards human-machine interaction becoming\neasier and more intuitive, opening up a wide range of research\npossibilities. At the same time, the use of these models is also\nassociated with a lack of transparency regarding how these models\nwork, but efforts are being made to bring some transparency to\nthese models, and to analyze use cases where they can be useful and\nwhere they cannot [35]. Based on the premises that these models\nopen up a wide range of research directions [7], and that at the same\ntime (and needless to say) they are not the solution to all problems,\nwe are interested in identifying use cases and tasks where they\ncan be potentially useful, while acknowledging and systematically\ndocumenting their limitations [56]. More specifically, the aim of\nthis work is to analyze the performance of GPT-3.5 for a specific\nuse case, namely the analysis of frames in news, from an empirical\npoint of view, with the objective of shedding light on a potential\nuse of generative models in journalistic tasks.\nFrame analysis is a concept from journalism, which consists of\nstudying the way in which news stories are presented on an issue,\nand what aspects are emphasized: Is a merely informative vision\ngiven in an article? Or is it intended to leave a moral lesson? Is\na news article being presented from an economic point of view?\nOr from a more human, emotional angle? The examples above\ncorrespond to different frames with which an article can be written.\nThe concept of news framing has been studied in computing as\na step beyond topic modeling and sentiment analysis, and for this\npurpose, in recent years, pre-trained language models have been\nused for fine-tuning the classification process of these frames [60]\n[10], but the emergence of generative models opens the possibility\nof doing prompt-engineering of these classification tasks, instead\nof the fine-tuning approach investigated so far.\nOur work aims to address this research gap by posing the fol-\nlowing research questions:\nRQ1: What are the main frames in the news headlines about\nthe anti-vaccine movement, as reported in newspapers across 5\nEuropean countries?\n627\n<image: CalRGB, width: 1003, height: 1004, bpc: 8>ICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nDavid Alonso del Barrio and Daniel Gatica-Perez\nRQ2: Can prompt engineering be used for classification of head-\nlines according to frames?\nBy addressing the above research questions, our work makes the\nfollowing contributions:\nContribution 1. We implemented a process to do human an-\nnotation of the main frame of 1786 headlines of articles about the\nCovid-19 no-vax movement, as reported in 19 newspapers from 5\nEuropean countries (France, Italy, Spain, Switzerland and United\nKingdom.) At the headline level, we found that the predominant\nframe was human interest, where this frame corresponds to a per-\nsonification of an event, either through a statement by a person,\nor the explanation of a specific event that happened to a person.\nFurthermore, we found a large number of headlines annotated as\ncontaining no frame, as they simply present information without\nentering into evaluations. We also found that for all the countries\ninvolved, the distribution of frame types was very similar, i.e., hu-\nman interest and no frame are the two predominant frames. Finally,\nthe generated annotations allowed to subsequently study the per-\nformance of a large language model.\nContribution 2. We studied the performance of GPT-3.5 on\nthe task of frame classification of headlines. In addition to using\nthe fine-tuning approach from previous literature, we propose an\nalternative approach for frame classification that requires no labeled\ndata for training, namely prompt-engineering using GPT-3.5. The\nresults show that fine-tuning with GPT-3.5 produces 72% accuracy\n(slightly higher than other smaller models), and that the prompt-\nengineering approach results in lower performance (49% accuracy.)\nOur analysis also shows that the subjectivity of the human labeling\ntask has an effect on the obtained accufracy.\nThe paper is organized as follows. In Section 2, we discuss related\nwork. In Section 3, we describe the news dataset. In Section 4, we\ndescribe the methodology for both human labeling and machine\nclassification of news frames. We present and discuss results for\nRQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide\nconclusions in Section 7.\n2\nRELATED WORK\nFraming has been a concept widely studied in journalism, with a\ndefinition that is rooted in the study of this domain [23]: “To frame\nis to select some aspects of a perceived reality and make them more\nsalient in a communicating text, in such a way as to promote a par-\nticular problem definition, causal interpretation, moral evaluation,\nand/or treatment recommendation for the item described.”\nFor frame recognition, there are two main approaches: the induc-\ntive approach [16], where one can extract the frames after reading\nthe article, and the deductive approach [38], where a predefined\nlist of frames exists and the goal is to interpret if any of them ap-\npears in the article. In the deductive case, there are generic frames\nand subject-specific frames, and the way to detect them typically\ninvolves reading and identifying one frame at a time, or through\nanswers to yes/no questions that represent the frames. Semetko et\nal. [52] used 5 types of generic frames (attribution of responsibility,\nhuman interest, conflict, morality, and economic consequences)\nbased on previous literature, and they defined a list of 20 yes/no\nquestions to detect frames in articles. For instance, the questions\nabout morality are the following: \"Does the story contain any moral\nmessage? Does the story make reference to morality, God, and other\nreligious tenets? Does the story offer specific social prescriptions\nabout how to behave?\", and so on for each of the frame types. This\ncategorization of frames has been used in various topics such as\nclimate change [18] [19], vaccine hesitance [13], or immigration\n[34].\nWe now compare the two approaches on a common topic, such\nas Covid-19. Ebrahim et al. [21] followed an inductive approach\nin which the frames were not predefined but emerged from the\ntext (e.g., deadly spread, stay home, what if, the cost of Covid-19)\nusing headlines as the unit of analysis. In contrast, the deductive\napproach has studied very different labels. El-Behary et al. [22]\nfollowed the method of yes/no questions, but in addition to the\n5 generic frames presented before, they also used blame frame\nand fear frame. Adiprasetio et al. [1] and Rodelo [50] used the 5\ngeneric frames with yes/no questions, while Catalán-Matamoros et\nal. [14] used the 5 frames and read the headline and subheadline\nto decide the main frame. Table 1 summarizes some of the the\nexisting approaches. This previous work showed how frame labels\ncan be different, and also that frame analysis has been done at both\nheadline and article levels. These two approaches (inductive and\ndeductive) that originated in journalism have since been replicated\nin the computing literature.\nWe decided to follow the deductive approach because a prede-\nfined list of frames allows to compare among topics, countries,\nprevious literature, and also because they represent a fixed list of\nlabels for machine classification models. Furthermore, the induc-\ntive approach tends to be more specific to a topic, and from the\ncomputing viewpoint, past work has tried to justify topic modeling\nas a technique to extract frames from articles.\nYlä-Antitila et al. [60] proposed topic modeling as a frame ex-\ntraction technique. They argued that topics can be interpreted as\nframes if three requirements are met: frames are operationalized as\nconnections between concepts; subject-specific data is selected; and\ntopics are adequately validated as frames, for which they suggested\na practical procedure. This approach was based on the choice of a\nspecific topic (e.g., climate change) and the use of Latent Dirichlet\nAllocation (LDA) as a technique to extract a number of subtopics.\nIn a second phase, a qualitative study of the top 10 words of each\nsubtopic was performed, and the different subtopics were elimi-\nnated or grouped, reducing the number and establishing a tentative\ndescription. In a third phase, the top 10 articles belonging to that\nframe/topic were taken, and if the description of the topic fitted\nat least 8 of the 10 articles, that topic/frame remained. The frames\nfound in this article were: green growth, emission cuts, negotiations\nand treaties, environmental risk, cost of carbon emissions, Chinese\nemissions, economics of energy production, climate change, en-\nvironmental activism, North-South burden sharing, state leaders\nnegotiating, and citizen participation.\nFrom Entman’s definition of frame [23], it seems that the deduc-\ntive approach is more refined than the inductive approach (which\nseems to resemble the detection of sub-themes.) For example, with\nregard to climate change, there are stories on how people have been\naffected by climate change from an emotional point of view, thus\npersonalizing the problem. In this case, we could categorize the\ncorresponding frame as human interest, as the writer of the article\nis selecting \"some aspects of a perceived reality and make them\n628\nFraming the News:\nFrom Human Perception to Large Language Model Inferences\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nmore salient\". The language subtleties with which news articles are\npresented cannot be captured with basic topic modeling.\nIsoaho et al.[30] held the position that while the benefits of\nscale and scope in topic modeling were clear, there were also a\nnumber of problems, namely that topic outputs do not correspond\nto the methodological definition of frames, and thus topic modeling\nremained an incomplete method for frame analysis. Topic modeling,\nin the practice of journalistic research, is a useful technique to deal\nwith the large datasets that are available, yet is often not enough to\ndo more thorough analyses [31]. In our work, we clearly notice that\nframe analysis is not topic modeling. For example, two documents\ncould be about the same topic, say Covid-19 vaccination, but one\narticle could emphasize the number of deaths after vaccination,\nwhile the other emphasized the role of the vaccine as a solution to\nthe epidemic.\nWe also consider that the larger the number of possible frame\ntypes, the more likely it is to end up doing topic modeling instead of\nframe analysis. Using a deductive approach, Dallas et al. [12] created\na dataset with articles about polemic topics such as immigration,\nsame sex marriage, or smoking, and they defined 15 types of frames:\n\"economic, capacity and resources, morality, fairness and equality,\nlegality, constitutionality and jurisprudence, policy prescription and\nevaluation, crime and punishment, security and defense, health and\nsafety, quality of life, cultural identity, political, external regulation\nand reputation, other\". In this case, they authors did not use a list\nof questions. Instead, for each article, annotators were asked to\nidentify any of the 15 framing dimensions present in the article\nand to label text blurbs that cued them (based on the definitions of\neach of the frame dimensions) and decide the main frame of each\narticle. In our case, we followed the idea of detecting the main frame\nby reading the text instead of answering questions, but instead of\nusing the 15 frames proposed in [12] , we used the 5 generic frames\nproposed in [52].\nA final decision in our work was the type of text to analyze,\nwhether headlines or whole article. For this decision, the chosen\nclassification method was also going to be important. For example,\nKhanehzar et al. [33] used traditional approaches such as SVMs as\nbaseline, and demonstrated the improvement in frame classifica-\ntion with the use of pre-trained languages models such as BERT,\nRoBERTa and XLNet, following a fine-tuning approach, setting\nas input text a maximum of 256 tokens (although the maximum\nnumber of input tokens in these models is 512 tokens.) Liu et al.\n[37] classified news headlines about the gun problem in the United\nStates, arguing for the choice of headlines as a unit of analysis\nbased on previous journalism literature [6], [44], that advocated\nfor the importance and influence of headlines on readers and the\nsubsequent perception of articles. From a computational viewpoint,\nusing headlines is also an advantage, since you avoid the 512 token\nlimitation in BERT-based models. Therefore, we decided to work\nwith headlines about a controversial issue, namely the Covid-19\nno-vax movement.\nContinuing with the question of the methods used for classi-\nfication, much work has been developed in prompt engineering,\nespecially since the release of GPT-3. Liu et al.[36] presented a good\noverview of the work done on this new NLP paradigm, not only\nexplaining the concept of prompt engineering, but also the differ-\nent strategies that can be followed both in the design of prompts,\nTable 1: Summary of deductive approaches for frame analysis\nRef\nFrames\nGoal\nTechnique\nNumber\nof\nsamples\n[12] 15 generic frames: \"Economic\", \"Capac-\nity and resources\", \"Morality\", \"Fair-\nness and equality\", \"Legality, constitu-\ntionality and jurisprudence\", \"Policy\nprescription and evaluation\", \"Crime\nand punishment\", \"Security and de-\nfense\", \"Health and safety\", \"Quality of\nlife\", \"Cultural identity\", \"Public opin-\nion\", \"Political\", \"External regulation\nand reputation\", \"Other\".\nTo label frames of full\narticles\nReading\nthe\nfull\narticle,\nthe annotator\ndefines\nthe\nmain frame\n20000 articles\n[33] 15 generic frames\nClassification\nBERT\nbased\nmodels\n12000 articles\n[52] 5 generic frames: \"human interest\",\n\"conflict\", \"morality\", \"attribution of\nresponsibility\", and \"economic conse-\nquences\".\nTo label frames of full\narticles\nYes/No\nques-\ntions.\n2600\narticles\nand\n1522\ntv\nnews stories\n[37] 9 specific frames:“Politics”, “Public\nopinion”,\n“Society/Culture”,\nand\n“Economic\nconsequences”\n,\n“2nd\nAmendment” (Gun Rights), “Gun\ncontrol/regulation”, “Mental health”,\n“School/Public space safety”, and\n“Race/Ethnicity”.\nTo label frames of full\narticles/ Classification\nReading\nthe\nfull\narticle,\nthe annotator\ndefines\nthe\nmain\nframe.\nBERT\nbased\nmodels\n2990 headlines\n[22] 5 generic frames + blame frame and\nfear frame\nTo label frames of full\narticles\nYes/No\nques-\ntions.\n1170 articles\n[1]\n5 generic frames\nTo label frames of full\narticles\nReading\nthe\nfull\narticle,\nthe annotator\ndefines\nthe\nmain frame.\n6713 articles\n[50] 5 generic frames + pandemic frames\nTo label frames of full\narticles\nYes/No\nques-\ntions.\n2742 articles\n[14] 5 generic frames, journalistic role and\npandemic frames\nTo label frames of full\narticles\nReading\nthe\nheadline\nand\nsubheadline,\nthe annotator\ndefines\nthe\nmain frame.\n131 headlines +\nsubheadlines\nthe potential applications, and the challenges to face when using\nthis approach. Prompt engineering applications include knowledge\nprobing [46], information extraction [53], NLP reasoning [57], ques-\ntion answering [32], text generation [20], multi-modal learning [58],\nand text classification [24], the latter being the prompt-engineering\nuse case in our work. Puri et al.[45] presented a very interesting\nidea that we apply to our classification task. This consists of pro-\nviding the language model with natural language descriptions of\nclassification tasks as input, and training it to generate the correct\nanswer in natural language via a language modeling objective. It is\na zero-shot learning approach, in which no examples are used to\nexplain the task to the model. Radford et al. [48] demonstrated that\nlanguage models can learn tasks without any explicit supervision.\nWe have followed this approach to find an alternative way to do\nframe analysis.\nAs mentioned before, the emergence of giant models like GPT-3,\nBLOOM, and ChatGPT are a very active research topic. To the best\nof our knowledge, on one hand our work extends the computational\nanalysis of news related to the covid-19 no-vax movement, which\nillustrates the influence of the press on the ways societies think\nabout relevant issues [40], [59], and on the other hand it adds to\nthe literature of human-machine interaction, regarding the design\nof GPT-3 prompts for classification tasks [39], [2].\n3\nDATA: EUROPEAN COVID-19 NEWS\nDATASET\nWe used part of the European Covid-19 News dataset collected in\nour recent work [3]. This dataset contains 51320 articles on Covid-\n19 vaccination from 19 newspapers from 5 different countries: Italy,\n629\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nDavid Alonso del Barrio and Daniel Gatica-Perez\nFrance, Spain, Switzerland and UK. The articles cover a time period\nof 22 months, from January 2020 to October 2021. All content was\ntranslated into English to be able to work in a common language.\nThe dataset was used for various analyses, such as name entity\nrecognition, sentiment analysis, and subtopic modeling, to under-\nstand how Covid-19 vaccination was reported in Europe through\nthe print media (in digital format.) The subtopic modeling analysis\nrevealed a subsample of articles on the no-vax movement, which is\nthe one we have used in this paper. We took the headlines of the\narticles associated with the no-vax movement, selecting all articles\ncontaining any of the keywords in Table 2 in the headline or in the\nmain text. This corresponds to a total of 1786 headlines.\nTable 2: Keywords used to identify no-vax articles\nKeywords\nNO VAX TOPIC\n\"anti-vaxxers\", \"anti-vaccine\", \"anti-vaxx\", \"anti-corona\", \"no-vax\", \"no vax\",\"anti-vaccin\"\nIn Table 3, we show the number of headlines per country and\nnewspaper. France is the country with the most no-vax articles in\nthe corpus, with 523 articles, followed by Italy with 508. However,\nnote that there are 6 newspapers from France, while only 2 from\nItaly. Corriere della Sera is the newspaper that dealt most frequently\nwith the subject (429 articles), while The Telegraph is the second\none (206 articles). The total number of articles normalized by the\nnumber of newspapers per country is also shown in the last column\nof the Table. Using these normalized values, the ranking is Italy,\nUK, France, Switzerland, and Spain.\nTable 3: Number of headlines by newspaper and country\nCOUNTRY\nNEWSPAPER\nHEADLINES\nTOTAL (NORM. TOTAL)\nFRANCE\nLa Croix\n94\n523 (87.1)\nLe Monde\n125\nLes Echos\n49\nLiberation\n97\nLyon Capitale\n8\nOuest France\n150\nITALY\nCorriere della Sera\n429\n508 (254.0)\nIl Sole 24 Ore\n79\nSPAIN\n20 minutos\n27\n303 (50.5)\nABC\n50\nEl Diario\n32\nEl Mundo\n77\nEl Español\n22\nLa Vanguardia\n95\nSWITZERLAND\n24 heures\n97\n230 (76.6)\nLa Liberté\n22\nLe Temps\n111\nUNITED KINGDOM\nThe Irish News\n16\n222 (111.0)\nThe Telegraph\n206\n1786\n4\nMETHODOLOGY\n4.1\nHuman labeling of news frames\nTo carry out the labeling of the frames in our corpus of headlines, we\nfirst designed a codebook, which contained the definitions of each\nof the frame types and a couple of examples of each type, as well\nas a definition of the corpus subject matter and definitions of the\nconcept of frame analysis, so that the annotators could understand\nthe task to be performed. The codebook follows the proposed by\n[52] with 5 generic frames (attribution of responsibility, human\ninterest, conflict, morality, and economic consequences) plus one\nadditional ’no-frame’ category. Two researchers were engaged to\nannotate a sample of the collected newspaper articles following a\nthree-phase training procedure.\nIn the first phase, annotators had to read the codebook and get\nfamiliar with the task. In the second phase, they were asked to\nidentify the main frame in the same subset of 50 headlines. At the\nend of the second phase, the intercoder reliability (ICR) was 0.58\nbetween the 2 annotators. We analyzed those cases where there\nwere discrepancies, and observed that in some cases, there was not a\nunique main frame, because both annotators had valid arguments to\nselect one of the frames. In other cases, the discrepancies were due\nto slight misunderstanding of the definitions. In the third phase, the\nannotators coded again 50 headlines, and the ICR increased to was\n0.66. We realized that the possibility of having two frames remained.\nThey discussed the cases in which they had disagreed, and if the\nother person’s arguments were considered valid, it could be said that\nthere were two frames. After this three-phase training procedure,\nannotators were ready to annotate the dataset independently. We\ndivided the dataset into two equal parts, and each person annotated\n893 headlines.\n4.2\nFine-tuning GPT-3.5 and BERT-based\nmodels\nWith the annotated dataset, we investigated two NLP approaches:\nthe first one involves fine-tuning a pre-trained model; the second\none is prompt engineering. Pre-trained language models have been\n<image: DeviceRGB, width: 1249, height: 473, bpc: 8>Figure 1: Pre-train, fine-tune, prompt\ntrained with large text strings based on two unsupervised tasks,\nnext sentence prediction and masked language model. Figure 1\nsummarizes these techniques.\nIn the first approach, a model with a fixed architecture is pre-\ntrained as a language model (LM), predicting the likelihood of the\nobserved textual data. This can be done due to the availability of\nlarge, raw text data needed to train LMs. This learning process can\nproduce general purpose features of the modeled language. The\nlearning process produces robust, general-purpose features of the\nlanguage being modeled. The above pre-trained LM is then adapted\nto different downstream tasks, by introducing additional parameters\nand adjusting them using task-specific objective functions. In this\napproach, the focus was primarily on goal engineering, designing\nthe training targets used in both the pre-training and the fine-tuning\nstages [36].\n630\nFraming the News:\nFrom Human Perception to Large Language Model Inferences\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nWe present an example to illustrate the idea. Imagine that the\ntask is sentiment analysis, and we have a dataset with sentences\nand their associated sentiment, and a pre-trained model, which is a\nsaved neural network trained with a much larger dataset. For that\npre-trained model to address the target task, we unfreeze a few of\nthe top layers of the saved model base and jointly train both the\nnewly-added classifier layers and the last layers of the base model.\nThis allows to \"fine-tune\" the higher-order feature representations\nin the base model to make them more relevant for the sentiment\nanalysis task. In this way, instead of having to obtain a very large\ndataset with target labels to train a model, we can reuse the pre-\ntrained model and use a much smaller train dataset. We use a part\nof our dataset as examples for the model to learn the task, while\nthe other part of the dataset is used to evaluate model performance.\nPrevious works related to frame classification in the computing\nliterature have used fine-tuning, BERT-based models. In our work,\nwe have done the same as a baseline, but we aimed to go one step\nfurther and also produce results using fine-tuning of GPT-3.5.\n4.3\nPrompt-engineering with GPT-3.5\nModel fine-tuning has been widely used, but with the emergence\nof generative models such as GPT-3, another way to approach\nclassification tasks has appeared. The idea is to use the pre-trained\nmodel directly and convert the task to be performed into a format\nas close as possible to the tasks for which it has been pre-trained.\nThat is, if the model has been pre-trained from next word prediction\nas in the case of GPT-3, classification can be done by defining a\nprompt, where the input to the model is an incomplete sentence,\nand the model must complete it with a word or several words, just\nas it has been trained. This avoids having to use part of the already\nlabeled dataset to teach the task to be performed to the model, and\na previous labeling is not needed [36].\nIn this approach, instead of adapting pre-trained LMs to down-\nstream tasks via objective engineering, downstream tasks are re-\nformulated to look more like those solved during the original LM\ntraining with the help of a textual prompt. For example, when recog-\nnizing the emotion of a social media post, “I missed the bus today.”,\nwe may continue with a prompt “I felt so _”, and ask the LM to\nfill the blank with an emotion-bearing word. Or if we choose the\nprompt “English: I missed the bus today. French: _”), an LM may\nbe able to fill in the blank with a French translation. In this way,\nby selecting the appropriate prompts, we can influence the model\nbehavior so that the pre-trained LM itself can be used to predict the\ndesired output, even without any additional task-specific training\n[36].\nWe use this emerging NLP approach to classify frames at headline\nlevel. We are not aware of previous uses of this strategy to classify\nframes as we propose here. The idea is the following. Prompt engi-\nneering consists of giving a prompt to the model, and understands\nthat prompt as an incomplete sentence. To do prompt engineer-\ning with our dataset, we needed to define an appropriate prompt\nthat would produce the headline frames as output. We defined sev-\neral experiments with the Playground of GPT-3, in order to find\nthe best prompt for our task. In our initial experiments, we fol-\nlowed existing approaches in prompt engineering to do sentiment\nanalysis, where the individual answer was an adjective, and this\nadjective was matched with a sentiment. In a similar fashion, we\ndecided to build a thesaurus of adjectives that define each of the\nframes. For instance, the human interest frame could be ’interest-\ning’, ’emotional’, ’personal’, ’human’. The conflict frame could be:\n’conflictive’, ’bellicose’, ’troublesome’, ’rowdy’, ’quarrelsome’, ’trou-\nblemaker’, ’agitator’, etc. After the list of adjectives was defined,\nwe needed to define the prompt in order to get, as an answer, one\nof the adjectives in our thesaurus to match them with the frame.\nWe used the GPT-3 playground using the headline as input and\nasking for the frame as output, but the strategy did not work. In\nour final experiment, instead of giving the headline as input, we\ngave the definitions of each type of frame plus the headline, and we\nasked the model to choose between the different types of frames\nas output. In this way, the output of the model was directly one of\nthe frames, and we avoided the step of matching adjectives with\nframes. An example is shown in Figure 2.\n<image: DeviceRGB, width: 710, height: 244, bpc: 8>Figure 2: GPT-3.5 for frame inference: input and output\nFor the GPT-3 configuration 1, there are 3 main concepts:\n• TEMPERATURE [0-1]. This parameter controls randomness,\nlowering it results in less random completions.\n• TOP_P [0-1]. This parameter controls diversity via nucleus\nsampling.\n• MAX_TOKENS[1-4000]. This parameter indicates the maxi-\nmum number of tokens to generate,\n• MODEL. GPT-3 offer four main models with different levels\nof power, suitable for different tasks. Davinci is the most\ncapable model, and Ada is the fastest.\nAfter testing with the GPT-3 playground and varying different\nhyper-parameters to assess performance, we set the temperature to\n0, since the higher the temperature the more random the response.\nFurthermore, the Top-p parameter was set to 1, as it would likely\nget a set of the most likely words for the model to choose from. The\nmaximum number of tokens was set to 2; in this way, the model\nis asked to choose between one of the responses. As a model, we\nused the one with the best performance at the time of experimental\ndesign, which was TEXT-DAVINCI-003, recognized as GPT 3.5.\n5\nRESULTS: HUMAN LABELING OF FRAMES\nIN NO-VAX NEWS HEADLINES (RQ1)\nIn this section, we present and discuss the results of the analysis\nrelated to our first RQ.\nFigure 3 shows the distribution of frames per country at headline\nlevel, with human interest and no-frame being the predominant\n1https://beta.openai.com/docs/introduction\n631\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nDavid Alonso del Barrio and Daniel Gatica-Perez\nones. Attribution of responsibility is the third one except in Switzer-\nland, where the corresponding frame is conflict. Finally, morality\nand economic are the least represented in the dataset for every\ncountry.\n<image: DeviceRGB, width: 650, height: 745, bpc: 8>Figure 3: Non-normalized distribution of frames per country\nThe monthly distribution of frames aggregated for all countries\nis shown in Fig. 4. We can see two big peaks, the first one in January\n2021 and the second one in August 2021. In all countries, the vac-\ncination process started at the end of December 2020, so it makes\nsense that the no-vax movement started to be more predominant in\nthe news in January 2021. Human interest is the most predominant\nframe. Manual inspection shows that this is because the headlines\nare about personal cases of people who are pro- or anti- vaccine.\nAttribution of responsibility is also present. Manual inspection in-\ndicates that local politicians and health authorities had to make\ndecisions about who could be vaccinated at the beginning of the\nprocess. The second peak at the end of summer 2021 coincided\nwith the health pass (also called Covid passport in some countries),\nand we can observe a peak in the curve corresponding to the con-\nflict frame, reflecting the demonstrations against the measure of\nmandatory health passes taken by country governments.\nIn Figure 5, we compare the sentiment per frame and per country,\nto understand if there were any major differences. The sentiment\nanalysis labels were obtained using BERT-sent from the Hugging\nFace package [47], used in our previous work (please refer to our\noriginal analysis in [3] for details.) We normalized the results be-\ntween 0 and 1 to compare frames between countries. We see that the\nsentiment is predominantly neutral (in blue). Examining in more\n<image: DeviceRGB, width: 622, height: 600, bpc: 8>Figure 4: Non-normalized monthly distribution of frames.\ndetail the negative and positive sentiment of each frame category,\nwe observed a few trends:\n• Attribution of responsibility: Negative sentiment represents\n30-40% of the cases, while positive tone is only found in\nresidual form in Italy, Switzerland, and the United Kingdom.\n• Conflict: Negative sentiment represents 20-35% of the cases.\n• Economic: Predominantly neutral, with only negative tone\nin Italy and UK (in the latter case, all headlines with this\nframe were considered negative.)\n• Human interest: Negative sentiment represents 30-40% of\nthe cases, while positive tone is only found in residual form\nin Italy, Spain, and Switzerland.\n• Morality: Predominantly neutral, with negative tone in Italy,\nSwitzerland, and the United Kingdom,\n• No frame: 20-30% of negative content.\n<image: DeviceRGB, width: 981, height: 525, bpc: 8>Figure 5: Sentiment of headline by frame and by country\n632\nFraming the News:\nFrom Human Perception to Large Language Model Inferences\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nRegarding the results of the annotation process, the fact that the\ndistribution of the 6 frame types is relatively similar between coun-\ntries suggests that the anti-vaccine movement issue was treated\nin a similar way in these countries. The fact that human interest\nis the most dominant frame indicates that this issue was treated\nfrom a more human and emotional approach, with headlines about\npersonal experiences, celebrities giving their opinion about vacci-\nnation, and politicians defending vaccine policies. Moreover, the\nreason for many headlines being classified as no-frame is partly\ndue to how data was selected. We chose articles that contained\nwords related to no-vax, either in the headline or in the article. This\nresulted in many headlines not containing anything specific related\nto no-vax, while the no-vax content was actually included in the\nmain text of the corresponding articles.\nIt is worth mentioning that prior to obtaining the results, we had\nexpected that attribution of responsibility would be among the most\nprominent frames, since governments took many measures such as\nmandatory health pass requirements to access certain sites; we had\nalso expected that the conflict frame would be prominent, since\nthere were many demonstrations in Europe. In reality, however,\nthese frames categories were not reflected as frequently at the\nheadline level.\nRegarding the analysis at the temporal level, it is clear that certain\nevents were captured by the press, such as the start of vaccination\nor the mandatory vaccination passport.\nFinally, the sentiment analysis of the different frames shows that\nthe predominant tone in all of them is neutral or negative, with very\nsimilar trends between countries. This association between senti-\nment analysis and frames has been discussed in previous literature\n[11] [43].\n6\nRESULTS: GPT-3.5 FOR FRAME\nCLASSIFICATION OF HEADLINES (RQ2)\nHere, we present and discuss the results related to our second RQ.\n6.1\nFine-tuning GPT-3.5\nTable 4 shows the results of the 6-class classification task using\n5-cross validation. Three models were used: GPT-3.5 and two BERT-\nbased models. We observe that, on average, GPT-3.5 performs better\nthan the BERT-based models. This is somehow expected as GPT-\n3.5 is a much larger model. Overall, in the case of fine-tuning, the\nbest performance for the six-class frame classification task is 72%\naccuracy, which is promising, with an improvement over previous\nmodels based on BERT. Yet, it should be noted that the performance\ndifferences are modest (2% improvement between GPT-3.5 and\nRoBERTa).\nTable 4: Classification results for six-class frame classifica-\ntion and 5-fold cross validation\nACCURACY\n0\n1\n2\n3\n4\nAVERAGE\nBERT\n0.68\n0.69\n0.72\n0.64\n0.70\n0.67\nRoBERTa\n0.70\n0.72\n0.72\n0.67\n0.71\n0.70\nGPT3\n0.75\n0.70\n0.72\n0.71\n0.71\n0.72\nOn the other hand, BERT is open-source, while GPT-3 has an\neconomic cost as the use of the model is not free, which monetarily\nlimits the number of experiments that can be performed with it,\nas well as the different configurations one can explore to improve\nperformance. This is important because much of the improvement\nin performance requires empirical explorations of model parameters\nMore specifically, the cost of an experiment for each of the folds has\na cost of 4 dollars (at the time of writing this paper.) This represents\na limitation in practice.\nFurthermore, GPT-3 has a significant carbon footprint. Similarly,\nfor prompt engineering (discussed in the next subsection), choosing\nthe right prompt (i.e., the words that best define the task so that the\nmodel is able to perform adequately) is also based on trial and error.\nThis also has an impact on carbon footprint. In connection with\nthis topic, Strubell et al.[55] argue that improvements in the accu-\nracy of models depend on the availability of large computational\nresources, which involve large economic and environmental costs.\nA criticism has been made as ’the rich get richer’, in the sense that\nnot all research groups have sufficient infrastructure resources and\naccess to funding needed to use these models and improve their\nperformance. Also in relation to this analysis, the work of Bender\net al. [4] evaluates the costs and risks of the use of large language\nmodels, stating that researchers should be aware of the impact that\nthese models have on the environment, and assess whether the\nbenefits outweigh the risks. The work in [4] provides a very telling\nexample, where people living in the Maldives or Sudan are affected\nby floods and pay the environmental price of training English LLMs,\nwhen similar models have not been produced for languages like\nDhivehi or Sudanese Arab. In short, there is a need to establish\nways to use this technological development responsibly, and it all\nstarts with being aware of the risks it presents.\n6.2\nPrompt-engineering with GPT-3.5\nFor each headline, we got the frame that the model considered the\nmost likely, and we compared these GPT-3.5 inferences with the\nframes labeled by the annotators. The agreement between model\nand annotator was of 49%. Analyzing the results, and specifically\nlooking at the cases where the annotator and GPT-3.5 disagreed,\nwe discovered that according to the frame definitions, the model\nin some cases proposed a frame that indeed made sense. This ob-\nservation, together with our previous experience in the annotation\nprocess, where headlines could have more than one valid frame,\nled us to design a second post-hoc experiment. We took all the\nheadlines where each of the two annotators had disagreed with\nGPT-3.5, and we asked the annotators to state whether they would\nagree (or not) with each GPT-inferred label for a given headline.\nIt is important to emphasize that the annotators did not know the\norigin of that label, i.e., they did not know if it was the label they\nhad originally assigned, or if it was a random one. In this way, we\ncould quantify how GPT-3.5 worked according to valid arguments\nprovided by the annotators. In this post-hoc experiment, the model\nagreed in 76% of cases with the annotators.\nLooking at the results of the classification models, the 49% accu-\nracy of the prompt-engineering approach can be considered low,\nyet we consider that it is a valid avenue for further investigation,\nas in the second post-hoc analysis, we found that the model agrees\n633\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\nDavid Alonso del Barrio and Daniel Gatica-Perez\nwith human annotators in 76% of the cases. Clearly, framing in-\nvolves aspects of subjectivity [42]. Much of what we do as people\nhas a subjective component, influenced by how we feel or how we\nexpress opinions.\nNews reading is never fully objective, and the annotators en-\ngaged in the frame classification task, influenced by their personal\nstate of mind, experience, and culture, may perceive information\ndifferently. Monarch affirms that \"for simple tasks, like binary labels\non objective tasks, the statistics are fairly straightforward to decide\nwhich is the ‘correct’ label when different annotators disagree. But\nfor subjective tasks, or even objective tasks with continuous data,\nthere are no simple heuristics for deciding what the correct label\nshould be\" [42].\nSubjectivity is involved in both the generation and perception\nof information: the assumption that there is only one frame is com-\nplicated by the point of view of the reader. In the case of news, the\ninformation sender (the journalist) has an intention, but the receiver\n(the reader) plays a role and is influenced by it. In psychology, this\nis known as the lens model of interpersonal communication, where\nthe sender has certain objectives, but the receiver can interpret\nor re-interpret what the sender wants to say, with more or less\naccuracy [26].\nFollowing this discussion on subjectivity, the question arose as to\nwhat would happen if, instead of headlines, we used the complete\narticle as a source of analysis. We wondered if longer text could\nmake the frame labeling task clearer than when using headlines.\nYet another possible hypothesis is that having to read longer texts\ncould lead to the same subject being presented from different angles.\nPlease recall that in the existing literature discussed in Section 2,\nboth headlines and full articles have been used from frame analysis\n(see Table 1.) This remains as an issue for future work.\n7\nCONCLUSIONS\nIn this paper, we first presented an analysis of human-generated\nnews frames on the covid-19 no-vax movement in Europe, and\nthen studied different approaches using large language models for\nautomatic inference of frames. We conclude by answering the two\nresearch questions we posed:\nRQ1: What are the main frames in the news headlines about the\ncovid-19 anti-vaccine movement in 5 European countries? After\nannotating the headlines, we found that of the 1786 headlines,\nthe predominant frame is human interest (45.3% of cases), which\npresents a news item with an emotional angle, putting a face to a\nproblem or situation. We also found that a substantial proportion\nof headlines were annotated as not presenting any frame (40.2% of\ncases). Finally, the other frame types are found more infrequently.\nRQ2: Can prompt engineering be used for classification of head-\nlines according to frames? We first used fine-tuning of a number of\nlanguage models, and found that GPT-3.5 produced classification ac-\ncuracy of 72% on a six-frame classification task. This represented a\nmodest 2% improvement over BERT-based models, at a significantly\nlarger environmental cost. We then presented a new way of classi-\nfying frames using prompts. At the headline level, inferences made\nwith GPT-3.5 reached 49% of agreement with human-generated\nframe labels. In many cases, the GPT-3.5 model inferred frame\ntypes that were considered as valid choices by human annotators,\nand in an post-doc experiment, the human-machine agreement\nreached 76%. These results have opened several new directions for\nfuture work.\nACKNOWLEDGMENTS\nThis work was supported by the AI4Media project, funded by the\nEuropean Commission (Grant 951911) under the H2020 Programme\nICT-48-2020. We also thank the newspapers for sharing their online\narticles. Finally, we thank our colleagues Haeeun Kim and Emma\nBouton-Bessac for their support with annotations, and Victor Bros\nand Oleksii Polegkyi for discussions.\n",
            "pdfUrl" : "",
            "reference" : "[1] Justito Adiprasetio and Annissa Winda Larasati. 2020. Pandemic crisis in online\nmedia: Quantitative framing analysis on Detik. com’s coverage of Covid-19.\nJurnal Ilmu Sosial Dan Ilmu Politik 24, 2 (2020), 153–170.\n[2] Neel Alex, Eli Lifland, Lewis Tunstall, Abhishek Thakur, Pegah Maham, C Jess\nRiedel, Emmie Hine, Carolyn Ashurst, Paul Sedille, Alexis Carlier, et al. 2021.\nRAFT: A real-world few-shot text classification benchmark.\narXiv preprint\narXiv:2109.14076 (2021).\n[3] David Alonso del Barrio and Daniel Gatica-Perez. 2022. How Did Europe’s Press\nCover Covid-19 Vaccination News? A Five-Country Analysis. (2022), 35–43.\nhttps://doi.org/10.1145/3512732.3533588\n[4] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret\nShmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models\nBe Too Big? (2021), 610–623.\n[5] Santosh Kumar Biswal and Nikhil Kumar Gouda. 2020. Artificial intelligence in\njournalism: A boon or bane? In Optimization in machine learning and applications.\nSpringer, 155–167.\n[6] Erik Bleich, Hannah Stonebraker, Hasher Nisar, and Rana Abdelhamid. 2015.\nMedia portrayals of minorities: Muslims in British newspaper headlines, 2001–\n2012. Journal of Ethnic and Migration Studies 41, 6 (2015), 942–962.\n[7] Michael Bommarito and Daniel Martin Katz. 2022. GPT Takes the Bar Exam.\nhttps://doi.org/10.48550/ARXIV.2212.14402\n[8] Meredith Broussard, Nicholas Diakopoulos, Andrea L Guzman, Rediet Abebe,\nMichel Dupagne, and Ching-Hua Chuan. 2019. Artificial intelligence and jour-\nnalism. Journalism & Mass Communication Quarterly 96, 3 (2019), 673–695.\n[9] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877–1901.\n[10] Björn Burscher, Daan Odijk, Rens Vliegenthart, Maarten De Rijke, and Claes H\nDe Vreese. 2014. Teaching the computer to code frames in news: Comparing\ntwo supervised machine learning approaches to frame analysis. Communication\nMethods and Measures 8, 3 (2014), 190–206.\n[11] Bjorn Burscher, Rens Vliegenthart, and Claes H de Vreese. 2016. Frames beyond\nwords: Applying cluster and sentiment analysis to news coverage of the nuclear\npower issue. Social Science Computer Review 34, 5 (2016), 530–545.\n[12] Dallas Card, Amber Boydstun, Justin Gross, Philip Resnik, and Noah Smith. 2015.\nThe Media Frames Corpus: Annotations of Frames Across Issues. 2 (01 2015),\n438–444. https://doi.org/10.3115/v1/P15-2072\n[13] Daniel Catalan-Matamoros and Carlos Elías. 2020. Vaccine hesitancy in the age\nof coronavirus and fake news: analysis of journalistic sources in the Spanish\nquality press. International Journal of Environmental Research and Public Health\n17, 21 (2020), 8136.\n[14] Daniel Catalán-Matamoros and Carmen Peñafiel-Saiz. 2019. Media and mistrust\nof vaccines: a content analysis of press headlines. Revista latina de comunicación\nsocial 74 (2019), 786–802.\n[15] Mark Coddington. 2015. Clarifying journalism’s quantitative turn: A typology\nfor evaluating data journalism, computational journalism, and computer-assisted\nreporting. Digital journalism 3, 3 (2015), 331–348.\n[16] Stephen D Cooper. 2010. The oppositional framing of bloggers. In Doing News\nFraming Analysis. Routledge, 151–172.\n[17] Robert Dale. 2021. GPT-3: What’s it good for? Natural Language Engineering 27,\n1 (2021), 113–118.\n[18] Astrid Dirikx and Dave Gelders. 2010.\nTo frame is to explain: A de-\nductive frame-analysis of Dutch and French climate change coverage dur-\ning the annual UN Conferences of the Parties.\nPublic Understanding of\nScience 19, 6 (2010), 732–742.\nhttps://doi.org/10.1177/0963662509352044\narXiv:https://doi.org/10.1177/0963662509352044 PMID: 21560546.\n[19] Astrid Dirikx and Dave Gelders. 2010. To frame is to explain: A deductive frame-\nanalysis of Dutch and French climate change coverage during the annual UN\nConferences of the Parties. Public understanding of science 19, 6 (2010), 732–742.\n634\nFraming the News:\nFrom Human Perception to Large Language Model Inferences\nICMR ’23, June 12–15, 2023, Thessaloniki, Greece\n[20] Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, and Graham Neubig.\n2020. Gsum: A general framework for guided neural abstractive summarization.\narXiv preprint arXiv:2010.08014 (2020).\n[21] Sumayya Ebrahim. 2022. The corona chronicles: Framing analysis of online news\nheadlines of the COVID-19 pandemic in Italy, USA and South Africa. Health SA\nGesondheid (Online) 27 (2022), 1–8.\n[22] Hend Abdelgaber Ahmed El-Behary. 2021. A Feverish Spring: A Comparative\nAnalysis of COVID-19 News Framing in Sweden, the UK, and Egypt. (2021).\n[23] Robert M Entman. 1993. Framing: Towards clarification of a fractured paradigm.\nMcQuail’s reader in mass communication theory 390 (1993), 397.\n[24] Tianyu Gao, Adam Fisch, and Danqi Chen. 2020. Making pre-trained language\nmodels better few-shot learners. arXiv preprint arXiv:2012.15723 (2020).\n[25] Piyush Ghasiya and Koji Okamura. 2021. Investigating COVID-19 news across\nfour nations: a topic modeling and sentiment analysis approach. Ieee Access 9\n(2021), 36645–36656.\n[26] Robert Gifford. 1994. A Lens-Mapping Framework for Understanding the En-\ncoding and Decoding of Interpersonal Dispositions in Nonverbal Behavior.\nJournal of Personality and Social Psychology 66 (02 1994), 398–412.\nhttps:\n//doi.org/10.1037//0022-3514.66.2.398\n[27] Quentin Grail, Julien Perez, and Eric Gaussier. 2021. Globalizing BERT-based\ntransformer architectures for long document summarization. In Proceedings of\nthe 16th Conference of the European Chapter of the Association for Computational\nLinguistics: Main Volume. 1792–1810.\n[28] Anushka Gupta, Diksha Chugh, Rahul Katarya, et al. 2022. Automated news\nsummarization using transformers. In Sustainable Advanced Computing. Springer,\n249–259.\n[29] Alfred Hermida and Mary Lynn Young. 2017. Finding the data unicorn: A hierar-\nchy of hybridity in data and computational journalism. Digital Journalism 5, 2\n(2017), 159–176.\n[30] Karoliina Isoaho, Daria Gritsenko, and Eetu Mäkelä. 2021. Topic modeling and\ntext analysis for qualitative policy research. Policy Studies Journal 49, 1 (2021),\n300–324.\n[31] Carina Jacobi, Wouter Van Atteveldt, and Kasper Welbers. 2016. Quantitative\nanalysis of large amounts of journalistic texts using topic modelling. Digital\njournalism 4, 1 (2016), 89–106.\n[32] Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig. 2020. How can we\nknow what language models know? Transactions of the Association for Computa-\ntional Linguistics 8 (2020), 423–438.\n[33] Shima Khanehzar, Andrew Turpin, and Gosia Mikołajczak. 2019. Modeling\nPolitical Framing Across Policy Issues and Contexts. In ALTA.\n[34] Jeesun Kim and Wayne Wanta. 2018. News framing of the US immigration debate\nduring election years: Focus on generic frames. The Communication Review 21, 2\n(2018), 89–115.\n[35] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michi-\nhiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al.\n2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110\n(2022).\n[36] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and\nGraham Neubig. 2021. Pre-train, prompt, and predict: A systematic survey of\nprompting methods in natural language processing. (2021). https://doi.org/10.\n48550/ARXIV.2107.13586\n[37] Siyi Liu, Lei Guo, Kate Mays, Margrit Betke, and Derry Tanti Wijaya. 2019.\nDetecting frames in news headlines and its application to analyzing news framing\ntrends surrounding US gun violence. In Proceedings of the 23rd conference on\ncomputational natural language learning (CoNLL).\n[38] Jörg Matthes and Matthias Kohring. 2008. The Content Analysis of Media Frames:\nToward Improving Reliability and Validity. Journal of Communication 58 (06\n2008). https://doi.org/10.1111/j.1460-2466.2008.00384.x\n[39] Selina Meyer, David Elsweiler, Bernd Ludwig, Marcos Fernandez-Pichel, and\nDavid E Losada. 2022. Do We Still Need Human Assessors? Prompt-Based GPT-3\nUser Simulation in Conversational AI. In Proceedings of the 4th Conference on\nConversational User Interfaces. 1–6.\n[40] Stuart E Middleton, Symeon Papadopoulos, and Yiannis Kompatsiaris. 2018. Social\ncomputing for verifying social media content in breaking news. IEEE Internet\nComputing 22, 2 (2018), 83–89.\n[41] Marko Milosavljević and Igor Vobič. 2021. ‘Our task is to demystify fears’:\nAnalysing newsroom management of automation in journalism. Journalism 22,\n9 (2021), 2203–2221.\n[42] R. Monarch. 2021. Human-in-the-Loop Machine Learning: Active Learning and\nAnnotation for Human-centered AI. Manning. https://books.google.ch/books?\nid=LCh0zQEACAAJ\n[43] Tom Nicholls and Pepper D Culpepper. 2021. Computational identification of\nmedia frames: Strengths, weaknesses, and opportunities. Political Communication\n38, 1-2 (2021), 159–181.\n[44] Zhongdang Pan and Gerald M Kosicki. 1993. Framing analysis: An approach to\nnews discourse. Political communication 10, 1 (1993), 55–75.\n[45] Raul Puri and Bryan Catanzaro. 2019. Zero-shot text classification with generative\nlanguage models. arXiv preprint arXiv:1912.10165 (2019).\n[46] Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying lms with\nmixtures of soft prompts. arXiv preprint arXiv:2104.06599 (2021).\n[47] Rabindra Lamsal. 2021. Sentiment Analysis of English Tweets with BERTsent.\nhttps://huggingface.co/rabindralamsal/finetuned-bertweet-sentiment-analysis.\n[48] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,\net al. 2019. Language models are unsupervised multitask learners. OpenAI blog\n1, 8 (2019), 9.\n[49] Nishant Rai, Deepika Kumar, Naman Kaushik, Chandan Raj, and Ahad Ali. 2022.\nFake News Classification using transformer based enhanced LSTM and BERT.\nInternational Journal of Cognitive Computing in Engineering 3 (2022), 98–105.\nhttps://doi.org/10.1016/j.ijcce.2022.03.003\n[50] Frida V Rodelo. 2021. Framing of the Covid-19 pandemic and its organizational\npredictors. Cuadernos. info 50 (2021), 91–112.\n[51] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel\nHesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias\nGallé, et al. 2022. Bloom: A 176b-parameter open-access multilingual language\nmodel. arXiv preprint arXiv:2211.05100 (2022).\n[52] Holli Semetko and Patti Valkenburg. 2000. Framing European Politics: A Content\nAnalysis of Press and Television News. Journal of Communication 50 (06 2000),\n93 – 109. https://doi.org/10.1111/j.1460-2466.2000.tb02843.x\n[53] Richard Shin, Christopher H Lin, Sam Thomson, Charles Chen, Subhro Roy, Em-\nmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, and Benjamin\nVan Durme. 2021. Constrained language models yield few-shot semantic parsers.\narXiv preprint arXiv:2104.08768 (2021).\n[54] Efstathios Sidiropoulos and Andreas Veglis. 2017. Computer Supported Collab-\norative Work trends on Media Organizations: Mixing Qualitative and Quan-\ntitative Approaches.\nStudies in Media and Communication 5 (04 2017), 63.\nhttps://doi.org/10.11114/smc.v5i1.2279\n[55] Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy\nconsiderations for deep learning in NLP. arXiv preprint arXiv:1906.02243 (2019).\n[56] Alex Tamkin, Miles Brundage, Jack Clark, and Deep Ganguli. 2021. Understanding\nthe capabilities, limitations, and societal impact of large language models. arXiv\npreprint arXiv:2102.02503 (2021).\n[57] Trieu H Trinh and Quoc V Le. 2018. A simple method for commonsense reasoning.\narXiv preprint arXiv:1806.02847 (2018).\n[58] Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and\nFelix Hill. 2021. Multimodal few-shot learning with frozen language models.\nAdvances in Neural Information Processing Systems 34 (2021), 200–212.\n[59] Sandra A Vannoy and Prashant Palvia. 2010. The social influence model of\ntechnology adoption. Commun. ACM 53, 6 (2010), 149–153.\n[60] Tuukka Ylä-Anttila, Veikko Eranti, and Anna Kukkonen. 2022. Topic modeling\nfor frame analysis: A study of media debates on climate change in India and USA.\nGlobal Media and Communication 18, 1 (2022), 91–112.\n635\n",
            "keyWords" : "Covid-19 no-vax, news framing, GPT-3, prompt-engineering, trans-\nformers, large language models\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "19",
          "_score" : 1.0,
          "_source" : {
            "title" : "ModelGame: A Quality Model for Gamified Software Modeling Learning",
            "samary" : "Gamification has been adopted in software development tasks inrecent years. This adoption seeks, for example, to improve the en-gagement of developers while creating UML models or writingcode. Empirical studies report that UML models suffer from incom-pleteness and inconsistency problems. This study conjectures thatgamification mechanics can improve learner engagement whilelearning software modeling, mitigating such problems concern-ing UML models. The current literature lacks studies that exploregamification and UML model quality in the context of softwaremodeling learning. This article, therefore, proposes ModelGame,which is a quality model to support software modeling learning in agamified way. It serves as a reference framework so that instructorscan obtain a parameterized way to evaluate UML models createdby learners. The quality of UML models can be improved by apply-ing gamified activities and providing guidelines aware of qualityissues. A qualitative questionnaire was answered by 19 instructorswho teach software modeling at higher education institutions. Theresults show that (1) 94.7% recognize that the proposed model canimprove the quality of UML models, indicating that they wouldadopt the ModelGame in their learning practices; and (2) 47.4% donot use any gamification mechanics in their classes. The results areencouraging, showing the potential for applying and improvingthe teaching and learning of software modeling.",
            "authors" : "Ed Wilson Júnior∗\nUniversidade do Vale do Rio dos Sinos\nSão Leopoldo, Rio Grande do Sul, Brazil\nedwjr7@edu.unisinos.br\nKleinner Farias\nUniversidade do Vale do Rio dos Sinos\nSão Leopoldo, Rio Grande do Sul, Brazil\nkleinnerfarias@unisinos.br\n",
            "institutions" : "",
            "integralText" : "1\nINTRODUCTION\nGamification has been adopted in software development tasks in\nrecent years. This adoption seeks, for example, to improve the en-\ngagement of developers while creating UML models or writing\ncode. Empirical studies [7, 9, 14] report that UML models suffer\nfrom incompleteness and inconsistency problems. Lange [14] rein-\nforces that these defects bring potential risks that can cause mis-\ninterpretation and communication failure, representing a risk to\nsoftware quality. Thus, finding formats that favor student learning\nand consequently in generating increasingly effective UML mod-\nels can become one of the main challenges faced by instructors\nthat include UML (Unified Modeling Language) as part of software\nmodeling content.\nSome studies [3, 12, 25] sought to understand how to apply gam-\nification in software modeling teaching using some elements such\nas points, emblems and levels. However, instructors and researchers\nstill find limitations when applying, evaluating, and measuring the\nuse of this tool in the learning of software modeling students and,\nconsequently, in the models developed by them, since in the current\nliterature there is no “frame of reference” that guides them. This\nstudy conjectures that gamification mechanics can improve learner\nengagement while learning software modeling, mitigating such\nproblems concerning UML models. The current literature lacks\nstudies that explore gamification and model quality in the context\nof software modeling learning.\nThis article, therefore, introduces ModelGame, which is a quality\nmodel to support software modeling learning in a gamified way.\nIt serves as a reference framework so that instructors can obtain\na parameterized way to evaluate UML models created by learners.\nThe quality of UML models can be improved by applying gami-\nfied activities and providing guidelines aware of quality issues. A\nreference framework would help to (1) establish parameters for eval-\nuating UML models created by learners; (2) provide guidelines to\nimprove the quality of these artifacts; (3) to analyze which elements\nof gamification could be included in each of the phases of modeling\nusing UML; (4) identify intrinsic and extrinsic aspects of students\nduring the modeling stages, to improve the models; (5) to compare\nvalidated theories about the inclusion of gamification in software\nmodeling teaching, taking into account the types of learning and\nmethodologies used; and (6) contributing to the identification of\ngamification use objectives in modeling activities.\nA qualitative questionnaire was answered by 19 instructors who\nteach software modeling at higher education institutions. The re-\nsults show that (1) 94.7% recognize that the proposed model can\nimprove the quality of UML models, indicating that they would\nadopt it in their learning practices; and (2) 47.4% do not use any\n100\n<image: CalRGB, width: 1003, height: 1004, bpc: 8>SBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nEd Wilson Júnior and Kleinner Farias\ngamification mechanics in their classes. These results are encourag-\ning, showing the potential for applying and improving the teaching\nand learning of software modeling.\nThe remainder of the paper is organized as follows. Section 2\npresents the main concepts discussed throughout the article. Sec-\ntion 3 discusses the related work, highlighting research opportu-\nnities. Section 4 introduces the proposed quality model. Section 5\npresents how the quality model was evaluated. Section 6 points out\nsome threats to validity. Finally, Section 7 presents some concluding\nremarks and future work.\n2\nBACKGROUND\nThis section presents the essential concepts for understanding this\nwork, including gamification and software engineering teaching\n(Section 2.1), and software modeling and model quality (Section\n2.2).\n2.1\nGamification and Software Engineering\nTeaching\nGamification aims to use game elements in the context of not game\n[5], bringing all positive aspects they provide as a way to encourage\nand engage “players,” thereby broadening their motivations.\nWerbach [23] classifies gamification into three dimensions: Dy-\nnamics, Mechanics, and Components. Dynamicsinclude all game\naspects related to the emotional responses of “players” (e.g., rela-\ntionship, progression, and narrative).Mechanics offer elements that\npromote the action of a game — usually elaborated via a rule-based\ndevelopment —, so that the player can interact with such elements,\ne.g., challenges, feedback, and rewards. Components represent\nthe aesthetic elements of gamification, whose goal is to present\nvisual aspects with which players can perform the interaction, for\nexample, points, scores, and emblems (badges).\nKnowing that the teaching of Software Engineering should in-\nvolve students to experience the professional practices of the area\nso that they can understand which practices and techniques are\nuseful in several different situations [2]. The challenges of teaching\nnew software engineers are not limited to learning programming,\nbut also include paying attention to detail, considering the quality\nof created models, established schedule and defined budgets [1]. In\naddition to understanding the technical challenges, these future\nprofessionals must be up to date with nontechnical issues, including\nteamwork, communication and management.\nTo meet these new demands of the current context, the format\nwith exhibition classes is no longer considered enough and may\neven become demotivating and ineffective in learning students. In\nthis sense, gamification has been increasingly used in the teach-\ning of software engineering as a way to promote behavioral and\npsychological changes [11] providing an environment that favors\ncommunication, cooperation, feedback, reward, achievement and\nother recurring elements that are capable of improving perfor-\nmance, efficiency and engagement in educational activities , and\ncan enhance, for example, the learning of software modeling.\n2.2\nSoftware Modeling and Model Quality\nSoftware modeling encompasses the set of principles, concepts, and\npractices that lead to the development of a high-quality system or\nproduct. The principles of this activity establish a philosophy that\nguides the entire software development process.\nIn this scenario, UML models play a crucial role in software\ndevelopment tasks, for example, documenting project decisions,\nunderstanding development details, promoting better communica-\ntion between teams, and generating greater efficiency in software\ndevelopment [19]. However, these models suffer problems of in-\nconsistency and incompleteness [10, 18], as well as end up being\noverlooked within the modeling process, as pointed out in some\nempirical studies in the literature [14, 15]. Class and sequence dia-\ngrams, for example, present inconsistencies when sequence diagram\nobjects are not found in the class diagram, consequently developers\nend up living with inconsistencies throughout the development\nprocess.\nA research challenge still open is how to evaluate these diagrams,\nboth in industry and in the teaching process, in terms of quality,\nsuch as syntactic and semantic, for example.\n3\nRELATED WORK\nThe selection of related works was carried out following two steps:\n(1) search in digital repositories, such as Google Scholar and Scopus\n(Elsevier) of articles related to gamification, quality modeling, and\nmodeling learning; and (2) filter selected articles considering the\nalignment of such works with the objective of the work (Section 4).\nAfter selecting the works, they were analyzed (Section 3.1) and\ncompared (Section 3.2), seeking to identify research opportunities.\n3.1\nAnalysis of Related Works\nPorto et al. (2021) [4]. This work performed a systematic map-\nping with the objective of characterizing how gamification has\nbeen adopted in noneducational contexts of software engineering\nactivities. The main results of this study show that gamification\nprovided benefits for activities such as requirements specification,\ndevelopment, testing, project management, and support process.\nIn addition, he pointed out that the number of publications and\nnew research initiatives has increased over the years, many posi-\ntive results have been achieved in software engineering activities.\nNevertheless, the study reinforced that gamification can still be\nexplored for other tasks in this area, as empirical evidence is very\nlimited.\nMarin (2021) [17]. It performed the application of gamification\non some topics of a software engineering course to engage students\nand increase their motivation and argued that, with due motiva-\ntion, students can better exercise the topics and obtain more solid\nknowledge. There were five games related to risk management,\nBPMN modeling, Scrum process, design and inspection of class\ndiagrams, and cosmic functional size measurement to assist in the\nlearning process of the software engineering course. This study also\npresented the lessons learned about the application of gamification\nand serious games in software engineering, including limitations\nor disadvantages.\nJurgelaitis et al. (2018) [12]. This work conducted a research to\ninvestigate how gamification could be inserted into an Information\nSystems Modeling course, which covers a range of topics on UML.\nAs a result, an implementation of the gamified system modeling\ncourse in the Moodle environment was presented, using additional\n101\nModelGame: A Quality Model for Gamified Software Modeling Learning\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nplugins for the use of the necessary gamified elements. The study\nshowed good results and obtained a positive acceptance by the\nparticipating students.\nRodrigues et al. (2018) [22]. They investigated the use of games\nand game elements in software engineering education, through a\nresearch that had the participation of 88 instructors of this disci-\npline. The results showed that most instructors are aware of these\neducational approaches, however, the games were adopted by only\n21 participants and game elements were adopted only by 19. Games\nare most often used to cover “Software Process” and “Project Man-\nagement”. The most commonly used game elements are points,\nquizzes, and challenges. The results also show that the main rea-\nsons for not adopting the resources are the lack of knowledge,\ninformation about games relevant to the engineering of teaching\nsoftware, and the lack of time to plan and include these approaches\nin the classroom.\nCosentino et al. (2017) [3]. They present a model-based ap-\nproach to learning modeling in a gamified way. The approach in-\ncludes a new language to model the gamification process itself and\nan environment where it can be incorporated into current mod-\neling tools to allow instructors and students to design and use a\ncomplete modeling framework, including gamification elements. In\naddition, the approach also had as a proposal to provide support to\ncollect and analyze gamification data, thus facilitating monitoring\nactivities.\nYohannis (2016) [25]. This research presents an exploration of\ngame design as an approach to strengthening the student’s mas-\ntery in software modeling by developing their abstraction skills. It\nbrought together concepts of gamification development, such as the\nlens of atoms of intrinsic skill and principles of pedagogical design\nof various theories and models of learning. The research follows\nthe Design Science Research Methodology and explores the best\npractices of Model Oriented Engineering. As a result, a modeling\ngame design framework and generation structure and a series of\nproduced games are presented.\nPedreira et al. (2015) [21]. They developed a systematic map-\nping of gamification in Software Engineering based on 29 studies.\nThe mapping revealed that software implementation is the area\nin which most studies focus, followed by software requirements,\nfew others in different areas, such as project planning and software\ntesting, and even to a lesser extent in activities involving software\nmodeling. However, the highlight of this work was to highlight that\ngamification in software engineering is still at a very early stage\nand the evidence on its impact in this field remains inconclusive.\n3.2\nComparative Analysis and Opportunities\nFive Comparison Criteria (CC) were defined selecting the most rele-\nvant variables to assist in the process of identifying similarities and\ndifferences between the proposed work and the selected articles.\nThis comparison is crucial to make the process of identifying re-\nsearch opportunities using objective rather than subjective criteria.\nThe criteria are described below:\n• Context (CC01): Works that explore the use of gamification\nin software modeling teaching/learning.\n• Participant profile (CC02): Studies that collected data from\nparticipants for screening and profile characterization.\n• Applicability of Gamification in UML (CC03): Studies\nthat evaluated how gamification can contribute to UML mod-\nels.\n• Model creation (CC04): Studies that have developed a model\nto improve factors that imply the non-adoption of UML.\n• Instructor participation (CC05): Studies that collected\nqualitative data through the participation of software mod-\neling instructors.\nTable 1 shows the comparison of the selected works, confronting\nthis work. Some gaps and research opportunities are observed: (1)\nonly the proposed work was the only one to fully meet all compar-\nison criteria; (2) although most of them targeted the application\nof gamification in software modeling teaching, they were not di-\nrected to the use of UML; (3) no study has developed a model to\nevaluate the learning and improvement of UML models developed\nby students; and (4) most of them did not have the participation\nof instructors to identify the difficulties and opportunities in the\napplication of gamification in the teaching of software modeling.\nThus, the next Section presents a quality model to explore these\nidentified opportunities.\nRelated Work\nComparison Criterion\nCC1\nCC2\nCC3\nCC4\nCC5\nProposed Work\n�\n�\n�\n�\n�\nPorto et al (2021) [4]\n�\n�\n�\n�\n�\nMarin (2021) [17]\n�\n�\n�\n�\n�\nJurgelaitis et al (2018) [12]\n�\n�\n�\n�\n�\nRodrigues et al (2018) [22]\n�\n�\n�\n�\n�\nCosentino et al (2017) [3]\n�\n�\n�\n�\n�\nYohannis (2016) [25]\n�\n�\n�\n�\n�\nPedreira et al (2015) [21]\n�\n�\n�\n�\n�\n� Completely Meets\n� Partially Meets\n� Does not attend\nTable 1: Comparative analysis of the selected related works\n4\nPROPOSED QUALITY MODEL\nThis section presents the proposed quality model to support soft-\nware modeling learning in a gamified way. It serves as a frame\nof reference so that instructors can evaluate the UML models cre-\nated by students through gamified activities. Section 4.1 presents\na proposal of a generic analytical framework. Section 4.2 details\nthe abstract syntax of the proposed quality model. Section 4.3 ex-\nplains the quality notions related to the gamified software modeling\nlearning.\n4.1\nGeneric Analytical Framework\nFigure 1 presents the generic analytical framework for improving\nthe quality of the models and serves as the basis for the creation of\nan evaluation scheme. The arrows (\"links\"), labeled as Evaluation\nand Gamified Modeling, represent the questions that the evidence\nmust answer; dotted lines represent associations; rectangles rep-\nresent the Models (rounded corners) or the quality states (square\ncorners) by which these bindings are measured. Ellipses represent\nthe adverse effects that can be generated from the evaluation and\nuse of gamification.\nThe numbers refer to the key questions and are connected with\nthe concepts and relationships of the abstract syntax of the Quality\n102\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nEd Wilson Júnior and Kleinner Farias\n<image: DeviceRGB, width: 1096, height: 381, bpc: 8>Figure 1: Generic analytical framework for gamified software modeling learning.\nModel (presented in Section 4.2), as follows: (1) Are there tools\nthat assist instructors in evaluating the models developed by stu-\ndents, thus reducing the poor quality and incompleteness of these\nartifacts? (2) What is the prevalence of characteristics that cause\nmodels to be at risk? (3) Are there notions of quality to evaluate\nthe models as a way to define parameters when performing their\ncorrection? (4) Applying the use of gamification in models that\nneed intervention would be a way to identify factors that could\ngenerate models with high quality levels? (5) Does the application\nof gamification improve the quality of the model? (5.a) How are the\nmodels without gamification evaluated in relation to those with\ngamification? (5.b) Are there reasons to expect that gamification\nmodels can have better quality results than those that are gener-\nated without gamification? (6) Is the output model really effective\nwhen associated with reducing the poor quality of the model? (7)\nDoes the absence of evaluation result in adverse effects? (7.a) is the\nevaluation acceptable for the model? (7.b) What are the potential\nharms, and how often do they occur? (8) Does gamification result\nin adverse effects on models?\nFact is that it is not enough just to include this \"toolbox\" in the\nUML learning process, it is necessary to provide the instructor with\na model (guide) that can serve as a reference to evaluate the quality\nof diagrams elaborated through gamified activities. For example,\nthe instructor could create models predefining inconsistencies by\nmaking use of these questions raised to evaluate the models created\nby the students. The set of questions serves as the starting point for\nthis evaluation. Knowing that the adaptation of the gamification\napproach requires a significant effort [20], in this study we present\nThe ModelGame as a way to identify factors that contribute to\nthe quality of these artifacts and, consequently, to the students’\nlearning.\n4.2\nAbstract Syntax\nFollowing the specification pattern of the UML metamodel, Figure 2\npresents the abstract syntax of the proposed Quality Model for\ngamified software modeling learning (ModelGame). It identifies\nthe main concepts and relationships. The numbers represent the\nnotions of quality that are discussed in Section 4.3. The following\nare detailed each of these concepts and relationships.\nDomain. The first concept presented in this study is the domain,\nwhich corresponds to a specific context of the application to be\ndeveloped to solve the problem. In this process, the design template\nrepresents the solution given to the domain.\nAssociation\n• contextualizes: Challenges[*]\nEach contextualise refers to the domain that will serve as the\nbasis for the challenges launched.\nChallenges. This concept represents the phase in which the\nproblem is contextualized (domain-based), as well as what will be\nthe missions, phases, scenarios, and other elements presented to\nthe players, in this case the students, who must use the principles\nof software engineering to perform the modeling and reach the\nfinal goal.\nAssociation\n• influences: Design Model[*]\nEach influence represents that the proposed challenge interfered\nin aspects of the design model, causing the user to seek to make a\ncontinuous improvement.\nModeling Language. Software modeling is an important step\nfor development to happen in a way that adheres to the require-\nments established by the requester, for this, there is the modeling\nlanguage, which offers a standardized way to document and design\nsoftware. Through the use of modeling languages, it is possible to\nachieve a high level of understanding about the software in ques-\ntion, improving the communication between all those involved in\nthe process, thus avoiding implementation errors. It points out that\nsoftware engineers use these languages to communicate design\ndecisions and verify the feasibility of implementing the intended\ndesign. The UML was consolidated as the Modeling Language in\nthe paradigm of object orientation, in which it is possible through\nvisual notation generated from the diagrams- presented later in this\nstudy as Design Models- to perform the representation of various\nperspectives of the system.\nAssociation\n103\nModelGame: A Quality Model for Gamified Software Modeling Learning\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\n<image: DeviceRGB, width: 1170, height: 780, bpc: 8>Figure 2: Abstract Quality Model Syntax.\n• expresses: Design Model[*]\nPerforms the representation of the intended design templates, in\nwhich the Modeling Language should be applicable to the domain\ntype.\nUser. This concept corresponds to the individual who performs\nthe interpretation of the developed design models, whose objective\nis to be able to understand the domain in question. In the gamified\ncontext, the user has the role of player and it is he who performs\nthe whole process, being able to perform the interpretation of ex-\nisting models or even creating new ones. The user can also identify\nand resolve inconsistencies that arise from compositions between\nmodels.\nAssociation\n• creates: Design Model[1..*]\nRepresents the process in which the user creates a design template,\nwhich can be one or more.\n• interprets: Design Model[1..*]\nIn this association, the user performs the interpretation of the design\ntemplate. When interpreting the model, paths for the resolution of\ninconsistencies can be identified.\n• detects: Inconsistency [*]\nRepresents the user’s discovery of design model inconsistencies,\nfor example, those that are generated from identifying conflicts,\nwhether a class is abstract or not.\n• resolves: Inconsistency [*]\nEach resolves equates to the resolution representation of the incon-\nsistencies by the user that happens after he analyzes and determines\nthe best alternative to perform this action.\n• uses: Modeling Tools [*]\nDetermines that the user can use modeling tools to generate/update\ndesign models.\nAssociation\n• Without a directed relationship.\nModeling Tool. This concept represents the applications that\nare used to carry out the construction of design models. There are\nseveral tools available, online and desktop, and it is up to the user\nto choose the one that will best meet their needs and adapt to the\ncontext in question, that is, they work in any domain that is being\nconsidered.\nDesign Model. The design model refers to a visual notation\n(diagram) to represent static and dynamic aspects. These models are\nbuilt according to a specific objective or task and tend to facilitate\nthe logical interpretation of the software in several aspects. The\nmost popular diagrams are Use Cases and Classes, the first being\nstatic and representing a set of actions generated from functional\nrequirements (use cases) and presenting the interactions generated\nwith external users (actors). The second is a static diagram and\nmakes the representation of the logical structure of the software\ninvolving the classes, their attributes, methods, and relationships\nbetween them [19].\nAssociation\n• describes: Domain[1]\nEach describes makes the representation of a specific domain\nand means that every design model must describe it.\nInconsistency. It corresponds to the defects found in the models\ndeveloped by users. They may occur because of the nonidentifi-\ncation and correction of possible conflicts and even an erroneous\ninterpretation.\nAssociation\n• affects: Design Model[*]\nThis association indicates that with each occurrence of the affect, a\nproblem is presented harming the quality of the design model.\n104\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nEd Wilson Júnior and Kleinner Farias\nPoints. This concept represents one of the most used game me-\nchanics in software engineering and functions as a quantitative\nreward for each action developed, in which it is possible to regulate\nthe number of rewarded points of the player, defined here as user,\nbased on the importance of each action. Through this concept, it\nis possible to stimulate competition, collaboration, and creativity\namong users, stimulating learning. Points appear as a derivation\nof the association affects, since when each inconsistency error is\nidentified or not, the user will receive a score and the association\ndescribes, because the points will also be applied when making\nconnections between the model and the domain.\nProgress. The concept of progress emerges as a factor that makes\nthe user able to perceive its evolution in the process, in this case,\nsoftware modeling. Progress emerges as a derivation of the associa-\ntion interprets, making the user know when they have performed\na correct interpretation of the proposed design model or what still\nneeds to be improved.\nFeedback. Feedback has the role of making the user realize that\nthe proposed goal can be achieved and follow its evolution, includ-\ning analyzing how to change or creating new strategies to achieve\nthe goal. This concept emerges as a derivation between the associa-\ntions it creates, causing the user to receive a return to the model\ncreation process.\n4.3\nQuality Notions\nAs discussed in Section 2, gamification can bring important ele-\nments for learning software modeling and, therefore, the objective\nof this section is to produce the notions of quality of the model\nof this study. The ModelGame is composed of ten counts, four of\nwhich are proposed in this study - scope, use, motivational and en-\ngagement - extracted from the main benefits that the gamification\nelements presented in Figure 2 can bring to the models. The others\nare adaptations of previous works [6, 14, 15], they are, syntactic,\nsemantic, social, effort, detection and resolution.\nScope Quality (1). It seeks to determine how much the proposed\nchallenge is contextualized with the design model, as well as the def-\ninition of the domain, problem, competencies, concepts, behaviors\nand attitudes that will be developed throughout the process.\nSyntactic Quality (2). This notion makes the representation of\nthe process of correction of the design models that are produced\nby the modeling language, because if it is not used correctly, incon-\nsistencies will arise. It is important to insert this notion of quality\ninto our study, since during the process of developing the models,\nusers may come across the composition of two class diagrams, for\nexample.\nSemantic Quality (3). It is necessary to verify that the design\nmodel and the problem domain match, so this notion performs\nthis type of analysis. Communication problems may occur between\nusers if the semantic elements of the model are affected.\nSocial Quality (4). Design models are used to communicate\nbetween members of a team to inform all established decisions\nabout software development [8]. If divergent interpretations occur,\nthis communication will be greatly impaired.\nQuality of Effort (5). This notion refers to the production chal-\nlenges of the model that will be generated, including factors such\nas time and cost.\nQuality of Use (6). To produce design templates, users can use\nunusual tools such as paper, whiteboard, and more. However, most\nof the time they choose to use formal tools (CASES) and can be\nonline or desktop. This notion corresponds to the level of ease and\napplicability of the models elaborated when making use of these\ntools, it is also important to contribute to communication between\nusers through collaboration-related functionalities.\nDetection Quality (7). This notion is referenced to the process\nof locating inconsistencies, since when users arise, they should\nperform traceability of them quickly. If the detection is complicated,\nit could hinder the process of correcting the models.\nResolution Quality (8). It corresponds to the level of quality\nrelated to the effort that users take to look for alternatives to solve\nthe identified problem.\nMotivational Quality (9). This notion refers to the motiva-\ntional factors involved during the learning and development of\ndesign models, which can be intrinsic and extrinsic. Elements of\ngamification such as points, feedback and progress bring the user a\ndegree of satisfaction in continuing their discovery and transfor-\nmations throughout the process.\nQuality of Engagement (10). The user in tracking their progress\ncan feel committed to the objective in question, and this notion\nrepresents the measurement of the level of commitment of them\nduring the development of design models.\n5\nEVALUATION\nThis section describes the methodology followed to evaluate the\nproposed quality model. This methodology follows well-established\nempirical guidelines [24]. Section 5.1 details the objective and re-\nsearch questions (RQ). Section 5.2 presents the questionnaire formu-\nlated to evaluate the proposed quality model. Section 5.3 explains\nthe context and selection of participants. Section 5.4 describes the\npresentation of the Model. Section 5.5 presents the analysis of the\ncollected data.\n5.1\nObjective and Research Questions\nThe objective (O) of this study is twofold: (O1) Introduce Model-\nGame as a tool for teaching Software Modeling; and (O2) Analyze\nthe applicability of the quality model regarding the improvement\nof UML models.\nTo analyze the different facets of the objectives, two Research\nQuestions (RQ) have been formulated:\n• RQ1: How do instructors evaluate the use of gamification\nin software modeling?\n• RQ2: What is the acceptance of ModelGame by software\nmodeling instructors?\n5.2\nQuestionnaire\nData was collected through an online questionnaire created through\nGoogle Forms1 following well-established guidelines described in\n[24]. This strategy was chosen because the questionnaire could\nbe applied quickly and easily collect data from individuals in geo-\ngraphically diverse locations. The questions of the questionnaire\n1Questionnaire: https://forms.gle/qjaFDpErEtGdLuWw6\n105\nModelGame: A Quality Model for Gamified Software Modeling Learning\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nwere concerned with examining the research gaps of previous stud-\nies and apprehending the structures of the previously developed\nquestionnaire.\nPart 1: Participant profile. The first part of the questionnaire\nconsisted of collecting data that are related to the characteristics\nand opinions of the participants. The creation of the participant\nprofile through this data is important to make the selection of\npossible users of ModelGame. Without this profile, participants\nwith an inadequate profile may generate inconsistent assessments.\nParticipants were asked to provide more general information, such\nas age, education level, academic background. Information about\nthe time of experience in teaching was also considered, including\nteaching software modeling and level of knowledge about UML\nmodels.\nPart 2: TAM questionnaire. The second part addressed ques-\ntions about the usability and acceptance of the technique, aiming\nto explore q3. To this end, this part of our questionnaire is based on\nthe technology acceptance model (TAM) [16]. This part contained\nnine questions, which were answered through the Likert Scale, in-\ncluding Totally Agree, Partially Agree, Neutral, Partially Disagree,\nand Totally Disagree. The questions formulated (Q) dealt with sev-\neral topics, including perceived ease of use (Q1-3), perceived utility\n(Q4-7), attitude towards use (Q8), and behavioral intention to use\n(Q9).\n5.3\nSelection of participants\nThe participants were selected based on the following criteria: in-\nstructors and/or professionals working in the teaching of software\nmodeling in higher education institutions in Brazil. Using this cri-\nterion, we sought to select participants with academic training\nand practical experience in teaching. This finite set of all possible\nparticipants represents the target population [13]. This popula-\ntion represents those people who are in a position to answer the\nquestions formulated and to whom the results of the survey apply\n[13]. In all, 19 people (n) answered the questionnaire. The partici-\npants were invited via e-mail to participate in the study and each\nof them previously received the explanation/training about the\nmodel proposed through the researcher and there was no doubt,\nthey could leave for the next step that consisted of completing the\nTAM questionnaire. We discussed the experimental process in the\nnext section.\n5.4\nExperimental Process\nFigure 3 presents the experimental process used in this study, which\nis composed of three phases discussed below:\nPhase 1: Presentation. It has an activity, presentation, in which\nthe researcher explained to the participants through a video detail\nabout the quality model. This process took place individually and\nin a standard way, where space was also made available for par-\nticipants to answer possible doubts about the proposed study and\nmodel, lasting an average of 20 minutes.\nPhase 2: Application of the TAM questionnaire. It has two\nactivities, the first being Collect demographic data. The participants\nanswered a list of questions (input) so that we could collect their\ncharacteristics and opinions about the ModelGame. The demo-\ngraphic data collected (output) became the result of this activity.\nThe second activity Apply TAM questionnaire (input). Participants\nreceived a list of questions about the perception of ease of use, per-\nceived utility, attitudes, and intention of behavior, in relation to the\nModelGame. Qualitative data (output) were generated, regarding\nthe usability and acceptance of the Model under the perspective\nof professionals who teach software modeling. This questionnaire\nfollowed the guidelines of the TAM [16].\nPhase 3: Analysis and result report. It has two activities. The\nfirst, Analyze data sought to perform a thorough analysis of the data\ncollected through the questionnaire and the researcher’s perception\nregarding the participants’ doubts during the presentation stage.\nFor this, the collected data were analyzed separately, as well as con-\nfronted, aiming to perform a triangulation of them. Subsequently,\nthere was an Evaluation data, as a way to understand in a more\ndepth the context, the perceptions of the participants in relation to\nthe proposed model as well as its applicability.\n<image: DeviceRGB, width: 590, height: 658, bpc: 8>Figure 3: The experimental process.\n5.5\nResult Analysis\n5.5.1\nProfile data of the participants. Table 3 describes the profile\ndata, reporting the characteristics and opinions of the participants.\nThese data were collected from May 18 to June 5, 2021. In total,\nwe had 19 participants. Our participants are between 20 and 49\nyears old, most of them have a degree in Computer Science (52.6%),\nInformation Systems (26.3%) or Systems Analysis (21.1%) and are\nspecialists (36.8%), masters (36.8%) and doctors (15.8%). About the\nworking time in teaching, the majority (42.1%) they have been teach-\ning for more than 8 years and teach disciplines related to software\nmodeling, including software engineering, systems analysis and\nsoftware projects. A total of 47.4% have a full level of knowledge\nabout UML and almost half of them (47.4%) has not yet used gamifi-\ncation in the teaching of software modeling. Therefore, we consider\n106\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nEd Wilson Júnior and Kleinner Farias\nTotally agree\nPartially agree\nNeutral\nPartially disagree\nTotally disagree\nPerceived ease of use\nI found the quality model easy to use\n8\n9\n2\n0\n0\nI found the quality model easy to learn\n10\n9\n0\n0\n0\nI found the quality model easy to master\n6\n12\n0\n1\n0\nPerceived usefulness\nThe model would make it easier to understand which elements of gamification can be used in modeling .\n12\n5\n2\n0\n0\nUsing the quality model would help increase productivity.\n9\n8\n2\n0\n0\nThe model would provide an understanding of how to mitigate the incompleteness of UML diagrams.\n5\n8\n5\n1\n0\nThe model would help compare theories about gamification in software modeling teaching.\n13\n4\n2\nAttitude towards use\nUsing the Quality Model for Gamified Software Modeling Learning is a good idea.\n13\n5\n1\n0\n0\nBehavioral intention to use\nI would use the quality model in software modeling classes.\n10\n7\n2\n0\n0\nTable 2: Collected data related to TAM questionnaire.\nthat although small, our sample is adequate to carry out an initial\nevaluation of the proposed approach.\nCharacteristic and Opinion (n=19)\nAnswer\n#\n%\nAge\n< 20 years\n0\n0.0%\n20-29 years\n4\n21.1%\n30-39 years\n8\n42.1%\n40-49 years\n5\n26.3%\n> 49 years\n2\n10.5%\nEducation\nUndergraduate*\n0\n0.0%\nSpecialization*\n7\n36.8%\nMaster*\n7\n36.8%\nPhD*\n3\n15.8%\nOthers\n2\n10.6%\nUndergraduate course\nInformation Systems\n5\n26.3%\nComputer Science\n10\n52.6%\nComputer Engineering\n0\n0.0%\nSystem Analysis\n4\n21,1%\nOthers\n0\n0.0%\nTime of experience in teaching\n< 2 years\n4\n21.1%\n2-4 years\n2\n10.5%\n5-6 years\n3\n15.8%\n7-8 years\n2\n10.5%\n> 8 years\n8\n42.1%\nExperience in teaching\n< 2 years\n3\n15.8%\nsoftware modeling\n2-4 years\n5\n26.3%\n5-6 years\n3\n15.8%\n7-8 years\n2\n10.5%\n> 8 years\n6\n31,6%\nLevel of knowledge\nBeginner\n2\n10.5%\nabout UML models\nJunior\n5\n26.3%\nFull\n9\n47.4%\nSenior\n3\n15.8%\nUsed gamification in teaching\nYes\n9\n47.4%\nNo\n9\n47,4%\nMaybe\n1\n5.3%\nGamification can contribute to the quality\nTotally agree\n10\n52.6%\nof the models of UML diagrams generated\nPartially agree\n8\n42.1%\nby students\nNeutral\n1\n5.3%\nPartially disagree\n0\n0.0%\nTotally disagree\n0\n0.0%\nTable 3: The profile data of the participants.\n5.5.2\nRQ1: How do instructors evaluate the use of gamification in\nsoftware modeling? Table 3 presents the collected data related to\nthe RQ formulated. First, we begin the analysis by verifying how\ninstructors visualize gamification in software modeling teaching.\nAlthough most of them (47.4%) have not yet used gamification\nelements (scores, challenge, emblem, among others) in their classes,\nmost (52.6%) totally agree and (42.1%) partially agree that the use\nof these can contribute to the quality of the models developed by\nthe students.\nWe consider the percentage of instructors who have not yet\nused gamification in their classes to be high and this may be tied\nto factors such as lack of knowledge, information about the tool,\nand even time to plan and include these approaches [22]. Although\nthey were based on software modeling teaching context, previous\nstudies [3, 4, 12, 17, 25] they did not count on the participation of\ninstructors and we understand that this participation is fundamental\nto understand the perceptions of these professionals since they will\nbe at the forefront of the use of gamification.\nThe ModelGame proposed in this study could help them insert\ngamification into their classes, according to the software modeling\nlearning design [25], based on the assumption that for this, it is\nnecessary to develop a better understanding of the tasks, activities,\nskills and operations that the different elements of gamification can\noffer and how they can correspond to the desired learning outcomes\nby developing a more concrete and motivating presentation that\ncan involve students and facilitate deep learning with UML.\n<image: DeviceRGB, width: 562, height: 223, bpc: 8>5.5.3\nRQ2: What is the acceptance of the ModelGame by software\nmodeling instructors? Using the TAM questionnaire, we tried to\nevaluate the ease of use, perceived usefulness, attitude, and behav-\nioral intention to use the Quality Model. Table 2 shows the data\nobtained. Our data obtained show that no one disagreed that the\nModelGame is easy to use, learn, and master. On the contrary, al-\nmost 90% of participants find the model easy to use (42.1% totally\nagree and 47.4% partially agrees and 10.5% neutral), learn (52.6%\n107\nModelGame: A Quality Model for Gamified Software Modeling Learning\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nfully agree and 47.4% partially agree) and master (31.6% fully agree,\n63.2% partially agree and 5.3% partially disagree).\nThe results are also favorable considering the perception of util-\nity. Most participants realized that the ModelGame would make it\neasier to understand which elements of gamification can be used in\neach of the phases of modeling using UML(63.3% totally agree, 26.3%\npartially agree and 10.5% neutral), increase productivity (47.4% fully\nagree, 42.1% partially agree and 10.5% neutral), and the use of the\nquality model would provide an understanding of how to mitigate\nthe incompleteness of UML diagrams (26.3% agree totalmen 42.1%\npartially agree, 26.3% neutral and 5.3% partially disagree). Still in\nthe useful aspect, we tried to know if the quality model would help\nto compare validated theories about the inclusion of gamification\nin software modeling teaching (68.4% totally agree, 21.1% partially\nagree and 10.5% neutral).\nConsidering the attitude towards use, participants believe that\nusing the ModelGame is a good idea (68.4% totally agree, 26.3%\npartially agree and 5.3% neutral), just as they are confident and\nwould use the Model in software modeling classes (52.6% totally\nagree, 36.8% partially agree and 10.5% neutral). These findings show\nthe potential for acceptance by people with profiles similar to those\nof participants. The results are encouraging and show the potential\nto use the proposed approach in the educational scenario.\n<image: DeviceRGB, width: 562, height: 151, bpc: 8>6\nTHREATS TO VALIDITY\nThis section discusses the possible threats to the validity of the\nstudy.\nInternal validity. The main point affecting the internal validity\nof our study concerns the total time used for the exploratory phase.\nTo mitigate this threat, we performed the video recording of a pilot\nexplaining the operating details and objectives of the ModelGame.\nIn relation to the methods used, the threats related to internal\nvalidity relate to how we extract the perceptions of the discussions\nand whether they represent the perceptions of teachers about the\nuse of the Model. We try to reduce this threat by applying the TAM\nquestionnaire.\nExternal validity. We identified threats related to external va-\nlidity, such as the number of participants who never applied the use\nof gamification. This study was limited to 19 participants (teachers)\nfrom various educational institutions, of which 9 (47.4%) never used\nany element of gamification in their classes, this factor can interfere\nin the data, since the model intends to evaluate the quality of UML\ndiagrams from gamified activities.\nConclusion validity. Threats related to the validity of the con-\nclusion are related to treatment and outcome. We try to make the\nreduction by combining quantitative and qualitative data through\ndifferent resources. These data were obtained through audio and\nquestionnaires. We analyze this data to answer the research ques-\ntions.\n7\nCONCLUSIONS AND FUTURE WORK\nThis study proposed an initial quality model (ModelGame) that\nserves as a reference framework for instructors for qualitative eval-\nuations of UML models developed from gamified activities, the\napplication of an empirical study with 19 participants was carried\nout to understand their vision in relation to gamification and the\nacceptance of the proposed Model. It was identified that most have\nnot yet used gamification in their classes, but agree that their use\ncan contribute to the quality of the models developed by the stu-\ndents and were open to using the model. Our findings can enhance\nthe adoption of new teaching practices through gamification, result-\ning in the improvement of software modeling learning using UML,\nand consequently the creation of models developed by students.\nThese approaches can stimulate students’ immersion in the design\nof systems as future professionals during learning.\nFinally, we hope to carry out in the future a series of experimental\nstudies to analyze each stage of application of the ModelGame\nand that this work represents a first step to better support the\napplication of empirical studies on models of evaluation of the\nuse of gamification in software modeling. We also hope that the\nquestions described throughout the article will encourage other\nresearchers to extend our study to different modeling languages\nand teaching methodologies.\n",
            "pdfUrl" : "",
            "reference" : "[1] Rick Adcock, Edward Alef, Bruce Amato, Mark Ardis, Larry Bernstein, Barry\nBoehm, Pierre Bourque, John Brackett, Murray Cantor, Lillian Cassel, et al. 2009.\nCurriculum guidelines for graduate degree programs in software engineering. ACM.\n[2] Mark Ardis, David Budgen, Gregory W Hislop, Jeff Offutt, Mark Sebern, and\nWillem Visser. 2015. SE 2014: Curriculum guidelines for undergraduate degree\nprograms in software engineering. Computer 48, 11 (2015), 106–109.\n[3] Valerio Cosentino, Sébastien Gérard, and Jordi Cabot Sagrera. 2017. A model-\nbased approach to gamify the learning of modeling. CEUR Workshop Proceed-\nings.\n[4] Daniel de Paula Porto, Gabriela Martins de Jesus, Fabiano Cutigi Ferrari, and\nSandra Camargo Pinto Ferraz Fabbri. 2021. Initiatives and challenges of using\ngamification in software engineering: A Systematic Mapping. Journal of Systems\nand Software 173 (2021), 110870.\n[5] Sebastian Deterding, Miguel Sicart, Lennart Nacke, Kenton O’Hara, and Dan\nDixon. 2011. Gamification. using game-design elements in non-gaming contexts.\nIn CHI’11 extended abstracts on human factors in computing systems. 2425–2428.\n[6] Ana Fernández-Saez et al. 2012. A systematic literature review on the quality of\nUML models. J. Data. Manage 22, 3 (2012), 46–70.\n[7] Kleinner Farias et al. 2012. Evaluating the impact of aspects on inconsistency\ndetection effort: a controlled experiment. In International Conference on Model\nDriven Engineering Languages and Systems. Springer, 219–234.\n[8] Kleinner Frias et al. 2014. Towards a quality model for model composition effort.\nIn 29th Annual ACM Symposium on Applied Computing. 1181–1183.\n[9] Kleinner Farias et al. 2015. Evaluating the effort of composing design models: a\ncontrolled experiment. Software & Systems Modeling 14, 4 (2015), 1349–1365.\n[10] Kleinner Farias et al. 2019. UML2Merge: a UML extension for model merging.\nIET Software 13, 6 (2019), 575–586.\n[11] Juho Hamari, Jonna Koivisto, and Harri Sarsa. 2014. Does gamification work?–\na literature review of empirical studies on gamification. In 2014 47th Hawaii\ninternational conference on system sciences. Ieee, 3025–3034.\n[12] Mantas Jurgelaitis, Vaidotas Drungilas, and Lina Čeponien˙e. 2018. Gamified\nMoodle course for teaching UML. Baltic journal of modern computing 6, 2 (2018),\n119–127.\n[13] Barbara A Kitchenham and Shari L Pfleeger. 2008. Personal opinion surveys. In\nGuide to advanced empirical software engineering. Springer, 63–92.\n[14] Christian Franz Josef Lange. 2007. Assessing and Improving the Quality of\nModeling: A series of Empirical Studies about the UML. (2007).\n[15] Odd Ivar Lindland, Guttorm Sindre, and Arne Solvberg. 1994. Understanding\nquality in conceptual modeling. IEEE software 11, 2 (1994), 42–49.\n[16] Nikola Marangunić and Andrina Granić. 2015. Technology acceptance model: a\nliterature review from 1986 to 2013. Universal access in the information society\n14, 1 (2015), 81–95.\n108\nSBCARS ’21, September 27-October 1, 2021, Joinville, Brazil\nEd Wilson Júnior and Kleinner Farias\n[17] Beatriz Marín. 2021. Lessons Learned About Gamification in Software Engineer-\ning Education. In Latin American Women and Research Contributions to the IT\nField. IGI Global, 174–197.\n[18] Kleinner Oliveira, Alessandro Garcia, and Jon Whittle. 2008. On the quantitative\nassessment of class model compositions: An exploratory study. 1th ESMDE at\nMODELS (2008).\n[19] OMG.\n2017.\nUML:\nInfrastructure\nspecification.\nhttps://www.omg.org/spec/UML/2.5.1/PDF.\n[20] Sofia Ouhbi and Nuno Pombo. 2020. Software Engineering Education: Challenges\nand Perspectives. In IEEE Global Engineering Education Conference. 202–209.\n[21] Oscar Pedreira, Félix García, Nieves Brisaboa, and Mario Piattini. 2015. Gamifica-\ntion in software engineering–A systematic mapping. Information and software\ntechnology 57 (2015), 157–168.\n[22] Pedro Rodrigues, Mauricio Souza, and Eduardo Figueiredo. 2018. Games and\ngamification in software engineering education: A survey with educators. In 2018\nIEEE Frontiers in Education Conference (FIE). IEEE, 1–9.\n[23] Kevin Werbach and Dan Hunter. 2012. For the win: How game thinking can\nrevolutionize your business. Wharton digital press.\n[24] Claes Wohlin, Per Runeson, Martin Höst, Magnus C Ohlsson, Björn Regnell, and\nAnders Wesslén. 2012. Experimentation in software engineering. Springer Science\n& Business Media.\n[25] Alfa Yohannis. 2016. Gamification of Software Modelling Learning.. In DS@\nMoDELS.\n109\n",
            "keyWords" : "Model design, learning model, Gamification\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "21",
          "_score" : 1.0,
          "_source" : {
            "title" : "The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development",
            "samary" : "Large language models (LLMs) have recently been applied in soft-ware engineering to perform tasks such as translating code betweenprogramming languages, generating code from natural language,and autocompleting code as it is being written. When used withindevelopment tools, these systems typically treat each model in-vocation independently from all previous invocations, and only aspecific limited functionality is exposed within the user interface.This approach to user interaction misses an opportunity for usersto more deeply engage with the model by having the context oftheir previous interactions, as well as the context of their code,inform the model’s responses. We developed a prototype system– the Programmer’s Assistant – in order to explore the utility ofconversational interactions grounded in code, as well as softwareengineers’ receptiveness to the idea of conversing with, rather thaninvoking, a code-fluent LLM. Through an evaluation with 42 partici-pants with varied levels of programming experience, we found thatour system was capable of conducting extended, multi-turn discus-sions, and that it enabled additional knowledge and capabilitiesbeyond code generation to emerge from the LLM. Despite skepti-cal initial expectations for conversational programming assistance,participants were impressed by the breadth of the assistant’s capa-bilities, the quality of its responses, and its potential for improvingtheir productivity. Our work demonstrates the unique potential ofconversational interactions with LLMs for co-creative processeslike software development.",
            "authors" : "Steven I. Ross\nIBM Research AI\nCambridge, MA, USA\nsteven_ross@us.ibm.com\nFernando Martinez\nIBM Argentina\nLa Plata, Buenos Aires, Argentina\nmartferc@ar.ibm.com\nStephanie Houde\nIBM Research AI\nCambridge, MA, USA\nStephanie.Houde@ibm.com\nMichael Muller\nIBM Research AI\nCambridge, MA, USA\nmichael_muller@us.ibm.com\nJustin D. Weisz\nIBM Research AI\nYorktown Heights, NY, USA\njweisz@us.ibm.com\n",
            "institutions" : "",
            "integralText" : "1\nINTRODUCTION\nSoftware development is a highly skilled task that requires knowl-\nedge, focus, and creativity [27, 28]. Many techniques have been\ndeveloped to enhance the productivity of software engineers, such\nas advanced code repositories [86], knowledge repositories [39],\nQ&A sites [1], and pair programming practices [18]. Collaborative\nsoftware engineering is especially promising, given that profes-\nsional software development is rarely a solo activity and relevant\nknowledge and expertise are typically distributed widely within an\norganization [68]. Many efforts have focused on incorporating col-\nlaborative technologies into software development environments\n(e.g. [8, 25, 26, 58, 101]).\nThe pioneering work of Rich and Waters on The Programmer’s\nApprentice [70] presented a novel concept of a knowledgeable auto-\nmated assistant – in effect, an artificial collaborative partner – that\ncould help software engineers with writing code, designing soft-\nware systems, and creating requirements specifications. At the time,\nAI technologies and computing resources were not sufficient to\nfully implement their vision. In the intervening years, an increase in\ncomputational power, the availability of large corpora of language\nand code data, and the development of deep neural networks have\nmade new approaches to achieving their goals worth exploring.\nRecently, models leveraging the transformer architecture [96]\nhave been developed to perform domain-specific software engi-\nneering tasks, such as translating code between languages [75],\ngenerating documentation for code [36, 38, 97, 98], and generating\nunit tests for code [92] (see Talamadupula [90] and Allamanis et al.\n[5] for surveys). Recently developed foundation models – large\nlanguage models that can be adapted to multiple tasks and which\nexhibit emergent behaviors for which they have not been explic-\nitly trained [14] – have also proven to be capable with source code.\n491\n<image: CalRGB, width: 1003, height: 1004, bpc: 8>IUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\nWhile the intent of training LLMs such as GPT-2 [64] and GPT-3 [17]\nwas to give them mastery of natural language, it quickly became\napparent that the presence of code in their training corpora had\ngiven them the ability to generate code based on natural language\ndescriptions [49]. The Codex model [24] was then produced by fine-\ntuning GPT-3 on a large corpus of source code data, leading to the\ndevelopment of Copilot [32], a tool that helps software engineers by\nautocompleting code as it is being written. Experimentation with\nCopilot has shown its ability to perform additional tasks, such as\nexplaining code, generating documentation, and translating code\nbetween languages [6].\nAlthough autocompletion interfaces are useful and valuable\nwhen the system can discern the developer’s intent, there are many\ninstances where that is insufficient. For example, the developer\nmay have a good idea of what they want to do, but may be unclear\non what functions, libraries, or even algorithms to employ. They\nmay even have general programming questions that need to be\nanswered before they are able to write any code.\nIn this paper, we seek to understand whether modern develop-\nments in code-fluent foundation models – large language models\nthat have been fine-tuned on source code data – are sufficient to\nsupport a conversational agent that can act as an assistant in the\nsoftware development process. We developed the Programmer’s\nAssistant to explore the capabilities that conversational interaction\ncould enable and the extent to which users would find conversa-\ntional assistance with programming tasks desirable and useful.\nWe hypothesize that a conversational system may provide a\nflexible and natural means for interacting with a code-fluent LLM.\nConversational interaction could enable users to pursue their ques-\ntions in a multiple exchange dialog (as observed by Barke et al.\n[13]) that allows them to ask follow-up questions and refine their\ninquiries. A conversational programming assistant could ask the\nuser clarifying or disambiguating questions to help it arrive at the\nbest answer. It could also provide multiple types of assistance to\nthe user beyond simply generating code snippets, such as engaging\nin general discussion of programming topics (e.g. [22, 71]) or help-\ning users improve their programming skills (as observed in other\nstudies of automating technologies [99]).\nOur paper makes the following contributions to the IUI commu-\nnity:\n• We provide empirical evidence that a conversational pro-\ngramming assistant based on a state-of-the-art, code-fluent\nfoundation model provides valuable assistance to software\nengineers in a myriad of ways: by answering general pro-\ngramming questions, by generating context-relevant code,\nby enabling the model to exhibit emergent behaviors, and by\nenabling users to ask follow-up questions that depend upon\ntheir conversational and code contexts.\n• We show how different interaction models – conversation,\ndirect manipulation, and search – provide complementary\ntypes of support to software engineers with tradeoffs be-\ntween the user’s focus and attention, the relevance of sup-\nport to their code context, the provenance of that support,\nand their ability to ask follow-up questions.\n• We motivate the need to further understand how to design\nhuman-centered AI systems that enhance the joint perfor-\nmance of the human-AI collaboration.\n2\nRELATED WORK\nWe discuss three areas of related work that have either motivated\nour study of conversational programming assistance or provided\nthe technical foundations for it. We begin by briefly summarizing\nRich and Waters’ visionary work on the Programmer’s Appren-\ntice [70], followed by summarizing work on code-fluent foundation\nmodels and human-centered evaluations of how these models im-\npact software engineers’ work. Finally, we discuss conversational\ninteraction and how it might be employed to provide more flexible\nand sophisticated assistance to software engineers.\n2.1\nThe Programmer’s Apprentice\nOur work is inspired by the vision laid out by Rich and Waters [70],\nwhich describes an artificial agent that can act as an intelligent as-\nsistant for software engineers by providing advice, catching errors,\nand handling routine details throughout the software development\nprocess. The Programmer’s Apprentice [70] relied on a knowledge\nbase of “clichés,” which are formal, structured versions of what\nare known today as software design patterns [31]. It used a hy-\nbrid reasoning system capable of special-purpose reasoning based\non frames and a plan calculus, along with general purpose logical\nreasoning. Although natural language interaction was envisioned,\nthe original prototype implementation ultimately used a stylized\ncommand language. We view our work as a conceptual successor\nto the Programmer’s Apprentice, as it enables the natural language\ninteraction that the Programmer’s Apprentice lacked.\n2.2\nCode-fluent Foundation Models and\nHuman-Centered Evaluations of\nProgramming Assistance\nGenerative models based on the transformer architecture [96] have\nrecently been applied to the domain of software engineering. Code-\nfluent large language models are capable of generating code from\nnatural language descriptions [105], translating code from one lan-\nguage to another [75], generating unit tests [92], and even gener-\nating documentation for code [36, 38, 97, 98]. These models are\nprobabilistic systems, and as such, do not always produce perfect\nresults (e.g. code that is free of syntax or logical errors). Nonetheless,\nWeisz et al. [102] found that software engineers are still interested\nin using such models in their work, and that the imperfect outputs\nof these models can even help them produce higher-quality code\nvia human-AI collaboration [103].\nNew tools based on code-fluent LLMs are actively being devel-\noped. GitHub Copilot1 is described as “Your AI pair programmer.” It\nis optimized for the code autocompletion use case: given a starting\nsnippet such as a method’s documentation, signature, or partial\nimplementation, Copilot completes the implementation. Copilot is\nbased on the OpenAI Codex model [24], a 12 billion parameter ver-\nsion of GPT-3 [17, 49], fine-tuned on code samples from 54 million\npublic software repositories on GitHub. Empirical evaluations of\n1https://github.com/features/copilot\n492\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nthis model have shown that, although the quality of its outputs is\nquite good, those outputs may still be problematic [57]. Echoing the\nresults from Weisz et al. [103], human-centered evaluations of Copi-\nlot have found that it increases users’ feelings of productivity [109],\nand that almost a third (27%) of its proposed code completions were\naccepted by users. In a contrasting evaluation, Vaithilingam et al.\n[95] found that while most participants expressed a preference\nto use Copilot in their daily work, it did not necessarily improve\ntheir task completion times or success rates. Yet, in a study by\nKalliamvakou [40], developers working with Copilot were able to\nimplement a web server in Javascript 55% faster than developers\nwho did not use Copilot.\nA grounded theory analysis of how programmers interact with\nCopilot [13] found that their interactions varied depending upon\nwhether they were accelerating tasks that they already knew how\nto do or if they were exploring solutions to problems that they were\nless sure about. Autocompletion was effective when developers\nwere operating in “acceleration mode” and relied on the model\nto produce short completions that could be verified quickly. In\n“exploration mode,” however, the interaction was more awkward.\nDevelopers would communicate with Copilot by typing comments\nand seeing what Copilot generated in response. Then, they would\nmodify their comments to explore other ways of prompting a re-\nsponse. Ultimately, the comments used to prompt the model would\nbe deleted after the relevant code was generated, indicating that\ntheir value was largely in driving a back-and-forth, yet context free,\ndialog with the model to coerce it to produce the desired results\nthrough an iterative refinement process. In this paper, we fully\ncommit to a context-aware conversational style of interaction with\na code-fluent LLM and assess the value it provides to users.\n2.3\nConversational Interaction and Analysis\n2.3.1\nConversational Interaction. Using natural language to inter-\nact with technology has had a long research history [2], starting in\nthe 1960s with pattern-matching approaches like Eliza [104], and\ncontinuing to today with state-of-the-art large language model-\nbased conversational systems [107] such as Meena [3] and Blender-\nBot [84]. These systems are intended to address the problem of\nopen-domain dialog, with a goal of realistically engaging in con-\nversation, but not particularly in a goal-directed or task-oriented\nmanner.\nTask-oriented chatbots are typically built with frameworks such\nas the Microsoft Bot Framework2, Google DialogFlow3, and IBM\nWatson Assistant4. They operate using pre-defined dialogue trees\nand use natural language processing to detect conversational intents\nand extract contextual entities. This structure enables the creation of\nspecial purpose, but fairly limited and rigid, conversational agents.\nThere have been several recent attempts to investigate conver-\nsational programming assistance. Kuttal et al. [42] conducted a\nWizard of Oz study in which a pair programmer was replaced with\na conversational agent, and they found that “agents can act as ef-\nfective pair programming partners.” The PACT system [106] is a\nchatbot that assists programmers adjusting to new programming\n2https://dev.botframework.com/\n3https://cloud.google.com/dialogflow\n4https://www.ibm.com/products/watson-assistant/artificial-intelligence\nenvironments. PACT is structured as a discrete question-answering\nsystem based on a neural machine translation approach, but it\ndoesn’t maintain a conversational context.\n2.3.2\nConversation Analysis. Conversation is a form of interaction\nbetween people that enables robust communication. Conversation\nAnalysis [76] is a method for understanding the natural structure\nof human conversational interaction. It catalogs different patterns\nof conversational acts and how they are utilized by interlocutors in\norder to attain a wide variety of goals. Recently, Conversation Anal-\nysis has been adapted to describe patterns of interactions between\nhumans and artificial conversational agents in order to aid in the\ndesign of chatbots [50]. We apply techniques from Conversation\nAnalysis in our study of conversational programming assistance.\n3\nTHE PROGRAMMER’S ASSISTANT\nIn order to explore conversational programming assistance, we\ncreated a functional prototype system called The Programmer’s\nAssistant. Our prototype, shown in Figure 1, combines a code editor\nwith a chat interface. The code editor was implemented using the\nMicrosoft Monaco Editor5 embedded in a React wrapper6. The\nchat user interface was implemented using the React-Chatbot-Kit7\nframework. To drive the conversational interaction, we employed\nOpenAI’s Codex model [24], accessed through its web API.\nWe developed our prototype as a lightweight coding environ-\nment in order to examine the user experience of interacting with\na conversational assistant. Our work was exploratory in nature,\nand thus we did not have specific design goals for the prototype\nbeyond integrating a code editor with a code-fluent LLM. We also\ndid not attempt to target the prototype for a specific class of users\n(e.g. novices or experts) or use cases (e.g. writing code vs. learning a\nnew programming language), as we wanted any value provided by\nconversational assistance to emerge from our user study. We also\ndid not implement the ability to run or debug code in our prototype\nas we wanted to explore the nature of the conversational interac-\ntion rather than having users focus extensively on the production\nof working code.\nWhen designing how users would interact with the Program-\nmer’s Assistant, we decided that it should be available on demand\nand not monitor the user’s work in progress or give unsolicited\nsuggestions or advice, in keeping with the conversational agent\ninteraction model proposed by Ross et al. [73, 74]. This approach\nwas supported by feedback from prospective users who were con-\ncerned about the assistant providing criticism of unfinished efforts\nin progress or distracting them while they worked. Instead, we\nforce initiative onto the user and only have the assistant respond\nto their requests. In this way, the assistant can provide help when\nrequested without undesirable interruptions that can distract or\ninterfere with the user’s flow.\nWhen a user interacts with the assistant, we keep track of their\nselection state in the code editor. If a user sends a message to the\nassistant without any code selected in the editor, then that message\n(along with the prior conversational context) is passed directly to\nthe model. If a user sends a message to the assistant with new code\n5https://microsoft.github.io/monaco-editor/\n6https://www.npmjs.com/package/@monaco-editor/react\n7https://fredrikoseberg.github.io/react-chatbot-kit-docs/\n493\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\nselected in the editor (i.e. code that wasn’t previously selected when\nthey sent their last message), then that code is appended to the\nmessage before being communicated to the model.\nThe model may produce multiple types of responses to a user’s\nmessage. We treat each type of response differently in the UI.\n• Responses that do not contain code are always rendered in\nthe chat UI (Figure 1E).\n• Responses containing short code snippets (≤ 10 lines) are\nrendered inline in the chat UI (Figure 1G).\n• Responses containing longer code snippets (> 10 lines) show\nthe code in a pop-up window (Figure 2A), with a proxy entry\nin the chat transcript (Figure 2B) that allows users to re-\ndisplay the code window after it has been closed. Non-code\ntext in the response remains in the chat transcript.\nThe assistant never directly modifies the contents of the user’s\nsource code; rather, any code the user desires to transfer from the\nchat takes place via copy/paste.\nFigure 1 shows a screenshot of a real, sample conversation, in\nwhich the user asks a question that results in an inline response,\nthen requests an explanation of some code in the editor, and then re-\nquests further elaboration. Figure 2 shows an example conversation\nthat resulted in the generation of a longer code sample, shown in a\npopup window. This example shows how the assistant produced an\nincomplete solution, followed by criticism from the user regarding\nthe missing code, and resulting in an apology and the generation\nof a complete solution.\n3.1\nSupporting Conversational Interaction\nWe enabled Codex to conduct a conversational interaction by prompt-\ning it with a conversational transcript and a request to produce\nthe next conversational turn. The prompt establishes a pattern of\nconversation between a user and a programming assistant named\nSocrates. It provides several examples of Socrates responding to gen-\neral coding questions, generating code in response to a request, and\naccepting code as input. It establishes a convention for delimiting\ncode in the conversation, making it easy to parse for display in the\nUI. It also establishes an interaction style for the assistant, directing\nit to be polite, eager, helpful, and humble, and to present its re-\nsponses in a non-authoritative manner8. Because of the possibility\nthat the model might produce erroneous answers or incorrect code\n(as discussed in Weisz et al. [102]), we felt it was important that the\nassistant convey a sense of uncertainty to encourage users to not\naccept its results uncritically to avoid over-reliance (e.g. as observed\nin Moroz et al.’s study of Copilot [51], and discussed more gener-\nally in Ashktorab et al. [9]) as well as automation bias [45, 46, 65].\nWe present the full text of the prompt used for the assistant in\nAppendix D.\n3.2\nArchitecture & UI Design\nThe Programmer’s Assistant communicates with the Codex API via\na proxy server that forwards requests from the React client. The\nproxy also rate-limits access to conform to the API’s policy, and\nit logs UI events from the client (e.g. requests, responses, and UI\n8The assistant’s use of non-authoritative responses was encoded into the LLM prompt;\noutput token probabilities from the LLM were not utilized to influence the assistant’s\nresponse.\ninteractions) in a back-end database. To address inconsistencies\nin the style or formatting of code generated by Codex, the proxy\nserver reformats all code segments using the Black code formatter\n9 before transmitting them to the client UI.\nThe client maintains the transcript of the ongoing conversation.\nEach time the user sends a message in the chat, the client constructs\na new prompt for the model by concatenating the initial prompt,\nthe chat transcript, and the user’s new utterance, and makes a re-\nquest for the model to complete the transcript. This completion\nrequest also specifies a stop sequence of tokens to prevent the\nmodel from generating both sides of the conversation (e.g. what\nthe model thinks the user’s next utterance might be after the as-\nsistant’s response). Given the API’s limitation on context length\n(4,096 tokens for both the prompt and model response), we silently\n“forget” older exchanges in the chat transcript when constructing\nthe prompt to ensure that our completion request remains within\nbounds. Nonetheless, the entire conversational history remains\nvisible to the user in the UI.\nThe client UI provides a loose coupling between the source code\neditor and the chat interface. Users can hide the chat pane when\nthey wish to focus solely on their code, and re-engage with it\nwhen they desire assistance. Code selected in the editor is included\nin the conversation in order to couple the code context with the\nconversation. Easily-accessible buttons are provided in the UI to\ncopy code responses from the assistant to the clipboard.\n3.3\nHandling Model Limitations\nWhile developing the Programmer’s Assistant, and in early pilot\ntesting, we experienced some quirks and shortcomings of the model\nand our approach to using it for conversational interaction. One\nlimitation stemmed from the fact that the model sometimes pro-\nduced incorrect responses (e.g. code with syntax errors), incomplete\nresponses (e.g. code that was missing functionality), irrelevant re-\nsponses (e.g. responses not related to the user’s question), or insub-\nstantial responses (e.g. “I don’t know”). Because of the probabilistic\nnature of model inference, re-prompting the model would some-\ntimes produce a more correct or appropriate response. Thus, we\nadded the ability for users to “try again,” either by asking in the chat\nor by clicking a button in the UI (Figure 1C). This feature removes\nthe assistant’s last response from the context presented to the model\nand then re-invokes the model with an increased temperature10.\nAlthough it is possible for transformer models such as Codex to\nproduce multiple possible responses to a single prompt, we only\nrequest a single response in order to speed up response time as\nwell as to preserve the token budget for conversational context.\nThus, the “try again” feature provides an alternate way to produce\na wider variety of responses.\nDuring pilot testing, we noticed that the assistant sometimes\nhappened to generate the same response to multiple, unrelated re-\nquests. In these cases, the assistant tended to get “stuck” in a pattern\nof repeating the same response and was unable to resume normal\nconversation. To avoid this problem, we automatically execute a\n9https://black.readthedocs.io/en/stable/\n10Temperature is a parameter in a generative model that specifies the amount of\nvariation in the generation process. Higher temperatures result in greater variability\nin the model’s output.\n494\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\n<image: ICCBased(RGB,C27F398), width: 1397, height: 963, bpc: 8>A\nB\nH\nG\nF\nE\nC\nD\nFigure 1: The Programmer’s Assistant. The user interface provides a code editor on the left (A) and a chat pane on the right (B).\nThe “try again” button (C) allows users to ask the assistant to generate an alternate response to the most recent question. The\n“start over” button (D) resets the conversational context for the assistant, but maintains the chat transcript in the UI. In this\nexample, we show the assistant introduce itself to the user (E). Next, the user asks a general programming question (F), for\nwhich the assistant provides an inline code response (G). The user then asks a question about code selected in the editor (H),\nfollowed by a series of follow-up questions.\n“try again” operation in the background when we see identical\nconsecutive responses from the assistant.\nFinally, we noticed that the accumulation of conversational con-\ntext sometimes resulted in the assistant becoming fixated on some\nportion of the earlier conversation. For example, it might respond\nto a question with portions of the prompt or of earlier conversation,\nand become less responsive to newer requests. To address this issue,\nwe introduced a “start over” feature, accessible via the chat or by\nclicking a button in the UI (Figure 1D), that resets the context to the\noriginal prompt, forgetting the rest of the conversational history.\nWe preserve the chat transcript in the UI, but delineate the break in\nthe assistant’s memory with an annotation in the chat transcript.\nThese annotations are added both for “try again” and “start over.”\n3.4\nSample Conversation\nWe provide a real sample conversation with the Programmer’s\nAssistant in Listing 1. This conversation begins with the assistant\ngreeting the user (line 1). Next, the user asks a general Python\nprogramming question (line 4), to which the assistant responds with\na non-authoritative remark (“I think...”) and a code snippet (line\n9). The user next asks a follow-up question that depends on their\nprevious question and the assistant’s response (line 11), to which\nthe assistant provides another code snippet (line 15), satisfying the\nuser’s request.\nThe user then switches topics and asks the assistant to write\na Fibonacci function (line 17), and the assistant again responds\nwith a non-authoritative remark (“I will give it a try,” line 20) and\na block of code. The user then asks how the function works (line\n30) and the assistant provides an adequate description (line 32).\n495\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\n<image: DeviceRGB, width: 1440, height: 1015, bpc: 8>Figure 2: Code Preview. Long code responses (> 10 lines) are presented in a pop-up window (A), with a button to copy the code\nand close the window. This code can be re-accessed from the chat transcript by clicking the proxy icon (B).\nNext, the user asks the assistant to re-implement the function in a\ndifferent way (line 37), again leveraging the ability to ask follow-up\nquestions. The assistant produces an alternative implementation\nthat conforms to the user’s request (line 41). The user follows up\nwith a question that depends on multiple past utterances and re-\nsponses in the chat transcript (line 47), and the assistant produces\na relevant response (line 49). The conversation closes with the user\nthanking the assistant (line 53) and the assistant acknowledging\ntheir gratitude (line 55).\nListing 1: A conversation with the Programmer’s Assistant.\nCode presented by the assistant is listed in bold face.\n1\nSocrates: Hello! My name is Socrates your programming\n2\nassistant.\nWhat can I help you with today?\n3\n4\nUser:\nHow do I get a list of the keys in a\n5\nPython dictionary?\n6\n7\nSocrates: I think you would do something like this:\n8\n9\nlist(my_dict.keys())\n10\n11\nUser:\nWhat if I just wanted to iterate over them?\n12\n13\nSocrates: I think you would do something like this:\n14\n15\nfor key in my_dict:\n16\n17\nUser:\nWrite a function that returns the nth value\n18\nin the Fibonacci sequence.\n19\n20\nSocrates: I will give it a try.\n21\n22\ndef fib(n):\n23\nif n == 0:\n24\nreturn 0\n25\nelif n == 1:\n26\nreturn 1\n27\nelse:\n28\nreturn fib(n - 1) + fib(n - 2)\n29\n30\nUser:\nHow does this work?\n31\n32\nSocrates: The Fibonacci sequence is defined by the\n33\nrecurrence relation F(n) = F(n-1) + F(n-2).\n34\nThis function implements that recurrence\n35\nrelation.\n36\n37\nUser:\nCan this be done without recursion?\n38\n496\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\n39\nSocrates: I think so. How about this?\n40\n41\ndef fib(n):\n42\na,b = 0,1\n43\nfor i in range(n):\n44\na,b = b,a+b\n45\nreturn\n46\n47\nUser:\nWhich version is better?\n48\n49\nSocrates: I think the recursive version is more\n50\nelegant , but the iterative version is more\n51\nefficient.\n52\n53\nUser:\nThanks!\n54\n55\nSocrates: You 're welcome!\n4\nEMPIRICAL STUDY OF CONVERSATIONAL\nPROGRAMMING ASSISTANCE\nWe conducted an empirical user study of the Programmer’s Assis-\ntant to assess whether conversational assistance provides value in\na software engineering context11. Our inquiry focused on the user\nexperience and value of conversational interactions grounded in\ncode. We therefore designed a qualitative study to investigate atti-\ntudes toward a conversational programming assistant: do people\nenjoy interacting conversationally, what kinds of questions do they\nask, and how does the experience compare to other forms of pro-\ngramming support such as searching the web? We note that prior\nstudies (e.g. [103, 105, 109]) conducted quantitative examinations\nof the use of LLMs in code work; our study is akin to Weisz et al.’s\nqualitative examination of software engineers’ attitudes toward\nworking with models that may fail to produce working code [102].\nTo address our questions, we deployed the Programmer’s Assis-\ntant within our organization – a global technology company – and\ninvited people to try it out and give us feedback on their experience.\nWe invited people with varying levels of programming skill in order\nto obtain a wide range of feedback on the kinds of use cases for\nwhich the tool could provide assistance.\n4.1\nTasks\nWe set up the Programmer’s Assistant as a playground environment\nthat participants could try out with a few sample programming\nproblems. We created a tutorial to orient participants to the assis-\ntant, its capabilities, and how to interact with it. We also created\nfour programming challenges focused on writing code, document-\ning code, and writing tests for code. We designed these challenges\nto expose participants to a broad range of the assistant’s capabilities.\nFor each of these challenges, we explicitly did not evaluate metrics\nsuch as the participant’s productivity, the quality of their solutions,\nor the time taken to produce them, as the focus of our study was to\nunderstand the utility of conversational interaction. We selected\nPython as the language used for the tutorial and challenges because\nof its general popularity [21] and the fact that it was well-supported\nby our underlying LLM [24].\n4.1.1\nTutorial. All participants were first introduced to the Pro-\ngrammer’s Assistant through a tutorial. The tutorial walked each\n11For historical context, we note that our study was completed before the public\nrelease of ChatGPT [60], which has subsequently demonstrated the application of\nconversational assistance for programming tasks [34].\nparticipant through 10 sample interactions to give them a feeling\nfor what the assistant could do and how to interact with it. The\ntutorial demonstrated how to ask questions, how to request code to\nbe generated, and how to evaluate existing code. It did not specifi-\ncally cover how to generate documentation or unit tests. Tutorial\ninstructions were provided within the code editor. We include the\nspecific text used for the tutorial in Appendix B.\n4.1.2\nProgramming Challenges. After completing the tutorial, par-\nticipants unlocked four programming challenges. Two of the chal-\nlenges involved coding problems (writing a queue class and writing\ncode to create a scatterplot of data in a CSV file), one involved doc-\numenting a given function (an implementation of a graph search\nalgorithm), and one involved writing unit tests for a given func-\ntion (computing the greatest common divisor of two arguments).\nAlthough the Programmer’s Assistant was visible and available for\nuse, we provided no specific requirement that it actually be used to\ncomplete the challenges.\nAfter participants completed their solution to a challenge, they\nsubmitted it by clicking a button in the UI. The code editor used\nin the Programmer’s Assistant was not a fully-functional IDE and\ndid not provide syntax checking or the ability to run, test, or debug\ncode. Due to these limitations, participants were asked to submit\ntheir solutions when they felt they had completed the challenge to\ntheir own satisfaction.\n4.2\nParticipants\nTo recruit participants for our study, we posted internal advertise-\nments in various communications channels focused on software\nengineering. Our advertisements stated that we were evaluating a\nconversational programming assistant, but were kept deliberately\nvague in order to minimize the impact on peoples’ expectations of\nthe experience.\nOur advertisement yielded a pool of 140 potential participants.\nIn order to recruit a diverse sample, we used a screening survey\nthat asked about their job role, their familiarity with and recency\nof use of Python, and their availability to participate in our study.\nWe accepted participants into the study on a rolling basis, selecting\nparticipants to capture a range of programming experiences and\nensure balanced gender representation. We conducted periodic re-\nviews to determine whether we were learning something new from\neach participant or if we had reached the point of saturation [7]. We\nstopped collecting data after running 42 participants as we were no\nlonger observing any new behaviors or gleaning any new insights.\nThe Programmer’s Assistant implementation and configuration\nwere held constant over the course of the study; no changes to the\nUI design or LLM prompt were made.\nOur participants had the following self-identified characteristics:\n• Job role: 19 Software Engineers, 12 Researcher/Scientists, 3\nSoftware Architects, 2 Data Scientists, 1 Machine Learning\nEngineer, 1 Systems Test Engineer, 1 Business Analyst, 1\nManager, 1 Marketer, and 1 Consultant.\n• Gender: 21 Female, 19 Male, 1 Gender Variant / Non-con-\nforming, and 1 Preferred not to say.\n• Python Experience: 17 participants had 3+ years of Python\nexperience, 11 had 1-3 years, 11 had less than 1 year, and 3\nwere not familiar with Python.\n497\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\n• Recency of Python Use: 29 participants had written Python\ncode within the past month, 4 within the past year, 5 within\nthe past 5 years, and 4 had not written Python code within\nthe past 5 years.\nWe provide full demographic information for individual partici-\npants in Appendix E.\n4.3\nProcedure\nParticipants completed the study on their own time, independently\nand without moderation. Each participant was provided with a web\nlink to a pre-study survey that described the nature of the study and\nthe tasks that they would be expected to perform. They were then\ndirected to the Programmer’s Assistant to complete the tutorial and\nthe four programming challenges. When participants indicated they\nwere finished with the challenges12, they were directed to a final\npost-study survey. Complete sessions generally required about an\nhour of effort, though some participants spread their effort across\na longer period of time and across multiple sessions. Participants\nwere compensated for their time at a rate equivalent to US $15/hr.\n4.4\nMeasures\nWe collected a variety of data in our study from three sources:\n(1) Surveys. We employed three surveys in the study: a pre-\nstudy survey to collect demographic information, a pre-task\nsurvey to gauge expectations of the conversational user ex-\nperience, and a post-task survey to assess actual user expe-\nrience. We describe these survey questions in the relevant\ncontext of our results, and we provide a complete listing of\nall survey instruments in Appendix A.\n(2) Event logs. The Programmer’s Assistant was instrumented\nto collect data on participants’ usage. The event logs pro-\nvided timestamped records of interaction events, including\nconversational exchanges, hiding/showing the assistant, use\nof the “try again” and “start over” features, and use of copy/-\npaste.\n(3) Conversation logs. From the event logs, we extracted con-\nversational transcripts between each participant and the\nProgrammer’s Assistant.\n5\nRESULTS\n5.1\nData & Analysis\nWe collected a wealth of data in our study: 126 survey responses\nfrom three surveys per participant, containing 296 written com-\nments in open-ended survey questions, and 4,877 instances of 23\ndifferent types of UI events, including 1,699 conversational ex-\nchanges13 in the event logs. We also compute, for each participant,\ncounts or durations for 21 different metrics from the event logs.\nIn our analysis, we deliberately exclude the portion of our data\ncollected during the tutorial exercise. We exclude this data because\nthat activity was guided by the tutorial instructions, not by our\nparticipants’ own initiative. Thus, our final sample consists of 3,172\n12We did not enforce that participants actually complete all of the challenges. Never-\ntheless, all participants but one did submit solutions to all of the challenges.\n13We refer to a participant’s utterance, followed by the assistant’s response, as a\nconversational exchange.\nevents, including 968 conversational exchanges in the event logs;\nno survey data was excluded.\nOur primary analysis of this data is qualitative, as our partici-\npants provided us with a rich source of interesting feedback and\nthought-provoking insights in their comments. Where applicable,\nwe supplement this data with quantitative data from the survey\nand the event logs, as well as chat transcript data from the con-\nversation logs. In this way, we triangulate [47] across our three\ndata sources, using the open-ended survey data as a foundation.\nWhen we quote participants, either from their qualitative survey\nresponses or the conversational transcripts, we reproduce their\nwords exactly as typed, including typos, misspellings, grammati-\ncal errors, capitalization, and potential trigger words, and we only\nmake minor clarifying edits where needed, delineated by square\nbrackets.\nIn order to set the context for our analysis, we first describe\nhow we used reflexive thematic analysis to analyze participants’\nresponses to the open-ended survey questions. We then describe\nour analysis of the conversation logs and our development of a\ncoding guide based on Conversation Analysis [76], and specifically,\nMoore and Arar’s Natural Conversation Framework [50].\n5.1.1\nThematic Analysis of Qualitative Survey Responses. We con-\nducted a reflexive thematic analysis to analyze the responses to\nour seven open-ended survey questions. We followed the process\ndescribed by Braun and Clarke [16] in which researchers immerse\nthemselves in the data, generate codes for material that seems\ninteresting, and then iteratively group and refine codes through\ncollaborative discussion in order to identify higher-level themes.\nInitially, four authors performed open-coding on the open-ended\nsurvey responses. Through discussion, these codes were grouped\nand consolidated into a single set, which were then re-applied to\nthe data by two authors. After another round of discussion, these\nauthors identified a set of 12 higher-level themes. Some themes had\nclear parallels to quantitative survey questions or event log data,\nand thus represented clear instances where we were able to trian-\ngulate across data sources. Other themes surprised us. We structure\nour presentation of the results based on these 12 themes, grouped\ninto three different aspects of the user experience: expectations\nand experience, utility of conversational assistance, and patterns of\ninteraction and mental models.\n5.1.2\nConversation Analysis via the Natural Conversation Frame-\nwork. In order to understand the content and structure of the\nconversations that took place between our participants and the\nProgrammer’s Assistant, we turned to the Natural Conversation\nFramework [50] (NCF). We developed a codebook for the event\nlogs, beginning with 21 different categories of utterances from the\nNCF. Nine NCF categories – Acknowledgment, Apology, Confirma-\ntion, Expression of Gratitude, Farewell, Greeting, Self-Identification,\nWelfare Check, and Welfare Report – appeared twice in our code-\nbook to distinguish cases in which the utterance was made by the\nhuman participant vs. the assistant. Other NCF categories were\nsplit to provide nuanced detail about the interaction; for example,\nwe distinguished three different kinds of NCF requests, depending\nupon whether they were stated as Requests for Action (e.g. “Would\nyou...”), Commands of Action (e.g. “Write a function that...”), or\nExpressions of Desire (e.g. “I want...”). We also added 18 additional\n498\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nInterlocutor\nOrientation\nCodes\nHuman\nSocial\nAcknowledgment, Apology, Criticism, Expression of Gratitude, Farewell, Greeting, Politeness,\nPraise, Self Identification, Small Talk, Welfare Check, Welfare Report\nTask\nAsks Question, Asserts Information, Capability Check, Command of Action, Expression of Desire, Identi-\nfies Error, Request for Action, Requests Elaboration, Requests Explanation\nMeta / UI\nChat Context Required, Confirmation, Copy, Copy (Extraneous), Erroneous Input, Includes Selection,\nIncludes Extraneous Selection, Missing Selection, Paste, Paste (Extraneous), Pasted Code in Chat, Spelling\nError, Start Over, Try Again\nAssistant\nAppears Fixated, Claims Ignorance, Didn’t Understand, Grants Request (Complete), Grants Request\n(Incomplete), Offers Help, Provided Wrong Answer, Requests Details, Requests Paraphrase, Response\nIncludes Code, Spews Garbage\nTable 1: Event log codebook. Our codebook contained 46 unique codes, applied separately to participant utterances (Human)\nand assistant responses (Assistant). Codes in bold were applied to both participant and assistant responses. Human codes were\nclassified as demonstrating either a social or task orientation to the assistant.\ncodes to identify meta-information such as utterances that included\ncode, utterances that referenced selected code, utterances that im-\nplicitly or explicitly referenced earlier portions of the conversation,\nor non-verbal UI activities such as copies, pastes, and invocations\nof “try again” and “start over.” Finally, we classified a subset of the\nhuman-applied codes based on whether they represented a par-\nticipant’s task or social orientation toward the assistant. We list\nour codes in Table 1, but note that not all of them ended up being\nrelevant to our analysis.\nWhen coding conversational data, we applied individual codes\nat the level of each conversational utterance. We allowed multiple\ncodes to be applied to each utterance to account for utterances that\nperformed multiple functions (e.g. greeting and self-identification).\nIn order to ensure consistency in how our codebook was applied,\ntwo authors coded a 10% sample of the 968 conversational ex-\nchanges, achieving a satisfactory level of inter-rater reliability (Krip-\npendorf’s \uD835\uDEFC = 0.77, where agreement was conservatively defined\nas having all of the same codes applied to both utterances in a\nconversational exchange).\n5.2\nExpectations and Experience\nPilot testing of the Programmer’s Assistant suggested that software\nengineers would be skeptical of a conversational programming\nassistant and its ability to provide useful assistance. Our study\nrevealed that, for most participants, their actual experience after\nusing the tool was better than they had anticipated. Participants\nwere surprised at the quality of the assistant’s responses and they\nappreciated how its integration with the code editor reduced the\namount of context switching they needed to do in the UI. Some\nparticipants struggled with the code selection feature, although\nothers appreciated the ability to ask questions related to selected\ncode.\n5.2.1\nUsage. All of our participants engaged with the Program-\nmer’s Assistant while working on the challenges, despite there\nbeing no requirement to do so. Forty-one participants submitted\nsolutions to all four challenges, and one participant, P14, only sub-\nmitted solutions for one of the four challenges. Participants spent\nan average of 68 minutes engaged with the assistant, as measured\nby the amount of time the Programmer’s Assistant window was in\nfocus.\nParticipants made an average of 23.0 utterances (SD = 15.1 ut-\nterances) to the assistant. On average, 6.2 of their utterances (SD =\n4.3 utterances) contained a code selection. The average latency per\nrequest14 was 6.7 seconds (SD = 3.1 seconds).\nWe saw a 66.3% rate of acceptance of generated code, where we\nconsidered code to be accepted if the participant performed a copy\nimmediately after the code was generated. This acceptance rate is\nmuch higher than the 27% acceptance rate reported for Copilot [109].\nWe believe one reason we observed a higher acceptance rate is\nbecause Copilot’s completion suggestions are generated proactively,\nwhereas the Programmer’s Assistant’s suggestions are generated\nupon request. When copying generated code from the assistant,\nparticipants most often copied the entirety of the generated code,\nand only in 5.8% of cases did they copy a smaller portion of it.\n5.2.2\nUser Experience Expectations & Changed Attitudes. Prior to\nrunning our study, we had reason to believe that participants would\nbe skeptical of a conversational programming assistant. Before de-\nveloping the Programmer’s Assistant, we showed potential users\nmockups of a program editor with an integrated chatbot feature.\nThese prototypes elicited uniformly negative reactions. People told\nus about their frustrating experiences with conventional chatbots\nand raised doubts about the knowledge, capabilities, and value\nof a conversational programming assistant. This skepticism moti-\nvated us to develop the Programmer’s Assistant in order to evaluate\nwhether the conversational experience, as powered by a state-of-\nthe-art code-fluent LLM, would be better than people had antici-\npated. During pilot testing, we received feedback that the Program-\nmer’s Assistant provided a much better conversational experience\ncompared to testers’ previous experiences with chatbots. Thus, in\ndesigning our study, we felt it important to first gauge participants’\nexpectations of a conversational interaction around code, and then\nmeasure their experience after the fact.\n14This time includes additional time added by our proxy server to ensure our confor-\nmance to the API rate limitation.\n499\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\nWe developed a short inventory of six scale items to measure user\nexperience of code work15. The scale was administered twice: once\nbefore participants were exposed to the Programmer’s Assistant\n(but after they had been briefed that they would interact with an AI\nchatbot), and once after completing the programming challenges.\nThe items were presented with the appropriate tense: Do you expect\n(Did you find that) the Programmer’s Assistant: (a) will be (was)\neasy to use; (b) will understand (understood) your requests; (c) will\nprovide (provided) high quality responses; (d) will help (helped)\nyou to write better code; (e) will help (helped) you to write code\nmore quickly; (f) will be (was) enjoyable to use. Each item was rated\non a 4-point scale of extent: Not at all (1), A little (2), Somewhat (3),\nA great deal (4).\nA factor analysis revealed the items on this scale measured a\nsingle construct, which we identify as user experience (Cronbach’s\n\uD835\uDEFC = 0.87). Thus, we computed two scores of user experience (UX)\nfor each participant: a pre-task UX score computed as the average\nof their six pre-task expectation scale responses, and a post-task\nUX score computed as the average of their six post-task experience\nscale responses.\nWe found that participants had lower initial expectations for\ntheir experience with a conversational programming assistant (pre-\ntask UX M (SD) = 3.0 (0.62) of 4) than their experience actually\nwas (post-task UX M (SD) = 3.6 (0.32) of 4). A paired sample t-test\nshows that this difference was significant, \uD835\uDC61(41) = 5.94, \uD835\uDC5D < .001,\nCohen’s \uD835\uDC51 = 0.92 (large). Measured another way, 32 participants\n(76.2%) had post-task UX ratings that were higher than their pre-\ntask expectations, demonstrating a significant shift in attitudes\ntoward conversational programming assistance.\nHowever, the UX ratings alone fail to capture participants’ nu-\nanced expectations of the assistant and the reasons for their shifted\nattitudes after using it. Participants expressed a variety of expecta-\ntions of the assistant before using it, including that it would be easy\nto use (P30) and produce correct responses (P30), understand the\nproblem and what is being asked of it (P8, P9, P11), not interfere\nwith their flow state (P5), produce imperfect or questionable out-\nputs (P6, P21), improve with feedback (P31), provide generic and\nunhelpful answers (P17) or only answer basic questions (P40), and\nproduce responses quickly (P40).\nP17 expected “to be frustrated very quickly and that what I’d think\nwould be relatively common questions would be responded to with\ngeneric, unhelpful answers.” P6 explained, “I didn’t have very good\nexperiences with chatbots. I think I’ll need to spend more time in\nreviewing and fixing the suggestions than in writing the code myself\nfrom scratch.” P11 had a more balanced view, that “It’ll do some tasks\nreally well, but others will not be as reliable.”\nAfter interacting with the Programmer’s Assistant, many par-\nticipants commented on how the experience was better than they\nanticipated, because it “seemed to be able to handle complex issues”\n(P10) and “was a great help” (P8). P20 felt it was “incredible!” P6 and\nP17, who were both initially skeptical, reported having a positive\nexperience. For P6, “It absolutely exceeded all my expectations, in\n15Our scale items were modeled from scales published in Weisz et al. [103, Table 9 –\nAI Support] that measured constructs including ease of use (item 3), response quality\n(item 1), the production of higher-quality code (item 5), and the ability to write code\nmore rapidly (item 4). We added additional items to cover the constructs of request\nunderstanding and enjoyment, and we cast all items on a 4-point scale of extent.\nall aspects that I could have imagined and more!” P17 provided a\nmore quantitative assessment: “Initial expectations: 3 Actual: 9.5.”\nP38 was emphatic in their evaluation: “I was blown away how well\nit allowing me to structure how I want the code to look and work and\njust giving me the thing I asked for.”\nMany participants described a sense of surprise in their experi-\nences. P9 was surprised by how well it understood their requests:\n“I was surprised at how well the Programmer Assistant\nwas able to understand my requests and generate good\ncode/documentation/tests. It understood major concepts\nand was able to explain it to me in a clear way, and it\nwas also able to understand and write functional code.\nIt even was able to help me review my answer. I was also\nsurprised at how well it could understand the context\nof what I was asking in follow-up questions when I did\nnot specify exactly what I was talking about, but rather\nreferencing our prior conversation (such as, ‘what does\nthat mean’).” (P9)\nSimilarly, P6 was surprised that they liked the conversational\ninteraction when they expected that they wouldn’t:\n“I though[t] I wouldn’t like the chatbot interaction and\nthat I would prefer something like the tool I’ve seen in\nthose demos [of Copilot]. But surprisingly, after using\nthe chatbot (and seeing the results: easy to use, it un-\nderstands well, I felt it like a partner) I like this kind of\nhelp.” (P6)\n5.2.3\nQuality of Assistant’s Responses. In order to gauge the quality\nof responses produced by the Programmer’s Assistant, we examined\nthe 910 task-oriented requests made by participants in the study.\nFor the vast majority (80.2%), the assistant produced a correct re-\nsponse (Grants Request (Complete)); in other cases, the assistant’s\nresponse was incorrect (9.6%; Provided Wrong Answer), correct but\nincomplete (4.4%; Grants Request (Incomplete)), or the assistant\ndidn’t understand (3.4%; Didn’t Understand), claimed ignorance of\nthe subject (1.5%; Claims Ignorance), or produced another type of\nresponse (0.9%; Appears Fixated, Spews Garbage).\nParticipants also reported experiencing this variability in the\nquality of the assistant’s responses. Some participants described\nhow the assistant provided “detailed answers” (P17) and “high qual-\nity outputs” (P18) that were “surprisingly good” (P2). P6 felt it was\n“incredible to see the quality of the responses,” and P3 even explored\nthe assistant’s capabilities outside the scope of the challenges and\nfound that it could handle those as well:\n“It was surprising the quality of the code and the ability\nto answer all my questions correctly. Although I think\nthe challenges may be biased towards what the Assistant\nis able to do, it was a great experience because I asked\nmany other things and it was able to answer correctly.”\n(P3)\nOf course, the Programmer’s Assistant wasn’t perfect, and some\nparticipants did run into issues. For P35, “The documentation gener-\nation did not perform very well.” P16 questioned the accuracy of the\nknowledge encoded in the model: “Does the model need to be up-\ndated? It said latest python version is 3.7 but google says it’s 3.10.” In\nsome instances, participants needed to ask their question multiple\n500\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\ntimes to get a good response: “you need to ask many times if you\nwant to get an answer and also a detailed explanation” (P3). P27 felt,\n“it was annoying when I asked it to try again and it would give me\nthe same response.” P22 struggled because, “It didn’t seem to handle\nmultiple sentences well.”\nP28 perhaps offered the most scathing criticism, that, “It makes\nmistakes often enough to be not very practical.” However, despite\nthe production of poorer-quality responses, other participants felt\nthat the assistant was still helpful. P36 reported that, “Only minor\ntweaks were normally needed to correct any issues.” Similarly, P38\ndescribed how the assistant wasn’t able to completely solve their\nproblem, but provided a useful start:\n“There was only one hickup I noticed where when I\nasked it to memoize fibonacci it couldn’t, but it dropped\nthe building blocks on my lap for me to finish so that\nwas fine, that was like minutes of effort on my part.”\n(P38)\n5.2.4\nUI Design & Affordances. Participants made many comments\non our specific UI design and the affordances provided (or not\nprovided) in our chat-augmented editor. Overall, the integration\nbetween the chat pane and the code editor was “very good” (P23),\nwith a “nice interface between the code pane and the assistant pane”\n(P17) that “makes it really convenient” (P35).\nPrior research by Brandt et al. [15] has shown how keeping\ndevelopers focused in their IDE improves productivity, and our\nparticipants expressed similar sentiments. P40 remarked, “It allows\nme to stay in one browser window/tab!” and P12 hinted at how the\ninterface might preserve their flow state by “prevent[ing] me from\ngetting distracted when looking into an issue in another tab.”\nSome aspects of our user interface were confusing to participants,\nsuch as the mechanism for selecting code to be included in the\nconversational context. P7 remarked, “It’s was a little confusing\ndoing the selection part for it to tell me what a function does, but...\nit gave me code that was insanely easy to copy and paste.” Other\nparticipants appreciated the code selection mechanism, such as P11:\n“I enjoyed the code selection feature, and found that very easy to use.”\nIn the event logs, we identified 20 instances in which a participant\nunintentionally included selected code in the conversation when\nit wasn’t needed (Includes Extraneous Selection), 12 instances in\nwhich a code selection was omitted when it was needed to provide\ncontext for the question (Missing Selection), and 16 instances in\nwhich a participant copy/pasted code directly into the chat rather\nthan selecting it in the editor (Pasted Code in Chat). Although\nthese cases represent a small fraction of the 227 instances in which\na code selection was required and included in the conversation\n(Includes Selection), their presence does indicate that more attention\nis needed to the interaction design of code selection.\nAnother issue regarded the awareness of the “try again” and\n“start over” features. The “try again” feature was only used by 14\nparticipants, who used it a total of 63 times over the course of\nthe study. Some participants used it specifically when they got an\nanswer which they saw as clearly wrong, while others used it to\nget a variety of possible answers before proceeding. The “start over”\nfeature was used even less, by 5 participants who used it a total of\n6 times. Despite our effort to surface these conversational features\nin the UI via shortcut buttons, they may not have been sufficiently\nnoticeable or salient: “The ‘try again’ button is not so reachable, often\ntimes I forgot it exists” (P23). By contrast, at least one participant\nwas successful with these features:\n“at some point it had issue with challenge 3 and I had to\nstart over. Just asking ‘try again’ was not enough and I\nwas getting always the same (wrong and not related)\nanswer. starting again solved the issue!” (P20)\n5.3\nUtility of Conversational Assistance\nOur next set of themes concerns the utility provided by conversa-\ntional programming assistance. Participants felt the assistant was\nhighly valuable and desired to use it in their own work. They felt it\nwould be most helpful for smaller or narrowly-scoped tasks, but\nable to provide a wide variety of types of assistance. The fact that\nthe interaction model was conversational and grounded in code\nwere valuable aspects, as was the ability for the assistant to bolster\nusers’ learning about programming topics through that interac-\ntion. Participants did question whether they could trust and rely\nupon the assistant’s responses, echoing a similar theme discussed\nin Weisz et al. [102].\n5.3.1\nValue & Appropriate Tasks. Participants rated the value of\nthe Programmer’s Assistant highly (M (SD) = 8.6 (1.4) of 10). Many\nparticipants asked questions such as, “Can I have it in my editor\nplease?” (P15), or made comments that, “I would enjoy using it in\nthe future” (P36), “I would love to be able to... have access to it for\nmy coding” (P37), and “I’d love to use this tool as part of my usual\nprogramming workflow if I could!” (P39). Some of the reasons why\nparticipants found it valuable are because it “help[s] me remember\nhow to do things in certain languages that normally I would just\nGoogle” (P9) and “It helps me to avoid silly syntax errors and can\nwhen I cannot remember exact function/method names and required\narguments” (P40). We did not observe any differences in value\nratings based on participants’ familiarity with or recency of using\nPython.\nParticipants described a wide variety of tasks for which they\nfelt the assistant would be useful. These tasks included “ordinary”\n(P23), “simpler” (P2), and “small, repetitive” (P4) tasks such as “quick\nlookups” (P25) for “short chunks of code” (P11) or for “narrowed\nquestions” (P26). Participants also felt the assistant was useful for\n“small containable novel algorithms” (P38) and “little coding problems”\n(P4).\nSeveral kinds of task assistance were reported as being valuable,\nsuch as explaining code (P31), implementing business logic in a\nUI (P38), understanding what code does (P19, P37), and recalling\nlanguage syntax, method names, and arguments (P12, P15, P20, P40,\nP42). P27 felt that the assistant was “More helpful when recognizing\na specific well known algorithm but not things you make yourself.”\nParticipants also made recommendations for how to increase\nthe value of the Programmer’s Assistant. P38 suggested, “What\nwould blow me away though is if it’s able to help with what I do most\noften which is to integrate, refactor and iterate on an existing system.”\nP16, P26, and P38 all desired more information on the data sources\nused to produce the assistant’s responses. P9 requested to “Have\nthe Programmer’s Assistant examine your code and make proactive\nsuggestions for improving it in the chat.” P36 requested the same,\n501\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\nbut cautioned that, “Care would need to be taken to avoid becoming\nan annoyance or disrupting the flow of a coding session.”\nIn the post-task survey, we probed participants on how certain\nchanges to the Programmer’s Assistant would either decrease, in-\ncrease, or result in no change to its value. Over 75% of participants\nfelt that the assistant would be more valuable if it operated in a\nproactive manner, either by making improvement suggestions in\nthe chat or as comments directly in the code. Similarly, 78.6% of\nparticipants felt that having more buttons in the UI for common\nfeatures such as explaining or documenting code would make the\ntool more valuable.\n5.3.2\nConversational Interactions Grounded in Code. One of the\nchallenges in interpreting participants’ comments about the utility\nof the Programmer’s Assistant was in disentangling the extent to\nwhich value was derived from the quality of the underlying model\nversus the integration of conversation in a code context. Indeed,\nparticipants felt that the chat interaction was valuable: 69.0% of\nparticipants felt that eliminating the conversational interaction\nand making the assistant behave more like web search would de-\ncrease its value. Further, our analysis of the conversation transcripts\nrevealed that 42% of the 910 task-oriented utterances from partic-\nipants required historical conversational context (Chat Context\nRequired) in order to be correctly interpreted. Thus, we observe\nthat behaviorally, participants did rely on conversational context\nin their interactions.\nIn the post-task survey, 83% of participants rated the importance\nof the ability to ask follow-up questions as being “somewhat” or “a\ngreat deal.” Several participants specifically commented on the value\nof this conversational context. P39 remarked, “I absolutely loved\nhow you can straight up ask follow-up questions to the Programmers’\nAssistant without having to reiterate the original topic/question.” P15\nexpressed a similar sentiment, saying, “I think the conversational\ncontext was someone helpful, just in communicating that it’s a running\nconversation where my context is remembered.” P9 provided a similar\nanalysis:\n“This tool was so helpful at answering questions I had\nabout the code in the context of the code I am working\non... I was also impressed with how well it was able to\nremember the context of our conversation, especially\nwhen I asked vague follow-up questions.” (P9)\nIn addition, some participants identified how a conversational\ninteraction grounded in code was useful, “because I think to ‘un-\nderstand’ the dev context could be VERY important” (P31). In fact,\n24.9% of task-oriented utterances included a relevant code selection\n(Includes Selection), showing that participants valued this ability.\nContrasting with these participants, P18 felt that interacting\nwith the assistant conversationally was tedious, and they employed\na more direct approach:\n“I really like the PA. But, I didn’t converse with it like\na chat bot. I often told it what to do (‘Document this\ncode.’) as opposed to asking it what to do (‘How do I\ndocument this code?’). Talking to it the way that was\nsuggested in the tutorial seemed overly verbose/tedious.”\n(P18)\nDespite these individual differences in interaction preferences,\nP39 envisioned that both interaction styles could be supported in\nthe tool:\n“I think both options should exist: people should be able\nto input their queries like a search bar AND also give\ntheir question as if in conversation.” (P39)\n5.3.3\nLearning Effects. One specific benefit of the Programmer’s\nAssistant identified by participants is its ability to help people\nimprove their programming skills and reinforce knowledge gaps.\nFor example, it can help users “remember how to do things in certain\nlanguages... such as, when I am using a language I haven’t used in a\nwhile” (P9). The assistant can also serve as an memory aid, such\nas when “I use a lot of libraries that I don’t always remember all\nof the functions” (P15). Similarly, P31 said, “No matter how good\nyou’re as a developer, you can’t (humanly) remember all the API of\nhundreds of libs or new languages... I’d learn new dev lang and new\nlib/frameworks faster.”\nP39 felt the assistant “is perfect for programmers of all levels,” and\nP1 felt it could help them rapidly improve their Python skills:\n“I have wanted to learn python... The main concern\nhow much time spent learning is needed before I could\nactually get some value out of learning python. I have\na feeling this would cut that time down from weeks to\na day or so.” (P1)\nP39 also identified the fact that, because the interactions with\nthe assistant are conversational, it forces people to learn how to\ncommunicate to others about their code:\n“The conversation aspect promotes proper communi-\ncation, which would really stand to benefit budding\nprogrammers if they want to learn how to explain con-\ncepts more fluently in the future to their colleagues.”\n(P39)\nConversely, P36 suggested that over-reliance on programming\nassistance might have a detrimental effect to one’s learning:\n“It’s definitely a huge time saver, but over-reliance on it\nmay cause new developers to skip learning the reference\nmaterial themselves and discovering new things and\nsparking new ideas.” (P36)\n5.3.4\nTrust. Many participants raised questions about whether\nthey could trust the responses provided by the Programmer’s Assis-\ntant. P21 asked this question most directly: “will the code be correct,\nsafe, efficient?” Other participants raised similar questions, such as,\n“I’m wondering how it validates it’s answers, if it can be trusted to\nalways give a working answer” (P10), and “Sometimes lack of source\nand context may raise doubts in the mind of the programmer” (P16).\nThese issues of trust were exacerbated by the fact that the Pro-\ngrammer’s Assistant did not allow participants to actually run their\ncode. Because of this limitation, participants had to rely on their\nown knowledge to judge the correctness of the assistant’s responses.\nP19 asserted, “There is no way to evaluate if the Programmer’s as-\nsistant is giving you the right advise or not other than your own\nknowledge,” and P9 concurred: “I had to trust that it was correct (and\nuse my own prior knowledge).”\n502\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nP18 described the potential consequences of allowing the assis-\ntant to write code for them:\n“The only thing that made me nervous was that it could\nhave introduced a bug that wasn’t immediately appar-\nent. And given I didn’t write the code, I could have easily\nglossed over a mistake when reviewing it. Especially if\nit is also the one writing the test cases.” (P18)\nDespite our efforts to make the Programmer’s Assistant respond\nin non-authoritative ways, we did observe participants sometimes\nuncritically accept generated results that were clearly wrong or\nincomplete. Thus, we did find behavioral evidence for over-reliance.\nListing 2: Building trust through explanations and justifica-\ntions\n1\nP9:\nwhat is a unit test?\n2\n3\nSocrates: A unit test is a test of a single function\n4\nor method.\nIt is typically written by the\n5\nprogrammer who wrote the code.\n6\n7\nP9:\n8\ndef euclid(a, b):\n9\nwhile b != 0:\n10\n(a, b) = (b, a % b)\n11\nreturn a\n12\n13\nhow would I write a unit test for this code?\n14\n15\n[...]\n16\n17\nSocrates: I think you would do something like this:\n18\n19\ndef test_euclid():\n20\nassert euclid(2, 4) == 2\n21\nassert euclid(6, 9) == 3\n22\nassert euclid(17, 12) == 1\n23\nassert euclid(4, 4) == 4\n24\n25\nP9:\nwhat is a euclid function\n26\n27\nSocrates: The euclid function is a function that\n28\ncomputes the greatest common divisor of two\n29\nnumbers.\n30\n31\nP9:\nis this a good unit test for a euclid\n32\nfunction\n33\n34\nSocrates: I believe that it is a good unit test for\n35\na euclid function.\n36\n37\nP9:\nwhy\n38\n39\nSocrates: It seems to me that it tests the edge\n40\ncases of a and b being equal , a being\n41\ngreater than b, and b being greater than a.\n42\n43\n[...]\n44\n45\nP9:\nthanks Socrates this was helpful\n46\n47\nSocrates: Always happy to help.\nOne way to address trust issues is for the assistant to provide\nfurther explanations and justifications that can calibrate a user’s\nconfidence in the assistant’s responses. Such explanations could\nbe requested conversationally, though most participants did not\nattempt to do so. One participant (P9) did ask for such explanations,\nand we show a summary of their transcript in Listing 2. In this\ninstance, P9 asked for a definition of a unit test (line 1), an expla-\nnation of the code being tested (line 25), and justifications of the\nquality of the unit test (lines 31& 37). Thus, we observe that the\nassistant is capable of producing explanations and justifications\nwhen asked.\n5.4\nPatterns of Interaction and Mental Models\nParticipants interacted with the assistant in a variety of ways with\ntwo main patterns of usage standing out: (1) invoking the assis-\ntant to solve the entire programming challenge, and (2) breaking\nthe challenge down into a set of smaller tasks and invoking the\nassistant’s help for each. There were no clear differences in how\nparticipants with differing Python experience approached the tasks.\nParticipants’ mental models of the assistant also varied. Although\nparticipants strongly saw the role of the assistant as being a tool,\ntheir behaviors revealed that in many cases, they actually treated it\nas a social agent. In addition, participants ascribed various mental\ncapacities to the assistant, such as having the ability to understand,\ncompute, and learn.\nParticipants felt the assistant changed the nature of their work\nprocess. For some participants, it enabled them to focus on the\nhigher-level aspects of development because the assistant handled\nlower-level details or provided partial solutions for them to build\nupon. Many participants felt the assistant sped up their work and\nhelped them remain focused on their tasks.\nFinally, participants drew comparisons between the Program-\nmer’s Assistant with other forms of programming support such\nas Copilot and web search. They felt that the conversational style\nof interaction enabled them to discover new, emergent behaviors\nfrom the model that were unavailable from Copilot’s focus on code\nautocompletion. They also felt that the examples provided by the\nassistant were more readily usable within their own code compared\nto browsing for answers within search results, speeding up the\ncoding process. However, some participants advocated for a bal-\nanced approach to the design of programming assistance tools by\nincorporating multiple modes of interaction rather than fixating\non a single one.\n5.4.1\nInteraction Styles and Assistant Role. We observed that par-\nticipants interacted with the Programmer’s Assistant in strikingly\ndifferent ways. Some participants would present the entire chal-\nlenge description to the assistant and then work with the results it\nproduced. Other participants approached the programming chal-\nlenges in a piecemeal fashion, breaking them apart into a set of\nsmaller tasks, then invoking the assistant to aid with each one.\nExperience with Python was not a determinant of how partici-\npants approached the programming challenges, but it did seem to\nimpact how participants interacted with the assistant. Less experi-\nenced participants tended to ask the assistant basic questions such\nas, “What is a unit test” (P29, not familiar with Python) and “how\ndo I document a function?” (P27, < 1 year of experience). More expe-\nrienced participants made detailed requests about specific Python\nlibraries or algorithms, such as, “given a pandas dataframe with\ntwo columns ‘Date’ and ‘Sales’ please use matplotlib to draw me a\nscatterplot” (P38, 3+ years of experience) and “implement a runge-\nkutta algorithm for solving an ODE with adaptive time steps” (P37,\n3+ years of experience).\nAnother difference we observed in how people interacted with\nthe assistant stemmed from their view on the role it played in their\n503\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\ncollaborative process. Some participants, such as P18, treated it\nmore as a tool by issuing commands rather than asking questions.\nAs quoted earlier, they said, “I didn’t converse with it like a chat\nbot.” P5 described their interaction style similarly: “I found myself\nwanting to type search queries into Socrates, not treating it as a person\nbut as a search tool.”\nIn anticipation that participants would have different orienta-\ntions to the assistant and its role, we asked a question on the post-\ntask survey about the different kinds of roles the assistant might\ntake. These roles generally fell into one of two categories: a tool\norientation (a tool, a reference guide, a content generator, a problem\nsolver), and a social orientation (a collaborator, a colleague, a coach,\nan advisor, a reviewer). Participants rated the extent to which they\nviewed the Programmer’s Assistant in each of these roles on a 4-\npoint scale of extent: Not at all (1), A little (2), Somewhat (3), or A\ngreat deal (4).\n0\n25\n50\n75\n100\nTool\nContent\ngenerator\nReference\nguide\nCollaborator\nProblem\nsolver\nAdvisor\nCoach\nReviewer\nColleague\nRole\nPercentage of participants\nRating\nNot at all\nA little\nSomewhat\nA great deal\nFigure 3: Role orientations. Participants overwhelmingly felt\nthat the assistant’s role was of a tool orientation rather than\na social orientation. The chart shows ratings distributions\nacross 9 different roles the assistant might take, sorted by\nthe percentage of participants who rated the extent of that\nrole as “A great deal.” The leftmost role is of a tool, with\n80.9% of participants rating it as “a great deal.” Following\ntool are content generator (69.0%), reference guide (64.3%),\ncollaborator (40.5%), problem solver (35.7%), advisor (21.4%),\ncoach (19.0%), reviewer (16.7%), and colleague (14.3%).\nWe show participants’ ratings of the assistant’s role in Figure 3.\nDespite the fact that their attitudes toward the assistant overwhelm-\ningly reflected a tool orientation, their behaviors reveal that many\nparticipants actually treated the assistant as a social agent. P6 de-\nscribed how “I felt it like a partner,” and P4 told the assistant, “I\ncould not have solved [the challenge] without your help,” to which\nthe assistant responded, “I’m glad I could help.”\nThe literature on Computers as Social Agents (CASA) helps us\ninterpret this result as it demonstrates how computers are often\ntreated like people [56, 67]. LLM-based conversational agents can\nexacerbate this tendency; as they likely have been trained on ex-\namples of social interaction, they can also respond as social agents.\nIn the conversation logs, we identified participants who inter-\nacted with the assistant in a socially-oriented fashion (the social\norientation codes in Table 1). Twenty participants (47.6%) made at\nleast one socially-oriented utterance. An extreme form of this inter-\naction style can be seen in a snippet from P6’s transcript (Listing 3).\nThe 20 participants with a behaviorally-demonstrated social\norientation did not generally differ in their role ratings from other\nparticipants, except that they rated the assistant as more likely to\nbe an advisor (Fisher’s exact test, two-tailed \uD835\uDC5D = .02) or a reviewer\n(Fisher’s exact test, two-tailed \uD835\uDC5D = .03). However, they did not differ\nin their overwhelmingly-strong ratings of the tool orientations.\nThus, at least for some participants, there seems to be a dissonance\nin their view of the assistant’s role orientation.\nListing 3: Excerpt from P6’s interaction with the Program-\nmer’s Assistant, in which P6 offers their thanks and congrat-\nulations.\n1\nP6:\nthank you! it's been really nice to code\n2\nwith you! or to have you coding! LOL\n3\nSocrates:\nYou 're welcome!\n4\nP6:\nI hope to see you on air soon , Socrates!\n5\nSocrates:\nI hope so too.\n6\nP6:\ncongrats to you research team! you 've made\n7\na good job!\n8\nSocrates:\nI'm glad you think so.\n9\nP6:\nsorry ... they 've made a good job (well ...\n10\nyou too ... ;-) )\n11\nSocrates:\nThank you.\n12\nP6:\nsee you next time! bye!!\n13\nSocrates:\nGoodbye.\n5.4.2\nMental Capacities. Participants made a number of inferences\nabout the Programmer’s Assistant and its capacities for thought.\nMany participants talked about how the assistant possessed a level\nof “understanding” (P6, P8, P11, P18, P32) of “the context” (P9, P21)\nas well as “major concepts” (P9) and “knowledge” (P33). P24 was\namazed by the assistant’s ability to “take a plain english request\nand interpret it properly.” P7 ascribed intelligence to the assistant,\nsaying, “It was a lot smarter and trained tha[n] I thought it was.”\nOne participant assumed that the assistant “Keeps improving\nthrough (user) feedback” (P31). Another felt that the assistant was\ncapable of computation: “It understands the problem... It can calculate\nthe results of a function back” (P8).\nHowever, not all participants were convinced of the assistant’s\nability to understand. P37 questioned the assistant’s limitations: “I\nwonder how far beyond boilerplate it can go and if it works for truly\noriginal problems.”\n5.4.3\nImpact of Conversational Assistance on Work Practices. Many\nparticipants discussed how the Programmer’s Assistant shaped\ntheir work practices on the programming challenges. Overall, par-\nticipants felt that the assistant “saves time” (P10), “helps me code\nfaster” (P34), and would “speed up my productivity” (P19) because “I\ncould focus on validating and improving the code it generated instead\nof having to write it all from scratch” (P18). P37 remarked that, “It\nopens a whole new door for fast develpment.” P4 discussed how the\nassistant “was helpful in staying focused on the code,” although for\nP14, “it took [me] time to get into tempo with the tool.”\nP31 pointed out how the assistant would change the nature of\ntheir work:\n“My job could focus more on higher level aspects and\ntherefore achieving better (quality) results, besides the\n504\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\ntime-to-value... Data science (and dev) becomes a more\ncreative-higher level experience.” (P31)\nOther participants discussed a work process in which the assis-\ntant provided incomplete solutions – the “building blocks” (P38) or\n“initial draft of code” (P11) – upon which they could build. P5 aptly\ndescribed this process:\n“It’s nice to copy well formulated challenges in natural\nlanguage and have the code generator take its best stab\nat it, then edit to our hearts content.” (P5)\nParticipants felt that human review of the assistant’s responses\nwas necessary because “The answers provided are generally not\nnovel solutions, often look clunky and non-elegant. There may be\nsome unnecessary code. Basically the code would need to be reviewed”\n(P16). P35 also pointed out how “The code generator was good but\nyou still have to really check it.” P19 discussed how they would turn\nto the assistant as a first source for support, and only if it wasn’t\nable to help would they then turn to other support tools:\n“The way I will use it is, I will first us[e] the Program-\nmer’s assistant for most of my cases. Only in certain\ncases where Programmer’s assistant cant answer things\nI will turn up to official documentation or stack overflow.”\n(P19)\nHowever, latency was a factor for interactive use of the assistant\nand participants noticed when the assistant took a long time to\nrespond. P19 remarked, “Sometimes it took lot of time, like more than\n5 seconds.” P40 also felt “the response [was] a little slow sometimes...\nin chat mode I expect faster responses.” As discussed in Section 5.2.1,\nthe assistant took an average of 6.7 seconds (SD = 3.1 seconds)\nto respond to a request, and participants did appreciate when the\nassistant produced rapid responses: “I loved how quick it was able\nto pull up answers to questions I had” (P38).\n5.4.4\nConversational Interaction vs. Other Interaction Models. Al-\nthough our study was not intended to make comparative evalu-\nations with the Copilot tool, we nonetheless asked participants\nwhether they were familiar with Copilot, and if so, to comment on\nhow the two tools compared. We also asked a similar question to\ncompare the assistant with another popular form of programming\nassistance, searching the web (via a search engine like Google, or\na Q&A site like Stack Overflow). In discussing the differences be-\ntween these three tools, we note that the primary differentiator is\ntheir interaction model.\nThe interaction model for the Programmer’s Assistant is clearly\nconversational: users ask questions in natural language and are\nprovided with a response in natural language and/or code. The\ninteraction model of Copilot is reminiscent of direct manipulation\ninterfaces [37], in which the user’s actions in the user interface\ndirectly manipulate an object on the screen. Copilot automatically\nmakes autocompletion suggestions as the user types. This auto-\ncompleted code is directly placed in the source editor; thus, the\nuser’s work is contained entirely within the scope of the object\non which they are working (i.e. the source code), which is how\ndirect manipulation interfaces operate. In web search, users enter\na separate search context (e.g. a search engine accessed within a\nweb browser), type in a natural language query, and then forage\namongst search results to identify relevant items of interest [12, 62].\nWhen a desirable item is found, users must translate it into their\ncode environment (e.g. via copy/paste) and possibly edit it to fit\ntheir existing code.\nWe also note that the Programmer’s Assistant and Copilot both\nutilize the same underlying AI model, Codex [24], which means\nthat the only difference between these tools is the user experience.\nThe extent to which Codex was trained on data from programming-\nrelated Q&A web sites is less clear, but for the purposes of our\nanalysis, we focus our discussion solely on the differences in their\ninteraction models16.\nParticipants reported various benefits and drawbacks of a con-\nversational interaction over a direct manipulation interaction. Fore-\nmost, conversation “felt very natural” (P21) and “feels much more\nnatural using Natural Language with the AI” (P39). In addition, P39\nfelt that “the use cases of Programmers’ Assistant seem more open-\nended.” Many participants were surprised at the variety of tasks the\nassistant was capable of performing, from writing unit tests (P19,\nP36, P37) and documentation (P12, P19, P36, P37) to explaining\nwhat code did (P31, P38) and even answering general-knowledge\nquestions (P31). Again, we note that the Programmer’s Assistant\nutilizes the same underlying model as Copilot, yet the conversa-\ntional interface was able to expose a wider variety of emergent\nbehaviors from the model. Multiple participants explored the limits\nof the assistant’s knowledge and abilities beyond our programming\nchallenges. For example, P37 asked it questions about physics and\nordinary differential equations (“ODe” as written by P37), and was\nsurprised by the “versatility of what it could answer.”\n“I asked it some physics and ODe question and the\nanswers, though not complete, included the key parts\nneeded to write that code.” (P37)\nP31 probed the assistant on its knowledge of geography and was\nsurprised when the assistant produced a correct answer.\n“I asked something out of SW engineering domain (ge-\nography) and it replied correctly, also by correctly an-\nswering on my nationality.” (P31)\nFor some participants, the ability to assess the assistant’s re-\nsponse before committing to it (i.e. by inserting assistant-generated\ncode into their editor) was a boon. P15 described how the copy/-\npaste boundary provided them with “a bit more control to ask specific\nquestions about what I wanted and to assess before putting it in my\ncode.” Other participants felt that the copy/paste boundary was\nmore inefficient:\n“I think the main difference is the ability of Copilot to\nsuggest code while you type, what make it faster and\neasier to use. While using the Programmer’s Assistant,\nyou need to go to the chat, ask the question, copy the\n16As an aside, our comparison of direct manipulation, search, and conversational inter-\naction models is reminiscent of historical comparisons of text-based and graphical user\ninterfaces [54, 63]. Each modality was shown to have advantages and disadvantages.\nFor example, text-only interfaces can provide accessibility [54, 78] and productivity [53]\nadvantages, whereas graphical user interfaces provide greater discoverability [10, 88].\nSome researchers explored ways to bridge the two interaction modes, such as by\ndeveloping GUI wrappers for command line programs [53, 94] or by developing tools\nthat converted GUI activities into procedural descriptions [55]. Our view is that similar\nbridges can be constructed between direct manipulation, search, and conversational\nmodels of interaction; a user’s interaction with an LLM need not be constrained to a\nsingle interaction model.\n505\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\ncode (or rephrase the question if it was not understood\nby the agent), and edit it to match your code.” (P3)\nA large number of participants felt that the conversational inter-\naction was faster than web search (P1, P6, P7, P10, P11, P12, P16,\nP17, P18, P20, P24, P29, P30, P33, P36, P37, P42) because of its ability\nto provide “real-time responses” (P32) that can be “applied exactly to\nyour code” (P33) without having to “parse through lots of text... to get\nwhat you need” (P15). In addition, the assistant provided “MUCH\nfaster, better responses” (P17) that were “much more relevant to the\nproblems” (P34) and “simple [and] succinct” (P9), without having to\n“sort through answers on your own or read documentation” (P9) or\n“look at many posts before finding the relevant one” (P18).\nDespite these benefits, some participants felt that the assistant\nmight not work well for “more specific and difficult problems on\na bigger scale” as compared to web search. P9 felt that “the data\n[of the Programmer’s Assistant] wasn’t as rich” as the web. Other\nparticipants felt that the assistant lacked the “multiple answers” (P9)\nand “rich social commentary” (P19) that accompanies answers on\nQ&A sites:\n“I like to see the different versions proposed on stack\noverflow and the commentary of what makes one solu-\ntion better than another in a given situation.” (P27)\nSome participants promoted a more balanced view that there\nisn’t a single mode of interaction superior to all others. P19 felt that\nweb search would be a fallback when the assistant failed to answer\na question. P39 described how search could be integrated with the\nconversational interaction:\n“I think both options should exist: people should be able\nto input their queries like a search bar AND also give\ntheir question as if in conversation.” (P39)\n6\nDISCUSSION\n6.1\nValue of Conversational Interaction\nWe began our research by asking the question of whether con-\ntemporary developments in code-fluent LLMs could sufficiently\nsupport a conversational programming assistant. We believe that\nour work has demonstrated that they can. Clearly, the Program-\nmer’s Assistant was viewed by our participants as a useful tool that\nprovided real value – so much so that many participants explic-\nitly requested or expressed the desire to use it in their own work.\nHowever, how much of this value was derived from the model itself\nand its ability to produce high-quality responses to programming\nquestions, versus from participants’ ability to conduct extended\nconversational interactions grounded in their actual source code?\nWe believe that both of these constituent aspects were valuable.\nIndeed, many participants commented on their surprise and satis-\nfaction with the quality of the assistant’s responses (Section 5.2.3).\nHowever, participants also valued the conversational interactions\nthat they had with the assistant. In the event logs, we saw evi-\ndence that participants were leveraging conversational context to\nask follow-up questions as well as leveraging code context by ask-\ning about their code selections (Section 5.3.2). Many participants\nreported that they would find the tool less valuable if the conver-\nsational interaction were removed (Section 5.3.2). Further, conver-\nsation seemed to provide unique value beyond other interaction\nmodels (direct manipulation and search) because of its embedded-\nness in the UI and its ability to surface emergent behaviors of the\nmodel (Section 5.4.4).\nWe do not believe that these different interaction models are\nin competition and we agree with P39’s assessment that assistive\ntools can be built using a plethora of different interaction models.\nFor use cases in which a model is known to produce high-quality\nresults (e.g. code autocompletion for Codex), a direct manipulation\ninterface seems wholly appropriate as it would provide a discov-\nerable and predictable way of invoking the model to produce a\nknown type of result. However, direct manipulation interfaces may\nbe less ideal for surfacing the emergent behaviors of a foundation\nmodel [14], and thus natural language interaction may be more suit-\nable. Many popular text-to-image models, such as DALL-E 2 [66]\nand Stable Diffusion [72], operate in a one-shot fashion, in which\nthe user specifies a prompt, clicks a button, and gets results. Our\nstudy demonstrates how the additional contextual layers of con-\nversational history and the artifact-under-development provide\nadditional value to the co-creative process.\n6.2\nToward Human-AI Synergy\nThe aim of human-centered AI is to “enable[] people to see, think,\ncreate, and act in extraordinary ways, by combining potent user\nexperiences with embedded AI methods to support services that\nusers want” [82]. Building upon this definition, Rezwana and Maher\n[69] posit that, “In a creative collaboration, interaction dynamics,\nsuch as turn-taking, contribution type, and communication, are the\ndriving forces of the co-creative process. Therefore the interaction\nmodel is a critical and essential component for effective co-creative\nsystems.” [69]. They go on to note that, “There is relatively little\nresearch about interaction design in the co-creativity field, which\nis reflected in a lack of focus on interaction design in many existing\nco-creative systems.”\nOur study begins to address this gap. While many co-creative\nsystems examine casual tasks or experimental activities (e.g., Spoto\nand Oleynik [87]), our focus was on the co-creative practice of\nprogramming. Our goal was to understand peoples’ attitudes to-\nward a conversational programming assistant, akin to Wang et al.’s\nexamination of data scientists’ attitudes toward automated data\nscience technologies [99]. We found that, despite an initial level of\nskepticism, participants felt that a conversational assistant would\nprovide value by improving their productivity (Section 5.4.3). How-\never, further work is needed to assess the extent to which this type\nof assistance provides measurable productivity increases.\nCampero et al. [19] conducted a survey of papers published in\n2021 that examined human-AI synergy, the notion that a human-AI\nteam can accomplish more by working together than either party\ncould accomplish working alone. They found mixed results, with\nno clear consensus emerging on how to design human-centered AI\nsystems that can guarantee positive synergy. Summarizing from\ntheir discussion,\n“Perhaps achieving substantial synergies among people\nand computers is harder than many people think. Per-\nhaps it requires... new ways of configuring groups that\ninclude people and computers. And perhaps it needs\n506\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nmore systematic, focused attention from researchers\nthan it has, so far, received.” [19, p.9]\nWe believe such evaluations of human-AI synergy should go\nbeyond one-shot performance measures. As implied by many of the\nuses cases listed by Seeber et al. [80], human-centered AI systems\nare often deployed in socio-organizational contexts that require\nlongitudinal use [20, 41, 43], such as product design [93], game de-\nsign [4], and engineering [20, Section 3.2.2]. Thus, we would expect\nthat over time and through interaction with each other, human-AI\nteams would improve their performance through a mutual learning\nprocess.\nEvidence for this process surfaced in our study when participants\ndescribed how they could improve their programming skills by\ninteracting with the assistant (Section 5.3.3). We assert that the\nlearning should operate in both directions: not only should people\nimprove their programming skills, but the model itself can also\nimprove based on peoples’ interactions with it. For example, when\nthe assistant provides a code example to the user, and the user\ntakes that example and edits it, those edits constitute feedback that\ncan be used to further fine-tune the model. In addition, through\nlongitudinal use, we believe that human and AI partners can create\nreciprocal representations of one another – i.e., the human is likely\nto create a mental model of the AI, and the AI may be engineered to\ndevelop a user model for each of its human users [30, 48, 79]. Such a\npair of models is often described as Mutual Theory of Mind [29, 100].\nThis type of capability raises the possibility of personalizing and\nadapting an assistant to the strengths and needs of individual users.\nWith such models, an assistant that knows a user is learning a\nprogramming language could provide natural language explana-\ntions alongside code outputs, whereas an assistant that knows a\nuser is strongly skilled in a programming language might shorten\nor omit those explanations. Similarly, users are likely to update\ntheir mental models of the AI with more experience. We believe the\nspace for exploring how these reciprocal models impact human-AI\nsynergy is rich, and we encourage additional work in this area.\nHuman-centered AI systems that are designed to combine and\nsynergize the distinct skills of humans and AI models cannot suc-\nceed if they diminish the human skills upon which they depend.\nWell-designed human-centered AI systems develop new and com-\nplementary skills for both the human and AI constituents [82, 83],\nand we believe that mutual learning may address concerns that the\nwide deployment and use of AI systems will result in a de-skilling\nof the workforce [77, 108].\nUltimately, the design decisions that go into an interactive AI\nsystem have ethical implications. Our design attempts to augment\nthe user’s knowledge and skills by presenting help on demand,\ncouched in non-authoritative suggestions, which leaves the user\nfirmly in control and ultimately responsible for the work product.\n6.3\nOpportunities for Future Research\nOur work highlights many interesting avenues for future enhance-\nments that could be made to LLM-based conversational assistants\nsuch as our Programmer’s Assistant, as well as future human-\ncentered research on LLM-based conversational assistance.\nOur work employed a code-fluent model that was not specifi-\ncally designed to handle conversational interaction. Fine-tuning\nthe underlying LLM for conversational interaction, such as what\nhas been done with Lamda [91], is one opportunity to improve the\nassistant’s performance. Another opportunity is to align the lan-\nguage model to follow the desiderata proposed by Askell et al. [11]\nand described by Ouyang et al. as, “helpful (they should help the\nuser solve their task), honest (they shouldn’t fabricate information\nor mislead the user), and harmless (they should not cause physical,\npsychological, or social harm to people or the environment)” [61,\np.2]. Glaese et al. [33] propose a slightly different desiderata of\n“correct” instead of “honest,” which may be more applicable to the\nsoftware engineering domain, as the ability to produce correct code\nand correct answers about code are both important properties of a\nconversational programming assistant.\nCombining LLMs with search-based approaches to establish ad-\nditional context for the model, such as AlphaCode [44] has done,\nmay also result in more capable systems. These “searches” need not\nbe limited to textual sources, but could be conducted over appro-\npriate semantic stores (e.g. a knowledge graph) and take advantage\nof explicit semantic reasoning services, resulting in an integration\nof symbolic and neural approaches. Further, allowing for “internal\ndeliberation” of the type shown in Nye et al. [59] could result in\nbetter-reasoned results, as well as better explanations and justifica-\ntions.\nAnother avenue for improvement involves the prompt used to\nconfigure the assistant (Appendix D). Just as the prompt for each\nsuccessive interaction is modified by the growth of the conversa-\ntional transcript, there is no requirement that the initial prompt be\nstatic. It too can be specialized to incorporate aspects of a user model,\nenabling the realization of a Mutual Theory of Mind [29, 100]. Pro-\nviding better UX affordances for visualizing and manipulating the\nactive contexts – code and conversation – could provide users with\nmore control over which information contributes to the generation\nof the assistant’s response.\nOur participants clearly indicated that they were interested in\nhaving an assistant that behaved more proactively, in contrast to\nour deliberate design of an assistant that never takes conversational\ninitiative. A more proactive assistant would be able to interrupt or\nremind a user when necessary [23], yet this characteristic raises\nmany challenging issues. How can we calibrate the threshold for\nsuch interruptions? How can users tune the assistant to deliver only\nthose interruptions that the they would find useful (e.g., [28, 81])?\nHow can we help users to regain their prior context after dealing\nwith an interruption (e.g. [89])? Should an assistant be used to\npersuade or nudge the user (e.g. [35])? Who should determine\nthe topic, frequency, and insistence of such persuasion attempts\n(e.g. [52, 85])? Should users have the ability to moderate or defeat\nattempted persuasions, or should those decisions be left to the\norganization?\nFinally, we explored the different kinds of role orientations our\nparticipants had toward the assistant and found that participants\nvaried in their views of it as a tool versus a social agent (e.g. collabo-\nrator or colleague). We posit that peoples’ effectiveness in working\nwith an AI system may be influenced by their role orientation, and\nwe encourage future research in this area.\n507\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\n7\nCONCLUSION\nWe developed a prototype system, the Programmer’s Assistant, in\norder to assess the utility of a conversational assistant in a software\nengineering context. The assistant was implemented using a state-\nof-the-art code-fluent large language model, Codex [24], and was\ncapable of generating both code and natural language responses to\nuser inquiries. We further used the prompting mechanism of the\nmodel to set up a conversational interaction in which the model\nuses the conversational history, plus the user’s current utterance,\nin order to generate a response. In this way, users are able to ask\nfollow-up questions in the chat that reference prior utterances and\nresponses. We incorporated the conversational assistant into a code\nediting environment, enabling the conversation to be grounded in\nthe context of the user’s source code.\nWe evaluated this system with 42 participants with varied levels\nof programming skill, and their quantitative and qualitative feed-\nback, coupled with their usage of the system, demonstrated the\nvaried, and sometimes emergent, types of assistance it was able to\nprovide. Many participants noted the high quality of the conversa-\ntional responses, including the assistant’s ability to produce code,\nexplain code, answer general programming questions, and even\nanswer general knowledge questions. Participants felt this type of\nassistance would aid their productivity, and they drew meaningful\ncontrasts between the conversational style of interaction with other\ntools that employ a direct manipulation or search-based interaction\nmodel.\nOur study motivates the use of conversational styles of inter-\naction with large language models by showing how they enable\nemergent behaviors in a co-creative context. The Programmer’s\nAssistant did not always generate perfect code or correct answers;\nnonetheless, participants in our study had an overall positive ex-\nperience working with it on a variety of programming challenges.\nWe believe that our work takes us one step closer to realizing the\nvision of human-centered AI: learning how to design systems that\nmaximize the synergy in human-AI collaborations.\nACKNOWLEDGMENTS\nWe would like to thank Socrates for his tireless assistance during\nthe user study, as well as for suggesting the title of this paper based\non its abstract.\n",
            "pdfUrl" : "",
            "reference" : "[1] Rabe Abdalkareem, Emad Shihab, and Juergen Rilling. 2017. What Do Developers\nUse the Crowd For? A Study Using Stack Overflow. IEEE Software 34, 2 (2017),\n53–60. https://doi.org/10.1109/MS.2017.31\n[2] Eleni Adamopoulou and Lefteris Moussiades. 2020. Chatbots: History, technol-\nogy, and applications. Machine Learning with Applications 2 (2020), 100006.\n[3] Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel,\nRomal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\nand Quoc V. Le. 2020. Towards a Human-like Open-Domain Chatbot.\n[4] Safinah Ali, Nisha Elizabeth Devasia, and Cynthia Breazeal. 2022. Escape! Bot:\nSocial Robots as Creative Problem-Solving Partners. In Creativity and Cognition.\n275–283.\n[5] Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. 2018.\nA survey of machine learning for big code and naturalness. ACM Computing\nSurveys (CSUR) 51, 4 (2018), 1–37.\n[6] Irene Alvarado, Idan Gazit, and Amelia Wattenberger. 2022. GitHub Next |\nGitHub Copilot Labs. https://githubnext.com/projects/copilot-labs/\n[7] Hikari Ando, Rosanna Cousins, and Carolyn Young. 2014. Achieving saturation\nin thematic analysis: Development and refinement of a codebook. Comprehensive\nPsychology 3 (2014), 03–CP.\n[8] Craig Anslow, Stuart Marshall, James Noble, and Robert Biddle. 2013. Sourcevis:\nCollaborative software visualization for co-located environments. In 2013 First\nIEEE Working Conference on Software Visualization (VISSOFT). IEEE, 1–10.\n[9] Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Naren-\ndra Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian\nPan, Christine T Wolf, et al. 2021. AI-Assisted Human Labeling: Batching for\nEfficiency without Overreliance. Proceedings of the ACM on Human-Computer\nInteraction 5, CSCW1 (2021), 1–27.\n[10] Catherine A Ashworth. 1996. GUI Users have trouble using graphic conventions\non novel tasks. In Conference Companion on Human Factors in Computing Systems.\n75–76.\n[11] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom\nHenighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. 2021.\nA general language assistant as a laboratory for alignment. arXiv preprint\narXiv:2112.00861 (2021).\n[12] Leif Azzopardi, Paul Thomas, and Nick Craswell. 2018. Measuring the utility of\nsearch engine result pages: an information foraging based measure. In The 41st\nInternational ACM SIGIR conference on research & development in information\nretrieval. 605–614.\n[13] Shraddha Barke, Michael B James, and Nadia Polikarpova. 2022. Grounded\nCopilot: How Programmers Interact with Code-Generating Models. arXiv\npreprint arXiv:2206.15000 (2022).\n[14] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora,\nSydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma\nBrunskill, et al. 2021. On the opportunities and risks of foundation models.\narXiv preprint arXiv:2108.07258 (2021).\n[15] Joel Brandt, Mira Dontcheva, Marcos Weskamp, and Scott R Klemmer. 2010.\nExample-centric programming: integrating web search into the development\nenvironment. In Proceedings of the SIGCHI Conference on Human Factors in\nComputing Systems. 513–522.\n[16] Virginia Braun and Victoria Clarke. 2022. Common challenges in Thematic\nAnalysis and how to avoid them. Retrieved August 11 2022 from https://youtu.\nbe/tpWLsckpM78\n[17] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Ka-\nplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger,\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu,\nClemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott\nGray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage Models are\nFew-Shot Learners. In Advances in Neural Information Processing Systems,\nH. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33.\nCurran Associates, Inc., 1877–1901. https://proceedings.neurips.cc/paper/2020/\nfile/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[18] Sallyann Bryant, Pablo Romero, and Benedict\" du Boulay. 2006. The Collabora-\ntive Nature of Pair Programming. In Extreme Programming and Agile Processes\nin Software Engineering, Pekka Abrahamsson, Michele Marchesi, and Giancarlo\nSucci (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 53–64.\n[19] Andres Campero, Michelle Vaccaro, Jaeyoon Song, Haoran Wen, Abdullah\nAlmaatouq, and Thomas W Malone. 2022. A Test for Evaluating Performance\nin Human-Computer Systems. arXiv preprint arXiv:2206.12390 (2022).\n[20] Gaetano Cascini, Yukari Nagai, Georgi V Georgiev, Jader Zelaya, Niccolò Be-\ncattini, Jean-François Boujut, Hernan Casakin, Nathan Crilly, Elies Dekoninck,\nJohn Gero, et al. 2022. Perspectives on design creativity and innovation research:\n10 years later. , 30 pages.\n[21] Stephen Cass. 2022. Top Programming Languages 2022. IEEE Spectrum (23 Aug\n2022). https://spectrum.ieee.org/top-programming-languages-2022\n[22] Cristina Catalan Aguirre, Nuria Gonzalez Castro, Carlos Delgado Kloos, Carlos\nAlario-Hoyos, and Pedro José Muñoz Merino. 2021. Conversational agent for\nsupporting learners on a MOOC on programming with Java. (2021).\n[23] Ana Paula Chaves and Marco Aurelio Gerosa. 2021. How should my chatbot\ninteract? A survey on social characteristics in human–chatbot interaction design.\nInternational Journal of Human–Computer Interaction 37, 8 (2021), 729–758.\n[24] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared\nKaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex\nRay, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,\nAlethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe\nTillet, Felipe Petroski Such, David W. Cummings, Matthias Plappert, Fotios\nChantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol,\nIgor Babuschkin, S. Arun Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua\nAchiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M. Knight,\nMiles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario\nAmodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evalu-\nating a Large Language Models Trained on Code.\n[25] Li-Te\nCheng,\nR.B.\nDe\nSouza,\nSusanne\nHupfer,\nJohn\nPatter-\nson,\nand\nSteven\nRoss.\n2003.\nBuilding\nCollaboration\ninto\nIDEs:\nEdit>Compile>Run>Debug>Collaborate? Queue 1, 9 (2003).\n508\nThe Programmer’s Assistant\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\n[26] Carl Cook, Warwick Irwin, and Neville Churcher. 2005. A user evaluation\nof synchronous collaborative software engineering tools. In 12th Asia-Pacific\nSoftware Engineering Conference (APSEC’05). IEEE, 6–pp.\n[27] Claudio León de la Barra, Broderick Crawford, Ricardo Soto, Sanjay Misra,\nand Eric Monfroy. 2013. Agile Software Development: It Is about Knowledge\nManagement and Creativity. In Computational Science and Its Applications –\nICCSA 2013, Beniamino Murgante, Sanjay Misra, Maurizio Carlini, Carmelo M.\nTorre, Hong-Quang Nguyen, David Taniar, Bernady O. Apduhan, and Osvaldo\nGervasi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 98–113.\n[28] Uri Dekel and Steven Ross. 2004. Eclipse as a platform for research on in-\nterruption management in software development. In Proceedings of the 2004\nOOPSLA workshop on Eclipse Technology eXchange (Vancouver, British Columbia,\nCanada), Michael G. Burke (Ed.). ACM, 12–16.\n[29] Bobbie Eicher, Kathryn Cunningham, Sydni Peterson Marissa Gonzales, and\nAshok Goel. 2017. Toward mutual theory of mind as a foundation for co-creation.\nIn International Conference on Computational Creativity, Co-Creation Workshop.\n[30] Stephen M Fiore, Eduardo Salas, and Janis A Cannon-Bowers. 2001. Group\ndynamics and shared mental model development. How people evaluate others in\norganizations 234 (2001).\n[31] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. 1995. Design\npatterns: elements of reusable object-oriented software. Addison-Wesley.\n[32] GitHub, Inc. 2022. GitHub copilot · your AI pair programmer. Retrieved August\n5, 2022 from https://github.com/features/copilot/\n[33] Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu,\nTimo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe\nThacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona\nComanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie\nChen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soňa Mokrá, Nicholas\nFernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac,\nJohn Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and\nGeoffrey Irving. 2022. Improving alignment of dialogue agents via targeted\nhuman judgements. https://arxiv.org/abs/2209.14375\n[34] Stephanie Glen. 2022.\nChatGPT writes code, but won’t replace devel-\nopers.\nTechTarget (14 12 2022).\nRetrieved 20-Jan-2023 from https:\n//www.techtarget.com/searchsoftwarequality/news/252528379/ChatGPT-\nwrites-code-but-wont-replace-developers\n[35] Samuel Holmes, Anne Moorhead, Raymond Bond, Huiru Zheng, Vivien Coates,\nand Mike McTear. 2018. WeightMentor: a new automated chatbot for weight\nloss maintenance. In Proceedings of the 32nd International BCS Human Computer\nInteraction Conference 32. 1–5.\n[36] Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2020. Deep code comment\ngeneration with hybrid lexical and syntactical information. Empirical Software\nEngineering 25, 3 (2020), 2179–2217.\n[37] Edwin L Hutchins, James D Hollan, and Donald A Norman. 1985. Direct manip-\nulation interfaces. Human–computer interaction 1, 4 (1985), 311–338.\n[38] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.\nSummarizing source code using a neural attention model. In Proceedings of the\n54th Annual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers). 2073–2083.\n[39] Andreas Jedlitschka and Markus Nick. 2003. Software Engineering Knowledge\nRepositories. Springer Berlin Heidelberg, Berlin, Heidelberg, 55–80.\n[40] Eirini Kalliamvakou. 2022.\nResearch: Quantifying github copilot’s impact\non developer productivity and happiness.\nhttps://github.blog/2022-09-07-\nresearch-quantifying-github-copilots-impact-on-developer-productivity-\nand-happiness/\n[41] Anna Kantosalo et al. 2019. Human-Computer Co-Creativity: Designing, Evalu-\nating and Modelling Computational Collaborators for Poetry Writing. (2019).\n[42] Sandeep Kaur Kuttal, Bali Ong, Kate Kwasny, and Peter Robe. 2021. Trade-\nOffs for Substituting a Human with an Agent in a Pair Programming Context:\nThe Good, the Bad, and the Ugly. In Proceedings of the 2021 CHI Conference on\nHuman Factors in Computing Systems (Yokohama, Japan) (CHI ’21). Association\nfor Computing Machinery, New York, NY, USA, Article 243, 20 pages.\n[43] Lauramaria Laine. 2021. Exploring Advertising Creatives’ Attitudes Towards\nHuman-AI Collaboration. (2021).\n[44] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,\nRémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago,\nand et al. 2022. Competition-level code generation with AlphaCode.\nhttps:\n//arxiv.org/abs/2203.07814\n[45] Yaosheng Lou and Qi Sun. 2021. Over-reliance on database: A case study of\nusing web of science. Human Behavior and Emerging Technologies 3, 3 (2021),\n454–459.\n[46] David Lyell and Enrico Coiera. 2017. Automation bias and verification complex-\nity: a systematic review. Journal of the American Medical Informatics Association\n24, 2 (2017), 423–431.\n[47] Wendy E Mackay and Anne-Laure Fayard. 1997. HCI, natural science and\ndesign: a framework for triangulation across disciplines. In Proceedings of the\n2nd conference on Designing interactive systems: processes, practices, methods, and\ntechniques. 223–234.\n[48] John E Mathieu, Tonia S Heffner, Gerald F Goodwin, Eduardo Salas, and Janis A\nCannon-Bowers. 2000. The influence of shared mental models on team process\nand performance. Journal of applied psychology 85, 2 (2000), 273.\n[49] Cade Metz. 2022. Meet GPT-3. It Has Learned to Code (and Blog and Ar-\ngue). (Published 2020). https://www.nytimes.com/2020/11/24/science/artificial-\nintelligence-ai-gpt3.html\n[50] Robert J. Moore and Raphael Arar. 2019. Conversational UX Design: A Practi-\ntioner’s Guide to the Natural Conversation Framework. Association for Computing\nMachinery, New York, NY, USA.\n[51] Ekaterina A Moroz, Vladimir O Grizkevich, and Igor M Novozhilov. 2022. The\nPotential of Artificial Intelligence as a Method of Software Developer’s Produc-\ntivity Improvement. In 2022 Conference of Russian Young Researchers in Electrical\nand Electronic Engineering (ElConRus). IEEE, 386–390.\n[52] Michael Muller, Stevean Ross, Stephanie Houde, Mayank Agarwal, Fernando\nMartinez, John Richards, Kartik Talamadupula, and Justin D Weisz. 2022. Drink-\ning Chai with Your (AI) Programming Partner: A Design Fiction about Gener-\native AI for Software Engineering. HAI-GEN Workshop at IUI 2022: 3rd Work-\nshop on Human-AI Co-Creation with Generative Models (2022).\nhttps://hai-\ngen.github.io/2022/\n[53] Sandra R Murillo and J Alfredo Sánchez. 2014. Empowering interfaces for system\nadministrators: Keeping the command line in mind when designing GUIs. In\nProceedings of the XV International Conference on Human Computer Interaction.\n1–4.\n[54] Elizabeth D Mynatt and Gerhard Weber. 1994. Nonvisual presentation of graph-\nical user interfaces: contrasting two approaches. In Proceedings of the SIGCHI\nconference on Human factors in computing systems. 166–172.\n[55] Alok Mysore and Philip J Guo. 2017. Torta: Generating mixed-media gui and\ncommand-line app tutorials using operating-system-wide activity tracing. In\nProceedings of the 30th Annual ACM Symposium on User Interface Software and\nTechnology. 703–714.\n[56] C. Nass and Y. Moon. 2000. Machines and Mindlessness: Social Responses to\nComputers. Journal of Social Issues 56, 1 (2000), 81–103.\n[57] Nhan Nguyen and Sarah Nadi. 2022. An Empirical Evaluation of GitHub Copi-\nlot’s Code Suggestions. In 2022 IEEE/ACM 19th International Conference on\nMining Software Repositories (MSR). IEEE, 1–5.\n[58] Martin Nordio, H Estler, Carlo A Furia, Bertrand Meyer, et al. 2011. Collaborative\nsoftware development on the web. arXiv preprint arXiv:1105.0768 (2011).\n[59] Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Witold Michalewski, Ja-\ncob Austin, David Bieber, David Martin Dohan, Aitor Lewkowycz, Maarten Paul\nBosma, David Luan, Charles Sutton, and Augustus Odena. 2021. Show Your\nWork: Scratchpads for Intermediate Computation with Language Models.\nhttps://arxiv.org/abs/2112.00114.\n[60] OpenAI. 2022. ChatGPT: Optimizing Language Models for Dialogue. OpenAI\nBlog (30 11 2022). Retrieved 20-Jan-2023 from https://openai.com/blog/chatgpt/\n[61] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda\nAskell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training\nlanguage models to follow instructions with human feedback.\nhttps://arxiv.\norg/abs/2203.02155\n[62] Peter Pirolli and Stuart Card. 1999. Information foraging. Psychological review\n106, 4 (1999), 643.\n[63] Larry Press. 1990. Personal computing: Windows, DOS and the MAC. Commun.\nACM 33, 11 (1990), 19–26.\n[64] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya\nSutskever, et al. 2019. Language Models are Unsupervised Multitask Learners.\n[65] Alvin Rajkomar, Jeffrey Dean, and Isaac Kohane. 2019. Machine learning in\nmedicine. New England Journal of Medicine 380, 14 (2019), 1347–1358.\n[66] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.\n2022. Hierarchical text-conditional image generation with clip latents. arXiv\npreprint arXiv:2204.06125 (2022).\n[67] B. Reeves and C.I. Nass. 1996. The Media Equation: How People Treat Computers,\nTelevision, and New Media Like Real People and Places. CSLI Publications.\n[68] Mawarny Md Rejab, James Noble, and George Allan. 2014. Distributing Expertise\nin Agile Software Development Projects. In 2014 Agile Conference. 33–36.\n[69] Jeba Rezwana and Mary Lou Maher. 2021. COFI: A Framework for Modeling\nInteraction in Human-AI Co-Creative Systems.. In ICCC. 444–448.\n[70] Charles H. Rich and Richard C. Waters. 1990. The Programmer’s Apprentice.\nAddison-Wesley Publishing Company, Reading, MA.\n[71] Peter Robe and Sandeep Kaur Kuttal. 2022. Designing PairBuddy—A Conver-\nsational Agent for Pair Programming. ACM Transactions on Computer-Human\nInteraction (TOCHI) 29, 4 (2022), 1–44.\n[72] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn\nOmmer. 2022. High-resolution image synthesis with latent diffusion models. In\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni-\ntion. 10684–10695.\n509\nIUI ’23, March 27–31, 2023, Sydney, NSW, Australia\nRoss et al.\n[73] Steven Ross, Elizabeth Brownholtz, and Robert Armes. 2004.\nA Multiple-\nApplication Conversational Agent. In Proceedings of the 9th International Con-\nference on Intelligent User Interfaces (Funchal, Madeira, Portugal) (IUI ’04). Asso-\nciation for Computing Machinery, New York, NY, USA, 319–321.\n[74] Steven Ross, Elizabeth Brownholtz, and Robert Armes. 2004. Voice User Interface\nPrinciples for a Conversational Agent. In Proceedings of the 9th International\nConference on Intelligent User Interfaces (Funchal, Madeira, Portugal) (IUI ’04).\nAssociation for Computing Machinery, New York, NY, USA, 364–365.\n[75] Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot, and Guillaume Lample.\n2020. Unsupervised Translation of Programming Languages. In Advances in\nNeural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell,\nM.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 20601–20611.\n[76] Harvey Sacks. 1984. Notes on methodology. In Structures of Social Action:\nStudies in Conversation Analysis, John Heritage and J. Maxwell Atkinson (Eds.).\nCambridge University Press, Cambridge, 2–27.\n[77] Nithya Sambasivan and Rajesh Veeraraghavan. 2022. The Deskilling of Domain\nExpertise in AI Development. In CHI Conference on Human Factors in Computing\nSystems. 1–14.\n[78] Harini Sampath, Alice Merrick, and Andrew Macvean. 2021. Accessibility of\ncommand line interfaces. In Proceedings of the 2021 CHI Conference on Human\nFactors in Computing Systems. 1–10.\n[79] Matthias Scheutz, Scott A DeLoach, and Julie A Adams. 2017. A framework for\ndeveloping and using shared mental models in human-agent teams. Journal of\nCognitive Engineering and Decision Making 11, 3 (2017), 203–224.\n[80] Isabella Seeber, Eva Bittner, Robert O Briggs, Triparna De Vreede, Gert-Jan\nDe Vreede, Aaron Elkins, Ronald Maier, Alexander B Merz, Sarah Oeste-Reiß,\nNils Randrup, et al. 2020. Machines as teammates: A research agenda on AI in\nteam collaboration. Information & management 57, 2 (2020), 103174.\n[81] Shilad Sen, Werner Geyer, Michael Muller, Marty Moore, Beth Brownholtz, Eric\nWilcox, and David R Millen. 2006. FeedMe: a collaborative alert filtering system.\nIn Proceedings of the 2006 20th anniversary conference on Computer supported\ncooperative work. 89–98.\n[82] Ben Shneiderman. 2020. Human-centered artificial intelligence: Three fresh\nideas. AIS Transactions on Human-Computer Interaction 12, 3 (2020), 109–124.\n[83] Ben Shneiderman. 2022. Human-Centered AI. Oxford University Press.\n[84] Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller,\nMegan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. BlenderBot 3:\na deployed conversational agent that continually learns to responsibly engage.\narXiv preprint arXiv:2208.03188 (2022).\n[85] Michael Skirpan and Casey Fiesler. 2018. Ad empathy: A design fiction. In\nProceedings of the 2018 ACM Conference on Supporting Groupwork. 267–273.\n[86] Diomidis Spinellis. 2012. Git. IEEE Software 29, 3 (2012), 100–101.\nhttps:\n//doi.org/10.1109/MS.2012.61\n[87] Angie Spoto and Natalia Oleynik. 2017. Library of Mixed-Initiative Creative\nInterfaces. Retrieved 19-Jun-2021 from http://mici.codingconduct.cc/\n[88] Ayushi Srivastava, Shivani Kapania, Anupriya Tuli, and Pushpendra Singh.\n2021. Actionable UI Design Guidelines for Smartphone Applications Inclusive\nof Low-Literate Users. Proceedings of the ACM on Human-Computer Interaction\n5, CSCW1 (2021), 1–30.\n[89] Margaret-Anne Storey and Alexey Zagalsky. 2016. Disrupting developer produc-\ntivity one bot at a time. In Proceedings of the 2016 24th ACM SIGSOFT international\nsymposium on foundations of software engineering. 928–931.\n[90] Kartik Talamadupula. 2021. Applied AI matters: AI4Code: applying artificial\nintelligence to source code. AI Matters 7, 1 (2021), 18–20.\n[91] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul-\nshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, and\net al. 2022.\nLAMDA: Language models for dialog applications.\nhttps:\n//arxiv.org/abs/2201.08239\n[92] Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, and Neel\nSundaresan. 2020. Unit Test Case Generation with Transformers and Focal\nContext. arXiv preprint arXiv:2009.05617 (2020).\n[93] Severi Uusitalo, Anna Kantosalo, Antti Salovaara, Tapio Takala, and Christian\nGuckelsberger. 2022. Co-creative Product Design with Interactive Evolutionary\nAlgorithms: A Practice-Based Reflection. In International Conference on Compu-\ntational Intelligence in Music, Sound, Art and Design (Part of EvoStar). Springer,\n292–307.\n[94] Priyan Vaithilingam and Philip J Guo. 2019. Bespoke: Interactively synthesizing\ncustom GUIs from command-line applications by demonstration. In Proceedings\nof the 32nd annual ACM symposium on user interface software and technology.\n563–576.\n[95] Priyan Vaithilingam, Tianyi Zhang, and Elena L. Glassman. 2022. Expectation\nvs. Experience: Evaluating the Usability of Code Generation Tools Powered by\nLarge Language Models. In Extended Abstracts of the 2022 CHI Conference on\nHuman Factors in Computing Systems (New Orleans, LA, USA) (CHI EA ’22).\nAssociation for Computing Machinery, New York, NY, USA, Article 332, 7 pages.\nhttps://doi.org/10.1145/3491101.3519665\n[96] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you\nNeed. In Advances in Neural Information Processing Systems, I. Guyon, U. Von\nLuxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett\n(Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper/\n2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n[97] Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and\nPhilip S Yu. 2018. Improving automatic source code summarization via deep rein-\nforcement learning. In Proceedings of the 33rd ACM/IEEE international conference\non automated software engineering. 397–407.\n[98] April Yi Wang, Dakuo Wang, Jaimie Drozdal, Michael Muller, Soya Park, Justin D\nWeisz, Xuye Liu, Lingfei Wu, and Casey Dugan. 2022. Documentation Matters:\nHuman-Centered AI System to Assist Data Science Code Documentation in\nComputational Notebooks. ACM Transactions on Computer-Human Interaction\n29, 2 (2022), 1–33.\n[99] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer,\nCasey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray. 2019.\nHuman-AI collaboration in data science: Exploring data scientists’ perceptions\nof automated AI. Proceedings of the ACM on Human-Computer Interaction 3,\nCSCW (2019), 1–24.\n[100] Qiaosi Wang, Koustuv Saha, Eric Gregori, David Joyner, and Ashok Goel. 2021.\nTowards mutual theory of mind in human-ai interaction: How language reflects\nwhat students perceive about a virtual teaching assistant. In Proceedings of the\n2021 CHI Conference on Human Factors in Computing Systems. 1–14.\n[101] Jeremy Warner and Philip J Guo. 2017. Codepilot: Scaffolding end-to-end\ncollaborative software development for novice programmers. In Proceedings of\nthe 2017 CHI Conference on Human Factors in Computing Systems. 1136–1141.\n[102] Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross,\nFernando Martinez, Mayank Agarwal, and Kartik Talamadupula. 2021. Per-\nfection Not Required? Human-AI Partnerships in Code Translation. In 26th\nInternational Conference on Intelligent User Interfaces. 402–412.\n[103] Justin D Weisz, Michael Muller, Steven I Ross, Fernando Martinez, Stephanie\nHoude, Mayank Agarwal, Kartik Talamadupula, and John T Richards. 2022. Bet-\nter together? an evaluation of ai-supported code translation. In 27th International\nConference on Intelligent User Interfaces. 369–391.\n[104] Joseph Weizenbaum. 1966. ELIZA — a computer program for the study of\nnatural language communication between man and machine. Commun. ACM 9\n(1966), 36–45.\n[105] Frank F Xu, Bogdan Vasilescu, and Graham Neubig. 2022. In-ide code generation\nfrom natural language: Promise and challenges. ACM Transactions on Software\nEngineering and Methodology (TOSEM) 31, 2 (2022), 1–47.\n[106] Aditya Ankur Yadav, Ishan Garg, and Dr. Pratistha Mathur. 2019. PACT - Pro-\ngramming Assistant ChaTbot. In 2019 2nd International Conference on Intelligent\nCommunication and Computational Techniques (ICCT). 131–136.\n[107] Munazza Zaib, Quan Z. Sheng, and W. Zhang. 2020. A Short Survey of Pre-\ntrained Language Models for Conversational AI-A New Age in NLP. Proceedings\nof the Australasian Computer Science Week Multiconference (2020).\n[108] Elaine Zibrowski, Lisa Shepherd, Kamran Sedig, Richard Booth, Candace Gibson,\net al. 2018. Easier and faster is not always better: grounded theory of the impact\nof large-scale system transformation on the clinical work of emergency medicine\nnurses and physicians. JMIR Human Factors 5, 4 (2018), e11013.\n[109] Albert Ziegler, Eirini Kalliamvakou, X. Alice Li, Andrew Rice, Devon Rifkin,\nShawn Simister, Ganesh Sittampalam, and Edward Aftandilian. 2022. Produc-\ntivity Assessment of Neural Code Completion. In Proceedings of the 6th ACM\nSIGPLAN International Symposium on Machine Programming (San Diego, CA,\nUSA) (MAPS 2022). Association for Computing Machinery, New York, NY, USA,\n21–29. https://doi.org/10.1145/3520312.3534864\n510\n",
            "keyWords" : "code-fluent large language models, foundation models, conversa-\ntional interaction, human-centered AI\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "22",
          "_score" : 1.0,
          "_source" : {
            "title" : "Generating Diverse Code Explanations using the GPT-3 Large Language Model",
            "samary" : "",
            "authors" : "Stephen MacNeil\nstephen.macneil@temple.edu\nTemple University\nPhiladelphia, PA, USA\nAndrew Tran\nandrew.tran10@temple.edu\nTemple University\nPhiladelphia, PA, USA\nDan Mogil\ndaniel.mogil@temple.edu\nTemple University\nPhiladelphia, PA, USA\nSeth Bernstein\nseth.bernstein@temple.edu\nTemple University\nPhiladelphia, PA, USA\nErin Ross\nerinross@temple.edu\nTemple University\nPhiladelphia, PA, USA\nZiheng Huang\nz8huang@ucsd.edu\nUniversity of California—San Diego\nLa Jolla, CA, USA\n",
            "institutions" : "",
            "integralText" : "1\nABSTRACT\nGood explanations are essential to efficiently learning introductory\nprogramming concepts [10]. To provide high-quality explanations\nat scale, numerous systems automate the process by tracing the\nexecution of code [8, 12], defining terms [9], giving hints [16],\nand providing error-specific feedback [10, 16]. However, these ap-\nproaches often require manual effort to configure and only explain\na single aspect of a given code segment. Large language models\n(LLMs) are also changing how students interact with code [7]. For\nexample, Github’s Copilot can generate code for programmers [4],\nleading researchers to raise concerns about cheating [7]. Instead,\nour work focuses on LLMs’ potential to support learning by explain-\ning numerous aspects of a given code snippet. This poster features\na systematic analysis of the diverse natural language explanations\nthat GPT-3 can generate automatically for a given code snippet. We\npresent a subset of three use cases from our evolving design space\nof AI Explanations of Code.\n2\nUSE CASES\nTo understand the types of explanations GPT-3 [2] can generate,\nwe issued over 700 prompts across numerous code snippets. An\nexample prompt and resulting explanation is shown in Figure 1.\nWe discovered eight explanation types and Figure 2 includes three\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nICER 2022, August 7–11, 2022, Lugano and Virtual Event, Switzerland\n© 2022 Copyright held by the owner/author(s).\nACM ISBN 978-1-4503-9195-5/22/08.\nhttps://doi.org/10.1145/3501709.3544280\nexplanation types to illustrate the explanatory power of GPT-3. The\nadditional types include: 1) tracing the execution of code, 2) fixing\nbugs and explaining how they were fixed, 3) generating analogies\nto real world settings, 4) listing relevant programming concepts,\nand 5) predicting the console output.\n<image: DeviceRGB, width: 2550, height: 1656, bpc: 8>Figure 1: A prompt and explanation based on analogy.\n2.1\nAnalyzing and explaining time complexity\nInstructors rate time complexity as the most difficult programming\ntopic [17]. However, understanding time complexity is important [6,\n13] because it facilitates decision-making so students choose an\nappropriate algorithm for a given problem. This use case shows\nGPT-3 can identify and explain time complexity.\n2.2\nIdentifying common mistakes made by\nbeginner programmers\nCommonality exists in how students solve programming prob-\nlems [15] and the mistakes they make [1, 11]. Pedagogical tech-\nniques, such as the ‘muddiest point’ highlight these common and\nmost confusing concepts [3, 14]. GPT-3 can automatically create\na checklist of common mistakes students might make regarding a\ngiven code snippet.\n37\n<image: CalRGB, width: 1003, height: 1004, bpc: 8>ICER 2022, August 7–11, 2022, Lugano and Virtual Event, Switzerland\nMacNeil et al.\n<image: DeviceRGB, width: 3675, height: 2210, bpc: 8>Figure 2: Three example explanations automatically generated by GPT-3 for an ‘anonymized’ Binary Search code snippet.\n2.3\nSummarizing code at multiple levels of\nabstraction\nBefore understanding how a code snippet executes, it is often useful\nto understand the purpose of the code [5]. The summary gener-\nated by GPT-3 and shown in Figure 2 defines the goal, traces the\nexecution, and highlights relevant CS concepts such as arrays.\n3\nDISCUSSION\nOur three use cases demonstrate the potential for GPT-3 to explain\ncode for intro CS students. Our poster presentation will feature all\neight explanation types as a design space of explanations to convey\nthe diversity of explanations that can be generated by LLMs. We will\nhighlight best practices for generating effective explanations and\npitfalls that lead to less effective explanations. We are evaluating\nthe usefulness of these explanations in a series of summer classes.\n",
            "pdfUrl" : "",
            "reference" : "[1] Amjad Altadmri and Neil CC Brown. 2015. 37 million compilations: Investigating\nnovice programming mistakes in large-scale student data. In Proceedings of the\n46th ACM Technical Symposium on Computer Science Education. 522–527.\n[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in Neural\nInformation Processing Systems 33 (2020), 1877–1901.\n[3] Adam Carberry, Stephen Krause, Casey Ankeny, and Cynthia Waters. 2013.\n“Unmuddying” course content using muddiest point reflections. In 2013 IEEE\nFrontiers in Education Conference (FIE). IEEE, 937–942.\n[4] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira\nPinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,\net al. 2021. Evaluating large language models trained on code. arXiv preprint\narXiv:2107.03374 (2021).\n[5] Kathryn Cunningham, Yike Qiao, Alex Feng, and Eleanor O’Rourke. 2022. Bring-\ning \"High-Level\" Down to Earth: Gaining Clarity in Conversational Program-\nmer Learning Goals. In Proceedings of the 53rd ACM Technical Symposium\non Computer Science Education V. 1 (Providence, RI, USA) (SIGCSE 2022). As-\nsociation for Computing Machinery, New York, NY, USA, 551–557.\nhttps:\n//doi.org/10.1145/3478431.3499370\n[6] Elvina Elvina and Oscar Karnalim. 2017. Complexitor: An educational tool for\nlearning algorithm time complexity in practical manner. ComTech: Computer,\nMathematics and Engineering Applications 8, 1 (2017), 21–27.\n[7] James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and\nJames Prather. 2022. The Robots Are Coming: Exploring the Implications of Ope-\nnAI Codex on Introductory Programming. In Australasian Computing Education\nConference (Virtual Event, Australia) (ACE ’22). ACM, New York, NY, USA, 10–19.\nhttps://doi.org/10.1145/3511861.3511863\n[8] Philip J Guo. 2013. Online python tutor: embeddable web-based program visual-\nization for cs education. In Proceeding of the 44th ACM technical symposium on\nComputer science education. 579–584.\n[9] Andrew Head, Codanda Appachu, Marti A Hearst, and Björn Hartmann. 2015.\nTutorons: Generating context-relevant, on-demand explanations and demonstra-\ntions of online code. In 2015 IEEE Symposium on Visual Languages and Human-\nCentric Computing (VL/HCC). IEEE, 3–12.\n[10] Samiha Marwan, Ge Gao, Susan Fisk, Thomas W. Price, and Tiffany Barnes. 2020.\nAdaptive Immediate Feedback Can Improve Novice Programming Engagement\nand Intention to Persist in Computer Science. In Proceedings of the 2020 ACM\nConference on International Computing Education Research (Virtual Event, New\nZealand) (ICER ’20). Association for Computing Machinery, New York, NY, USA,\n194–203. https://doi.org/10.1145/3372782.3406264\n[11] Davin McCall and Michael Kölling. 2014. Meaningful categorisation of novice pro-\ngrammer errors. In 2014 IEEE Frontiers in Education Conference (FIE) Proceedings.\nIEEE, 1–8.\n[12] Greg L Nelson, Benjamin Xie, and Amy J Ko. 2017. Comprehension first: eval-\nuating a novel pedagogy and tutoring system for program tracing in CS1. In\nProceedings of the 2017 ACM conference on international computing education\nresearch. 2–11.\n[13] Miranda Parker and Colleen Lewis. 2014. What makes big-O analysis difficult:\nunderstanding how students understand runtime analysis. Journal of Computing\nSciences in Colleges 29, 4 (2014), 164–174.\n[14] Daniel Perez, Leila Zahedi, Monique Ross, Jia Zhu, Tiffany Vinci-Cannava, Laird\nKramer, and Maria Charters. 2020. WIP: An exploration into the muddiest points\n38\nGenerating Diverse Explanations with Large Language Models\nICER 2022, August 7–11, 2022, Lugano and Virtual Event, Switzerland\nand self-efficacy of students in introductory computer science courses. In 2020\nIEEE Frontiers in Education Conference (FIE). IEEE, 1–5.\n[15] Chris Piech, Mehran Sahami, Jonathan Huang, and Leonidas Guibas. 2015. Au-\ntonomously generating hints by inferring problem solving policies. In Proceedings\nof the second (2015) acm conference on learning@ scale. 195–204.\n[16] Thomas W Price, Yihuan Dong, and Dragan Lipovac. 2017. iSnap: towards\nintelligent tutoring in novice programming environments. In Proceedings of the\n2017 ACM SIGCSE Technical Symposium on computer science education. 483–488.\n[17] Carsten Schulte and Jens Bennedsen. 2006. What do teachers teach in introductory\nprogramming?. In Proceedings of the second international workshop on Computing\neducation research. 17–28.\n39\n",
            "keyWords" : "large language models, natural language processing, code explana-\ntions, computer science education\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "23",
          "_score" : 1.0,
          "_source" : {
            "title" : "Large Language Model Augmented Narrative Driven Recommendations",
            "samary" : "Narrative-driven recommendation (NDR) presents an informationaccess problem where users solicit recommendations with verbosedescriptions of their preferences and context, for example, travelerssoliciting recommendations for points of interest while describ-ing their likes/dislikes and travel circumstances. These requestsare increasingly important with the rise of natural language-basedconversational interfaces for search and recommendation systems.However, NDR lacks abundant training data for models, and currentplatforms commonly do not support these requests. Fortunately,classical user-item interaction datasets contain rich textual data,e.g., reviews, which often describe user preferences and context– this may be used to bootstrap training for NDR models. In thiswork, we explore using large language models (LLMs) for dataaugmentation to train NDR models. We use LLMs for authoringsynthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on syntheticqueries and user-item interaction data. Our experiments demon-strate that this is an effective strategy for training small-parameterretrieval models that outperform other retrieval and LLM baselinesfor narrative-driven recommendation.",
            "authors" : "Sheshera Mysore\nsmysore@cs.umass.edu\nUniversity of Massachusetts Amherst\nUSA\nAndrew McCallum\nmccallum@cs.umass.edu\nUniversity of Massachusetts Amherst\nUSA\nHamed Zamani\nhzamani@cs.umass.edu\nUniversity of Massachusetts Amherst\nUSA\n",
            "institutions" : "",
            "integralText" : "1\nINTRODUCTION\nRecommender systems personalized to users are an important com-\nponent of several industry-scale platforms [16, 17, 46]. These sys-\ntems function by inferring users’ interests from their prior inter-\nactions on the platform and making recommendations based on\nthese inferred interests. While recommendations based on historical\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nRecSys ’23, September 18–22, 2023, Singapore, Singapore\n© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0241-9/23/09...$15.00\nhttps://doi.org/10.1145/3604915.3608829\ninteractions are effective, users soliciting recommendations often\nstart with a vague idea about their desired target items or may\ndesire recommendations depending on the context of use, often\nmissing in historical interaction data (Figure 1). In these scenarios,\nit is common for users to solicit recommendations through long-\nform narrative queries describing their broad interests and context.\nInformation access tasks like these have been studied as narrative-\ndriven recommendations (NDR) for items ranging from books [5]\nand movies [18], to points of interest [1]. Bogers and Koolen [5]\nnote these narrative requests to be common on discussion forums\nand several subreddits1, but, there is a lack of support for these\ncomplex natural language queries in current recommenders.\nHowever, with the emergence of conversational interfaces for\ninformation access tasks, support for complex NDR tasks is likely\nto become necessary. In this context, recent work has noted an\nincrease in complex and subjective natural language requests com-\npared to more conventional search interfaces [13, 34]. Furthermore,\nthe emergence of large language models (LLM) with strong lan-\nguage understanding capabilities presents the potential for fulfilling\nsuch complex requests [9, 33]. This work explores the potential for\nre-purposing historical user-item recommendation datasets, tra-\nditionally used for training collaborative filtering recommenders,\nwith LLMs to support NDR.\nSpecifically, given a user’s interactions, \uD835\uDC37\uD835\uDC62, with items and\ntheir accompanying text documents (e.g., reviews, descriptions)\n\uD835\uDC37\uD835\uDC62 = {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1, selected from a user-item interaction dataset I, we\nprompt InstructGPT, a 175B parameter LLM, to author a synthetic\nnarrative query \uD835\uDC5E\uD835\uDC62 based on \uD835\uDC37\uD835\uDC62 (Figure 2). Since we expect the\nquery \uD835\uDC5E\uD835\uDC62 to be noisy and not fully representative of all the user\nreviews, \uD835\uDC37\uD835\uDC62 is filtered to retain only a fraction of the reviews based\non a language-model assigned likelihood of \uD835\uDC5E\uD835\uDC62 given a user doc-\nument, \uD835\uDC51\uD835\uDC56. Then, a pre-trained LM based retrieval model (110M\nparameters) is fine-tuned for retrieval on the synthetic queries and\nfiltered reviews.\nOur approach, which we refer to as Mint2, follows from the\nobservation that while narrative queries and suggestions are often\nmade in online discussion forums, and could serve as training data,\nthe number of these posts and the diversity of domains for which\nthey are available is significantly smaller than the size and diversity\nof passively gathered user-item interaction datasets. E.g. while\nBogers and Koolen [5] note nearly 25,000 narrative requests for\nbooks on the LibraryThing discussion forum, a publicly available\nuser-item interaction dataset for Goodreads contains interactions\nwith nearly 2.2M books by 460k users [43] .\nWe empirically evaluate Mint in a publicly available test collec-\ntion for point of interest recommendation: pointrec [1]. To train\n1r/MovieSuggestions, r/booksuggestions, r/Animesuggest\n2Mint: Data augMentation with INteraction narraTives.\n777\n<image: CalRGB, width: 1003, height: 1004, bpc: 8>RecSys ’23, September 18–22, 2023, Singapore, Singapore\nMysore, McCallum, Zamani\n<image: DeviceRGB, width: 1126, height: 822, bpc: 8>Figure 1: An example narrative query soliciting point of\ninterest recommendations. The query describes the users\npreferences and the context of their request.\n<image: DeviceRGB, width: 1112, height: 846, bpc: 8>Figure 2: The format of the prompt used in Mint for\ngenerating synthetic narrative queries from user-item\ninteraction with a large language model.\nour NDR models, we generate synthetic training data based on\nuser-item interaction datasets from Yelp. Models (110M parameters)\ntrained with Mint significantly outperform several baseline models\nand match the performance of significantly larger LLM baselines\nautoregressively generating recommendations. Code and synthetic\ndatasets are available:3\n2\nRELATED WORK\nData Augmentation for Information Access. A line of recent\nwork has explored using language models to generate synthetic\nqueries for data augmentation to train models for information re-\ntrieval tasks [7, 8, 15, 23, 31]. Here, given a document collection of\ninterest, a pre-trained language model is used to create synthetic\nqueries for the document collection. An optional filtering step ex-\ncludes noisy queries, and finally, a bi-encoder or a cross-encoder is\ntrained for the retrieval task. While earlier work of Ma et al. [31]\ntrain a custom query generation model on web-text datasets, more\nrecent work has leveraged large language models for zero/few-shot\nquestion generation [7, 8, 15, 23]. In generating synthetic queries,\nthis work indicates the effectiveness of smaller parameter LLMs\n(up to 6B parameters) for generating synthetic queries in simpler\ninformation-retrieval tasks [7, 8, 23], and finds larger models (100B\nparameters and above) to be necessary for harder tasks such as\nargument retrieval [15, 23]. Similar to this work, we explore the\ngeneration of synthetic queries with LLMs for a retrieval task. Un-\nlike this work, we demonstrate a data augmentation method for\ncreating effective training data from sets of user documents found in\nrecommendation datasets rather than individual documents. Other\nwork in this space has also explored training more efficient multi-\nvector models from synthetic queries instead of more expensive\ncross-encoder models [39] and generating queries with a diverse\nrange of intents than the ones available in implicit feedback datasets\nto enhance item retrievability [35].\n3https://github.com/iesl/narrative-driven-rec-mint/\nBesides creating queries for ad-hoc retrieval tasks, concurrent\nwork of Leszczynski et al. [25] has also explored the creation of syn-\nthetic conversational search datasets from music recommendation\ndatasets with LLMs. The synthetic queries and user documents are\nthen used to train bi-encoder retrieval models for conversational\nsearch. Our work resembles this in creating synthetic queries from\nsets of user items found in recommendation interaction datasets.\nHowever, it differs in the task of focus, creating long-form narra-\ntive queries for NDR. Finally, our work also builds on the recent\nperspective of Radlinski et al. [36] who make a case for natural\nlanguage user profiles driving recommenders – narrative requests\ntie closely to natural language user profiles. Our work presents a\nstep toward these systems.\nFinally, while our work explores data augmentation from user-\nitem interactions for a retrieval-oriented NDR task, prior work has\nalso explored data augmentation of the user-item graph for training\ncollaborative filtering models. This work has often explored aug-\nmentation to improve recommendation performance for minority\n[12, 47] or cold-start users [11, 28, 45]. And has leveraged genera-\ntive models [11, 45] and text similarity models [28] for augmenting\nthe user-item graph.\nComplex Queries in Information Access. With the advent\nof performant models for text understanding, focus on complex\nand interactive information access tasks has seen a resurgence\n[2, 29, 32, 48]. NDR presents an example of this – NDR was first\nformalized in Bogers and Koolen [5] for the case of book recommen-\ndation and subsequently studied in other domains [3, 4, 6]. Bogers\nand Koolen [5] systematically examined narrative requests posted\nby users on discussion forums. They defined NDR as a task requir-\ning item recommendation based on a long-form narrative query\nand prior-user item interactions. While this formulation resembles\npersonalized search [42] and query-driven recommendation [20],\nthe length and complexity of requests differentiate these from NDR.\nOther work has also demonstrated the effectiveness of re-ranking\ninitial recommendations from collaborative filtering approaches\n778\nLarge Language Model Augmented Narrative Driven Recommendations\nRecSys ’23, September 18–22, 2023, Singapore, Singapore\n<image: DeviceRGB, width: 1696, height: 354, bpc: 8>Figure 3: Mint re-purposes readily available user-item interaction datasets commonly used to train collaborative filtering\nmodels for narrative-driven recommendation. This is done by authoring narrative queries for sets of items liked by a user with\na large language model. The data is filtered with a smaller language model and retrieval models are trained on the synthetic\nqueries and user items.\nbased on the narrative query [18]. More recent work of Afzali et al.\n[1] formulate the NDR task without access to the prior interactions\nof a user while also noting the value of contextual cues contained\nin the narrative request. In our work, we focus on this latter for-\nmulation of NDR, given the lack of focus on effectively using the\nrich narrative queries in most prior work. Further, we demonstrate\nthe usefulness of data augmentation from LLMs and user-item\ninteraction datasets lacking narrative queries.\nBesides this, a range of work has explored more complex, long-\nform, and interactive query formulations for information access;\nthese resemble queries in NDR. Arguello et al. [2] define the tip of\ntongue retrieval task, a known-item search task where user queries\ndescribe the rich context of items while being unable to recall item\nmetadata itself. Mysore et al. [32] formulate an aspect conditional\nquery-by example task where results must match specific aspects of\na long natural language query. And finally, a vibrant body of work\nhas explored conversational critiquing of recommenders where nat-\nural language feedback helps tune the recommendations received\nby users [30, 44, 49].\n3\nMETHOD\n3.1\nProblem Setup\nIn our work, we define narrative-driven recommendation (NDR) to\nbe a ranking task, where given a narrative query \uD835\uDC5E made by a user\n\uD835\uDC62, a ranking system \uD835\uDC53 must generate a ranking \uD835\uDC45 over a collection\nof items C. Further, we assume access to a user-item interaction\ndataset I consisting of user interactions with items (\uD835\uDC62, {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1). We\nassume the items \uD835\uDC51\uD835\uDC56 to be textual documents like reviews or item\ndescriptions. While we don’t assume there to be any overlap in the\nusers making narrative queries or the collection of items C and the\nuser-items interaction dataset I, we assume them to be from the\nsame broad domain, e.g., books, movies, points-of-interest.\n3.2\nProposed Method\nOur proposed method, Mint, for NDR, re-purposes a dataset of\nabundantly available user-item interactions, I = {(\uD835\uDC62, {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1)} into\ntraining data for retrieval models by using LLMs as query gener-\nation models to author narrative queries \uD835\uDC5E\uD835\uDC62: D = {(\uD835\uDC5E\uD835\uDC62, {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1)}.\nThen, retrieval models are trained on the synthetic dataset D (Fig-\nure 3).\n3.2.1\nNarrative Queries from LLMs. To author a narrative query \uD835\uDC5E\uD835\uDC62\nfor a user in I, we make use of the 175B parameter InstructGPT4\nmodel as our query generation model QGen. We include the text\nof interacted items {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1 in the prompt for QGen, and instruct it\nto author a narrative query (Figure 2). To improve the coherence\nof generated queries and obtain correctly formatted outputs, we\nmanually author narrative queries for 3 topically diverse users\nbased on their interacted items and include it in the prompt for\nQGen. The same three few shot examples are used for the whole\ndataset I, and the three users were chosen from I. Generating\nnarrative queries based on user interactions may also be considered\na form of multi-document summarization for generating a natural\nlanguage user profile [36].\n3.2.2\nFiltering Items for Synthetic Queries. Since we expect user\nitems to capture multiple aspects of their interests and generated\nqueries to only capture a subset of these interests, we only retain\nsome of the items present in {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1 before using it for training re-\ntrieval models. For this, we use a pre-trained language model to com-\npute the likelihood of the query given each user item, \uD835\uDC43\uD835\uDC3F\uD835\uDC40 (\uD835\uDC5E\uD835\uDC62|\uD835\uDC51\uD835\uDC56),\nand only retain the top \uD835\uDC40 highly scoring item for \uD835\uDC5E\uD835\uDC62, this re-\nsults in \uD835\uDC40 training samples per user for our NDR retrieval models:\n{(\uD835\uDC5E\uD835\uDC62,\uD835\uDC51\uD835\uDC56)\uD835\uDC40\n\uD835\uDC56=1}. In our experiments, we use FlanT5 with 3B parame-\nters [14] for computing and follow Sachan et al. [40] for computing\n\uD835\uDC43\uD835\uDC3F\uD835\uDC40 (\uD835\uDC5E\uD835\uDC62|\uD835\uDC51\uD835\uDC56). Note that our use of \uD835\uDC43\uD835\uDC3F\uD835\uDC40 (\uD835\uDC5E\uD835\uDC62|\uD835\uDC51\uD835\uDC56) represents a query-\nlikelihood model classically used for ad-hoc search and recently\nshown to be an effective unsupervised re-ranking method when\nused with large pre-trained language models [40].\n3.2.3\nTraining Retrieval Models. We train bi-encoder and cross-\nencoder models for NDR on the generated synthetic dataset – com-\nmonly used models in search tasks. Bi-encoders are commonly used\nas scalable first-stage rankers from a large collection of items. On the\nother hand, cross-encoders allow a richer interaction between query\nand item and are used as second-stage re-ranking models. For both\nmodels, we use a pre-trained transformer language model architec-\nture with 110M parameters, MPnet, a model similar to Bert [41].\nBi-encoder models embed the query and item independently into\nhigh dimensional vectors: q\uD835\uDC62 = MPNet(\uD835\uDC5E\uD835\uDC62), d\uD835\uDC56 = MPNet(\uD835\uDC51\uD835\uDC56) and\nrank items for the user based on the minimum L2 distance between\n4https://platform.openai.com/docs/models/gpt-3, text-davinci-003\n779\nRecSys ’23, September 18–22, 2023, Singapore, Singapore\nMysore, McCallum, Zamani\nq\uD835\uDC62 and d\uD835\uDC56. Embeddings are obtained by averaging token embeddings\nfrom the final layer of MPNet, and the same model is used for both\nqueries and items. Cross-encoder models input both the query and\nitem and output a score to be used for ranking \uD835\uDC60 = \uD835\uDC53Cr([\uD835\uDC5E\uD835\uDC62;\uD835\uDC51\uD835\uDC56]),\nwhere \uD835\uDC53Cr is parameterized as w\uD835\uDC47 dropout\n�\nW\uD835\uDC47 MPNet(·)\n�\n. We\ntrain our bi-encoder model with a margin ranking loss: L\uD835\uDC35\uD835\uDC56 =\n�\n\uD835\uDC62\n�\uD835\uDC40\n\uD835\uDC56=1 max[\uD835\uDC3F2(q\uD835\uDC62, d\uD835\uDC56) − \uD835\uDC3F2(q\uD835\uDC62, d\n′\n\uD835\uDC56) + \uD835\uDEFF, 0] with randomly sam-\npled negatives \uD835\uDC51\n′ and \uD835\uDEFF = 1. Our cross-encoders are trained with\na cross-entropy loss: L\uD835\uDC36\uD835\uDC5F = �\n\uD835\uDC62\n�\uD835\uDC40\n\uD835\uDC56=1 log(\n� \uD835\uDC52\uD835\uDC60\n\uD835\uDC51′ \uD835\uDC52\uD835\uDC60′ ). For training, 4\nnegative example items \uD835\uDC51′ are randomly sampled from ranks 100-\n300 from our trained bi-encoder. At test time, we retrieve the top\n200 items with our trained bi-encoder and re-rank them with the\ncross-encoder - we evaluate both these components in experiments\nand refer to them as BiEnc-Mint and CrEnc-Mint.\n4\nEXPERIMENTS AND RESULTS\nNext, we evaluate Mint on a publicly available test collection for\nNDR and present a series of ablations.\n4.1\nExperimental Setup\n4.1.1\nDatasets. We perform evaluations on an NDR dataset for\npoint-of-interest (POI) recommendation Pointrec [1]. Pointrec\ncontains 112 realistic narrative queries (130 words long) obtained\nfrom discussion forums on Reddit and items pooled from baseline\nrankers. The items are annotated on a graded relevance scale by\ncrowd-workers and/or discussion forum members and further vali-\ndated by the dataset authors. The item collection C in Pointrec\ncontains 700k POIs with metadata (category, city) and noisy text\nsnippets describing the POI obtained from the Bing search engine.\nFor test time ranking, we only rank the candidate items in the city\nand request category (e.g., “Restaurants”) of the query available in\nPointrec - this follows prior practice to exclude clearly irrelevant\nitems [1, 26]. We use user-item interaction datasets from Yelp to\ngenerate synthetic queries for training.5 Note also that we limit our\nevaluations to Pointrec since it presents the only publicly avail-\nable, manually annotated, and candidate pooled test collection for\nNDR, to our knowledge. Other datasets for NDR use document col-\nlections that are no longer publicly accessible [24], contain sparse\nand noisy relevance judgments due to them being determined with\nautomatic rules applied to discussion threads [18, 24], lack pooling\nto gather candidates for judging relevance [18, 24], or lack realistic\nnarrative queries [21]. We leave the development of more robust\ntest collections and evaluation methods for NDR to future work.\n4.1.2\nImplementation Details. Next, we describe important details\nfor Mint and leave finer details of the model and training to our\ncode release. To sample user interactions for generating synthetic\nqueries from the Yelp dataset, we exclude POIs and users with\nfewer than ten reviews to ensure that users were regular users of\nthe site with well represented interests. This follows common prior\npractice in preparing user-item interaction datasets for use [27].\nThen we retain users who deliver an average rating greater than\n3/5 and with 10-30 above-average reviews. This desirably biases\nour data to users who commonly describe their likings (rather than\n5https://www.yelp.com/dataset\ndislikes). It also retains the users whose interests are summarizable\nby QGen. In the Yelp dataset, this results in 45,193 retained users.\nNow, 10,000 randomly selected users are chosen for generating syn-\nthetic narrative queries. For these users, a single randomly selected\nsentence from 10 of their reviews is included in the prompt (Figure\n2) to QGen, i.e., \uD835\uDC41\uD835\uDC62 = 10. After generating synthetic queries, some\nitems are filtered out (§3.2.2). Here, we exclude 40% of the items\nfor a user. This results in about 60,000 training samples for training\nBiEnc-Mint and CrEnc-Mint. These decisions were made manu-\nally by examining the resulting datasets and the cost of authoring\nqueries. The expense of generating \uD835\uDC5E\uD835\uDC62 was about USD 230.\n4.1.3\nBaselines. We compare BiEnc-Mint and CrEnc-Mint mod-\nels against several standard and performant retrieval model base-\nlines. These span zero-shot/unsupervised rankers, supervised bi-\nencoders, unsupervised cross-encoders, and LLM baselines. BM25:\nA standard unsupervised sparse retrieval baseline based on term\noverlap between query and document, with strong generalization\nperformance across tasks and domains [38]. Contriver: A BERT-base\nbi-encoder model pre-trained for zero-shot retrieval with weakly su-\npervised query-document pairs [22]. MPNet-1B: A strong Sentence-\nBert bi-encoder model initialized with MPNet-base and trained on\n1 billion supervised query-document pairs aggregated from numer-\nous domains [37]. BERT-MSM: A BERT-base bi-encoder fine-tuned\non supervised question-passage pairs from MSMarco. UPR: A two-\nstage approach that retrieves items with a Contriver bi-encoder\nand re-ranks the top 200 items with a query-likelihood model using\na FlanT5 model with 3B parameters [14, 40]. This may be seen\nas an unsupervised “cross-encoder” model. Grounded LLM: A re-\ncently proposed two-stage approach which autoregressively gener-\nates ten pseudo-relevant items using an LLM (175B InstructGPT)\nprompted with the narrative query and generates recommenda-\ntions grounded in C by retrieving the nearest neighbors for each\ngenerated item using a bi-encoder [19]. We include one few-shot\nexample of a narrative query and recommended items in the prompt\nto the LLM. We run this baseline three times and report average\nperformance across runs. We report NDCG at 5 and 10, MAP, MRR,\nand Recall at 100 and 200. Finally, our reported results should be\nconsidered lower bounds on realistic performance due to the un-\njudged documents (about 70% at \uD835\uDC58 = 10) in our test collections\n[10].\n4.2\nResults\nTable 1 presents the performance of the proposed method compared\nagainst baselines. Here, bold numbers indicate the best-performing\nmodel, and superscripts indicate statistical significance computed\nwith two-sided t-tests at \uD835\uDC5D < 0.05.\nHere, we first note the performance of baseline approaches. We\nsee BM25 outperformed by Contriver, a transformer bi-encoder\nmodel trained for zero-shot retrieval; this mirrors prior work [22].\nNext, we see supervised bi-encoder models trained on similar pas-\nsage (MPNet-1B) and question-answer (BERT-MSM) pairs outper-\nform a weakly supervised model (Contriver) by smaller margins.\nFinally, the Grounded LLM outperforms all bi-encoder baselines, in-\ndicating strong few-shot generalization and mirroring prior results\n[19]. Examining the Mint models, we first note that the BiEnc-\nMint sees statistically significant improvement compared to BM25\n780\nLarge Language Model Augmented Narrative Driven Recommendations\nRecSys ’23, September 18–22, 2023, Singapore, Singapore\nTable 1: Performance of the proposed method, Mint, for point-of-interest recommendation on Pointrec. The superscripts\ndenote statistically significant improvements compared to specific baseline models.\nPointrec\nModel\nParameters\nNDCG@5\nNDCG@10\nMAP\nMRR\nRecall@100\nRecall@200\n1BM25\n-\n0.2682\n0.2464\n0.1182\n0.2685\n0.4194\n0.5429\n2Contriver\n110M\n0.2924\n0.2776\n0.1660\n0.3355\n0.4455\n0.5552\n3MPNet-1B\n110M\n0.3038\n0.2842\n0.1621\n0.3566\n0.4439\n0.5657\n4BERT-MSM\n110M\n0.3117\n0.2886\n0.1528\n0.3320\n0.4679\n0.5816\n5Grounded LLM\n175B+110M\n0.3558\n0.3251\n0.1808\n0.3861\n0.4797\n0.5797\n6UPR\n110M+3B\n0.3586\n0.3242\n0.1712\n0.4013\n0.4489\n0.5552\nBiEnc-Mint\n110M\n0.34891\n0.32631\n0.18901\n0.39821\n0.49141\n0.6221\nCrEnc-Mint\n2×110M\n0.372512\n0.348912\n0.219214\n0.43171\n0.5448123\n0.6221\nand outperforms the best bi-encoder baselines by 11-13% on preci-\nsion measures and 5-7% on recall measures. Specifically, we see a\nmodel trained for question-answering (BERT-MSM) underperform\nBiEnc-Mint, indicating the challenge of the NDR task. Further,\nBiEnc-Mint, trained on 5 orders of magnitude lesser data than\nMPNet-1B, sees improved performance – indicating the quality of\ndata obtained from Mint. Furthermore, BiEnc-Mint also performs\nat par with a 175B LLM while offering the inference efficiency of a\nsmall-parameter bi-encoder. Next, we see CrEnc-Mint outperform\nthe baseline bi-encoders, BiEnc-Mint, UPR, and Grounded LLM\nby 4-21% on precision measures and 7-13% on recall measures –\ndemonstrating the value of Mint for training NDR models.\n4.3\nAblations\nIn Table 2, we ablate various design choices in Mint. Different\nchoices result in different training sets for the BiEnc and CrEnc\nmodels. Also, note that in reporting ablation performance for CrEnc,\nwe still use the performant BiEnc-Mint model for obtaining nega-\ntive examples for training and first-stage ranking. Without high-\nquality negative examples, we found CrEnc to result in much poorer\nperformance.\nNo item filtering. Since synthetic queries are unlikely to rep-\nresent all the items of a user, Mint excludes user items {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1\nwhich have a low likelihood of being generated from the document\n(§3.2.2). Without this step, we expect the training set for training\nretrieval models to be larger and noisier. In Table 2, we see that\nexcluding this step leads to a lower performance for BiEnc and\nCrEnc, indicating that the quality of data obtained is important for\nperformance.\n6B LLM for QGen. Mint relies on using an expensive 175B pa-\nrameter InstructGPT model for QGen. Here, we investigate the\nefficacy for generating\uD835\uDC5E\uD835\uDC62 for {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1 with a 6B parameter Instruct-\nGPT model (text-curie-001). We use an identical setup to the\n175B LLM for this. In Table 2, we see that training on the synthetic\nnarrative queries of the smaller LLM results in worse models – of-\nten underperforming the baselines in Table 1. This indicates the\ninability of a smaller model to generate complex narrative queries\nwhile conditioning on a set of user items. This necessity of a larger\nLLM for generating queries in complex retrieval tasks has been\nobserved in prior work [15, 23].\n6B LLM for Item Queries. We find a smaller 6B LLM to result\nin poor quality data when used to generate narrative queries con-\nditioned on {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1. Here we simplify the text generation task –\nusing a 6B LLM to generate queries for individual items \uD835\uDC51\uD835\uDC56. This\nexperiment also mirrors the setup for generating synthetic queries\nfor search tasks [7, 15]. Here, we use 3-few shot examples and sam-\nple one item per user for generating \uD835\uDC5E\uD835\uDC62. Given the lower cost of\nusing a smaller LLM, we use all 45,193 users in our Yelp dataset\nrather than a smaller random sample. From Table 2, we see that this\nresults in higher quality queries than using smaller LLMs for gen-\nerating narrative queries from {\uD835\uDC51\uD835\uDC56}\uD835\uDC41\uD835\uDC62\n\uD835\uDC56=1. The resulting BiEnc model\nunderperforms the BiEnc-Mint, indicating the value of generating\ncomplex queries conditioned on multiple items as in Mint for NDR.\nWe see that CrEnc approaches the performance of CrEnc-Mint–\nnote, however, that this approach uses the performant BiEnc-Mint\nfor sampling negatives and first stage ranking. We leave further\nexploration of using small parameter LLMs for data augmentation\nfor NDR models to future work.\n5\nCONCLUSIONS\nIn this paper, we present Mint, a data augmentation method for the\nnarrative-driven recommendation (NDR) task. Mint re-purposes\nhistorical user-item interaction datasets for NDR by using a 175B pa-\nrameter large language model to author long-form narrative queries\nwhile conditioning on the text of items liked by users. We evaluate\nbi-encoder and cross-encoder models trained on data from Mint on\nthe publicly available Pointrec test collection for narrative-driven\npoint of interest recommendation. We demonstrate that the result-\ning models outperform several strong baselines and ablated models\nand match or outperform a 175B LLM directly used for NDR in a\n1-shot setup.\nHowever, Mint also presents some limitations. Given our use of\nhistorical interaction datasets for generating synthetic training data\nand the prevalence of popular interests in these datasets longer,\ntailed interests are unlikely to be present in the generated syn-\nthetic datasets. In turn, causing retrieval models to likely see poorer\nperformance on these requests. Our use of LLMs to generate syn-\nthetic queries also causes the queries to be repetitive in structure,\nlikely causing novel longer-tail queries to be poorly served. These\nlimitations may be addressed in future work.\n781\nRecSys ’23, September 18–22, 2023, Singapore, Singapore\nMysore, McCallum, Zamani\nTable 2: Mint ablated for different design choices on Pointrec.\nPointrec\nAblation\nNDCG@5\nNDCG@10\nMAP\nMRR\nRecall@100\nRecall@200\nBiEnc-Mint\n0.3489\n0.3263\n0.1890\n0.3982\n0.5263\n0.6221\n− No item filtering\n0.2949\n0.2766\n0.1634\n0.3505\n0.4979\n0.5951\n− 6B LLM for QGen\n0.2336\n0.2293\n0.1125\n0.2287\n0.426\n0.5435\n− 6B LLM for Item Queries\n0.3012\n0.2875\n0.1721\n0.3384\n0.4800\n0.5909\nCrEnc-Mint\n0.3725\n0.3489\n0.2192\n0.4317\n0.5448\n0.6221\n− No item filtering\n0.3570\n0.3379\n0.2071\n0.4063\n0.5366\n0.6221\n− 6B LLM for QGen\n0.2618\n0.2421\n0.1341\n0.3118\n0.4841\n0.6221\n− 6B LLM for Item Queries\n0.3792\n0.3451\n0.2128\n0.4098\n0.5546\n0.6221\nBesides this, other avenues also present rich future work. While\nMint leverages a 175B LLM for generating synthetic queries, smaller\nparameter LLMs may be explored for this purpose - perhaps by\ntraining dedicated QGen models. Mint may also be expanded to\nexplore more active strategies for sampling items and users for\nwhom narrative queries are authored - this may allow more effi-\ncient use of large parameter LLMs while ensuring higher quality\ntraining datasets. Next, the generation of synthetic queries from\nsets of documents may be explored for a broader range of retrieval\ntasks beyond NDR given its promise to generate larger training\nsets – a currently underexplored direction. Finally, given the lack of\nlarger-scale test collections for NDR and the effectiveness of LLMs\nfor authoring narrative queries from user-item interaction, fruitful\nfuture work may also explore the creation of larger-scale datasets\nin a mixed-initiative setup to robustly evaluate models for NDR.\nACKNOWLEDGMENTS\nWe thank anonymous reviewers for their invaluable feedback. This\nwork was partly supported by the Center for Intelligent Informa-\ntion Retrieval, NSF grants IIS-1922090 and 2143434, the Office of\nNaval Research contract number N000142212688, an Amazon Alexa\nPrize grant, and the Chan Zuckerberg Initiative under the project\nScientific Knowledge Base Construction. Any opinions, findings\nand conclusions or recommendations expressed here are those of\nthe authors and do not necessarily reflect those of the sponsors.\n",
            "pdfUrl" : "",
            "reference" : "[1] Jafar Afzali, Aleksander Mark Drzewiecki, and Krisztian Balog. 2021. POINTREC:\nA Test Collection for Narrative-Driven Point of Interest Recommendation. In\nProceedings of the 44th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (Virtual Event, Canada) (SIGIR ’21). As-\nsociation for Computing Machinery, New York, NY, USA, 2478–2484.\nhttps:\n//doi.org/10.1145/3404835.3463243\n[2] Jaime Arguello, Adam Ferguson, Emery Fine, Bhaskar Mitra, Hamed Zamani, and\nFernando Diaz. 2021. Tip of the Tongue Known-Item Retrieval: A Case Study in\nMovie Identification. In Proceedings of the 6th international ACM SIGIR Conference\non Human Information Interaction and Retrieval. ACM. https://dlnext.acm.org/\ndoi/10.1145/3406522.3446021\n[3] Toine Bogers, Maria Gäde, Marijn Koolen, Vivien Petras, and Mette Skov. 2018.\n“What was this Movie About this Chick?” A Comparative Study of Relevance\nAspects in Book and Movie Discovery. In Transforming Digital Worlds: 13th Inter-\nnational Conference, iConference 2018, Sheffield, UK, March 25-28, 2018, Proceedings\n13. Springer, 323–334.\n[4] Toine Bogers, Maria Gäde, Marijn Koolen, Vivien Petras, and Mette Skov. 2019.\n“Looking for an amazing game I can relax and sink hours into...”: A Study of\nRelevance Aspects in Video Game Discovery. In Information in Contemporary\nSociety: 14th International Conference, iConference 2019, Washington, DC, USA,\nMarch 31–April 3, 2019, Proceedings 14. Springer, 503–515.\n[5] Toine Bogers and Marijn Koolen. 2017. Defining and Supporting Narrative-Driven\nRecommendation. In Proceedings of the Eleventh ACM Conference on Recommender\nSystems (Como, Italy) (RecSys ’17). Association for Computing Machinery, New\nYork, NY, USA, 238–242. https://doi.org/10.1145/3109859.3109893\n[6] Toine Bogers and Marijn Koolen. 2018. “I’m looking for something like...”:\nCombining Narratives and Example Items for Narrative-driven Book Recommen-\ndation. In Knowledge-aware and Conversational Recommender Systems Workshop.\nCEUR Workshop Proceedings.\n[7] Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira. 2022.\nInPars: Unsupervised Dataset Generation for Information Retrieval. In Proceedings\nof the 45th International ACM SIGIR Conference on Research and Development\nin Information Retrieval (Madrid, Spain) (SIGIR ’22). Association for Computing\nMachinery, New York, NY, USA, 2387–2392.\nhttps://doi.org/10.1145/3477495.\n3531863\n[8] Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayani Kundu,\nRamya Ramanathan, and Eric Nyberg. 2023. InPars-Light: Cost-Effective Unsu-\npervised Training of Efficient Rankers. arXiv:2301.02998\n[9] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter,\nChris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.\nIn Advances in Neural Information Processing Systems, H. Larochelle, M. Ran-\nzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates,\nInc., 1877–1901.\nhttps://proceedings.neurips.cc/paper_files/paper/2020/file/\n1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[10] Chris Buckley and Ellen M. Voorhees. 2004. Retrieval Evaluation with Incomplete\nInformation. In Proceedings of the 27th Annual International ACM SIGIR Conference\non Research and Development in Information Retrieval (Sheffield, United Kingdom)\n(SIGIR ’04). Association for Computing Machinery, New York, NY, USA, 25–32.\nhttps://doi.org/10.1145/1008992.1009000\n[11] Dong-Kyu Chae, Jihoo Kim, Duen Horng Chau, and Sang-Wook Kim. 2020. AR-\nCF: Augmenting Virtual Users and Items in Collaborative Filtering for Addressing\nCold-Start Problems. In Proceedings of the 43rd International ACM SIGIR Con-\nference on Research and Development in Information Retrieval (Virtual Event,\nChina) (SIGIR ’20). Association for Computing Machinery, New York, NY, USA,\n1251–1260. https://doi.org/10.1145/3397271.3401038\n[12] Lei Chen, Le Wu, Kun Zhang, Richang Hong, Defu Lian, Zhiqiang Zhang, Jun\nZhou, and Meng Wang. 2023. Improving Recommendation Fairness via Data\nAugmentation. In Proceedings of the ACM Web Conference 2023 (Austin, TX,\nUSA) (WWW ’23). Association for Computing Machinery, New York, NY, USA,\n1012–1020. https://doi.org/10.1145/3543507.3583341\n[13] Li Chen, Zhirun Zhang, Xinzhi Zhang, and Lehong Zhao. 2022. A Pilot Study\nfor Understanding Users’ Attitudes Towards a Conversational Agent for News\nRecommendation. In Proceedings of the 4th Conference on Conversational User\nInterfaces (Glasgow, United Kingdom) (CUI ’22). Association for Computing\nMachinery, New York, NY, USA, Article 36, 6 pages.\nhttps://doi.org/10.1145/\n3543829.3544530\n[14] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,\nEric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling\ninstruction-finetuned language models. arXiv preprint arXiv:2210.11416 (2022).\n[15] Zhuyun Dai, Vincent Y Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov,\nKelvin Guu, Keith Hall, and Ming-Wei Chang. 2023. Promptagator: Few-shot\n782\nLarge Language Model Augmented Narrative Driven Recommendations\nRecSys ’23, September 18–22, 2023, Singapore, Singapore\nDense Retrieval From 8 Examples. In The Eleventh International Conference on\nLearning Representations. https://openreview.net/forum?id=gmL46YMpu2J\n[16] Abhinandan S. Das, Mayur Datar, Ashutosh Garg, and Shyam Rajaram. 2007.\nGoogle News Personalization: Scalable Online Collaborative Filtering. In Pro-\nceedings of the 16th International Conference on World Wide Web (Banff, Alberta,\nCanada) (WWW ’07). Association for Computing Machinery, New York, NY, USA,\n271–280. https://doi.org/10.1145/1242572.1242610\n[17] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet,\nUllas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, and Dasarathi\nSampath. 2010. The YouTube Video Recommendation System. In Proceedings of\nthe Fourth ACM Conference on Recommender Systems (Barcelona, Spain) (RecSys\n’10). Association for Computing Machinery, New York, NY, USA, 293–296. https:\n//doi.org/10.1145/1864708.1864770\n[18] Lukas Eberhard, Simon Walk, Lisa Posch, and Denis Helic. 2019. Evaluating\nNarrative-Driven Movie Recommendations on Reddit. In Proceedings of the 24th\nInternational Conference on Intelligent User Interfaces (Marina del Ray, California)\n(IUI ’19). Association for Computing Machinery, New York, NY, USA, 1–11. https:\n//doi.org/10.1145/3301275.3302287\n[19] Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2022. Precise Zero-Shot\nDense Retrieval without Relevance Labels. arXiv preprint arXiv:2212.10496 (2022).\n[20] Negar Hariri, Bamshad Mobasher, and Robin Burke. 2013. Query-Driven Context\nAware Recommendation. In Proceedings of the 7th ACM Conference on Recom-\nmender Systems (Hong Kong, China) (RecSys ’13). Association for Computing\nMachinery, New York, NY, USA, 9–16. https://doi.org/10.1145/2507157.2507187\n[21] Seyyed Hadi Hashemi, Jaap Kamps, Julia Kiseleva, Charles LA Clarke, and Ellen M\nVoorhees. 2016. Overview of the TREC 2016 Contextual Suggestion Track.. In\nTREC.\n[22] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bo-\njanowski, Armand Joulin, and Edouard Grave. 2022. Unsupervised Dense Infor-\nmation Retrieval with Contrastive Learning. Transactions on Machine Learning\nResearch (2022). https://openreview.net/forum?id=jKN1pXi7b0\n[23] Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo,\nJakub Zavrel, and Rodrigo Nogueira. 2023. InPars-v2: Large Language Models as\nEfficient Dataset Generators for Information Retrieval. arXiv:2301.01820\n[24] Marijn Koolen, Toine Bogers, Maria Gäde, Mark Hall, Iris Hendrickx, Hugo\nHuurdeman, Jaap Kamps, Mette Skov, Suzan Verberne, and David Walsh. 2016.\nOverview of the CLEF 2016 Social Book Search Lab. In Experimental IR Meets Mul-\ntilinguality, Multimodality, and Interaction, Norbert Fuhr, Paulo Quaresma, Teresa\nGonçalves, Birger Larsen, Krisztian Balog, Craig Macdonald, Linda Cappellato,\nand Nicola Ferro (Eds.). Springer International Publishing, Cham, 351–370.\n[25] Megan Leszczynski, Ravi Ganti, Shu Zhang, Krisztian Balog, Filip Radlinski,\nFernando Pereira, and Arun Tejasvi Chaganty. 2023. Generating Synthetic Data\nfor Conversational Music Recommendation Using Random Walks and Language\nModels. arXiv:2301.11489\n[26] Xin Liu, Yong Liu, Karl Aberer, and Chunyan Miao. 2013. Personalized Point-of-\nInterest Recommendation by Mining Users’ Preference Transition. In Proceedings\nof the 22nd ACM International Conference on Information & Knowledge Manage-\nment (San Francisco, California, USA) (CIKM ’13). Association for Computing Ma-\nchinery, New York, NY, USA, 733–738. https://doi.org/10.1145/2505515.2505639\n[27] Yiding Liu, Tuan-Anh Nguyen Pham, Gao Cong, and Quan Yuan. 2017. An\nExperimental Evaluation of Point-of-Interest Recommendation in Location-Based\nSocial Networks. Proc. VLDB Endow. 10, 10 (jun 2017), 1010–1021. https://doi.\norg/10.14778/3115404.3115407\n[28] Federico López, Martin Scholz, Jessica Yung, Marie Pellat, Michael Strube, and\nLucas Dixon. 2021. Augmenting the user-item graph with textual similarity\nmodels. arXiv preprint arXiv:2109.09358 (2021).\n[29] Xing Han Lu, Siva Reddy, and Harm de Vries. 2023. The StatCan Dialogue\nDataset: Retrieving Data Tables through Conversations with Genuine Intents. In\nProceedings of the 17th Conference of the European Chapter of the Association for\nComputational Linguistics. Association for Computational Linguistics, Dubrovnik,\nCroatia, 2799–2829. https://aclanthology.org/2023.eacl-main.206\n[30] Kai Luo, Scott Sanner, Ga Wu, Hanze Li, and Hojin Yang. 2020. Latent Linear\nCritiquing for Conversational Recommender Systems. In The Web Conference.\n[31] Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. 2021. Zero-shot\nNeural Passage Retrieval via Domain-targeted Synthetic Question Generation.\nIn Proceedings of the 16th Conference of the European Chapter of the Associa-\ntion for Computational Linguistics: Main Volume. Association for Computational\nLinguistics, Online, 1075–1088. https://doi.org/10.18653/v1/2021.eacl-main.92\n[32] Sheshera Mysore, Tim O’Gorman, Andrew McCallum, and Hamed Zamani. 2021.\nCSFCube - A Test Collection of Computer Science Research Articles for Faceted\nQuery by Example. In Thirty-fifth Conference on Neural Information Processing\nSystems Datasets and Benchmarks Track (Round 2). https://doi.org/10.48550/arXiv.\n2103.12906\n[33] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda\nAskell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with human feedback. In\nAdvances in Neural Information Processing Systems, S. Koyejo, S. Mohamed,\nA. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates,\nInc., 27730–27744. https://proceedings.neurips.cc/paper_files/paper/2022/file/\nb1efde53be364a73914f58805a001731-Paper-Conference.pdf\n[34] Andrea Papenmeier, Dagmar Kern, Daniel Hienert, Alfred Sliwa, Ahmet Aker,\nand Norbert Fuhr. 2021. Starting Conversations with Search Engines - Interfaces\nThat Elicit Natural Language Queries. In Proceedings of the 2021 Conference on\nHuman Information Interaction and Retrieval (Canberra ACT, Australia) (CHIIR\n’21). Association for Computing Machinery, New York, NY, USA, 261–265. https:\n//doi.org/10.1145/3406522.3446035\n[35] Gustavo Penha, Enrico Palumbo, Maryam Aziz, Alice Wang, and Hugues\nBouchard. 2023. Improving Content Retrievability in Search with Controllable\nQuery Generation. In Proceedings of the ACM Web Conference 2023 (Austin, TX,\nUSA) (WWW ’23). Association for Computing Machinery, New York, NY, USA,\n3182–3192. https://doi.org/10.1145/3543507.3583261\n[36] Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon, and Ben Wedin.\n2022. On Natural Language User Profiles for Transparent and Scrutable Rec-\nommendation. In Proceedings of the 45th International ACM SIGIR Conference\non Research and Development in Information Retrieval (Madrid, Spain) (SIGIR\n’22). Association for Computing Machinery, New York, NY, USA, 2863–2874.\nhttps://doi.org/10.1145/3477495.3531873\n[37] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings\nusing Siamese BERT-Networks. In Proceedings of the 2019 Conference on Em-\npirical Methods in Natural Language Processing. Association for Computational\nLinguistics. https://arxiv.org/abs/1908.10084\n[38] Stephen Robertson and Hugo Zaragoza. 2009.\nThe Probabilistic Relevance\nFramework: BM25 and Beyond. Found. Trends Inf. Retr. 3, 4 (apr 2009), 333–389.\nhttps://doi.org/10.1561/1500000019\n[39] Jon Saad-Falcon, Omar Khattab, Keshav Santhanam, Radu Florian, Martin\nFranz, Salim Roukos, Avirup Sil, Md Arafat Sultan, and Christopher Potts. 2023.\nUDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation\nof Rerankers. arXiv:2303.00807 [cs.IR]\n[40] Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau\nYih, Joelle Pineau, and Luke Zettlemoyer. 2022. Improving Passage Retrieval\nwith Zero-Shot Question Generation. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing. Association for Computational\nLinguistics, Abu Dhabi, United Arab Emirates, 3781–3797. https://aclanthology.\norg/2022.emnlp-main.249\n[41] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020. MPNet: Masked\nand Permuted Pre-training for Language Understanding. In Advances in Neural\nInformation Processing Systems, Vol. 33. https://proceedings.neurips.cc/paper_\nfiles/paper/2020/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf\n[42] Jaime Teevan, Susan T. Dumais, and Eric Horvitz. 2005. Personalizing Search via\nAutomated Analysis of Interests and Activities. In Proceedings of the 28th Annual\nInternational ACM SIGIR Conference on Research and Development in Information\nRetrieval (Salvador, Brazil) (SIGIR ’05). Association for Computing Machinery,\nNew York, NY, USA, 449–456. https://doi.org/10.1145/1076034.1076111\n[43] Mengting Wan and Julian McAuley. 2018. Item Recommendation on Monotonic\nBehavior Chains. In Proceedings of the 12th ACM Conference on Recommender\nSystems (Vancouver, British Columbia, Canada) (RecSys ’18). Association for\nComputing Machinery, New York, NY, USA, 86–94.\nhttps://doi.org/10.1145/\n3240323.3240369\n[44] Haonan Wang, Chang Zhou, Carl Yang, Hongxia Yang, and Jingrui He. 2021.\nControllable Gradient Item Retrieval. In Web Conference.\n[45] Qinyong Wang, Hongzhi Yin, Hao Wang, Quoc Viet Hung Nguyen, Zi Huang,\nand Lizhen Cui. 2019. Enhancing Collaborative Filtering with Generative Aug-\nmentation. In Proceedings of the 25th ACM SIGKDD International Conference\non Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD ’19). As-\nsociation for Computing Machinery, New York, NY, USA, 548–556.\nhttps:\n//doi.org/10.1145/3292500.3330873\n[46] Jiajing Xu, Andrew Zhai, and Charles Rosenberg. 2022. Rethinking Personalized\nRanking at Pinterest: An End-to-End Approach. In Proceedings of the 16th ACM\nConference on Recommender Systems (Seattle, WA, USA) (RecSys ’22). Association\nfor Computing Machinery, New York, NY, USA, 502–505.\nhttps://doi.org/10.\n1145/3523227.3547394\n[47] Yuxin Ying, Fuzhen Zhuang, Yongchun Zhu, Deqing Wang, and Hongwei Zheng.\n2023. CAMUS: Attribute-Aware Counterfactual Augmentation for Minority Users\nin Recommendation. In Proceedings of the ACM Web Conference 2023 (Austin, TX,\nUSA) (WWW ’23). Association for Computing Machinery, New York, NY, USA,\n1396–1404. https://doi.org/10.1145/3543507.3583538\n[48] Hamed Zamani, Johanne R Trippas, Jeff Dalton, and Filip Radlinski. 2022. Con-\nversational information seeking. arXiv preprint arXiv:2201.08808 (2022).\n[49] Jie Zou, Yifan Chen, and Evangelos Kanoulas. 2020. Towards Question-Based\nRecommender Systems. In Proceedings of the 43rd International ACM SIGIR Confer-\nence on Research and Development in Information Retrieval (Virtual Event, China)\n(SIGIR ’20). Association for Computing Machinery, New York, NY, USA, 881–890.\nhttps://doi.org/10.1145/3397271.3401180\n783\n",
            "keyWords" : "Error : Keywords not found"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "26",
          "_score" : 1.0,
          "_source" : {
            "title" : "SMT 2.0 : A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes",
            "samary" : "",
            "authors" : "Paul Saves a,b,∗,1, Rémi Lafage a,1, Nathalie Bartoli a,1, Youssef Diouane c,1, Jasper Bussemaker d,1,\nThierry Lefebvre a,1, John T. Hwang e,1, Joseph Morlier f,1, Joaquim R.R.A. Martins g,1\na ONERA/DTIS, Université de Toulouse, Toulouse, France\nb ISAE-SUPAERO, Université de Toulouse, Toulouse, France\nc Polytechnique Montréal, Montreal, QC, Canada\nd German Aerospace Center (DLR), Institute of System Architectures in Aeronautics, Hamburg, Germany\ne University of California San Diego, Department of Mechanical and Aerospace Engineering, La Jolla, CA, USA\nf ICA, Université de Toulouse, ISAE–SUPAERO, INSA, CNRS, MINES ALBI, UPS, Toulouse, France\ng University of Michigan, Department of Aerospace Engineering, Ann Arbor, MI, USA\n",
            "institutions" : "",
            "integralText" : "1. Motivation and significance\nWith the increasing complexity and accuracy of numerical models, it\nhas become more challenging to run complex simulations and computer\ncodes [1,2]. As a consequence, surrogate models have been recognized\nas a key tool for engineering tasks such as design space exploration,\nuncertainty quantification, and optimization [3]. In practice, surrogate\nmodels are used to reduce the computational effort of these tasks by\nreplacing expensive numerical simulations with closed-form approxi-\nmations [4, Ch. 10]. To build such a model, we start by evaluating\nthe original expensive simulation at a set of points through a Design\nof Experiments (DoE). Then, the corresponding evaluations are used to\nbuild the surrogate model according to the chosen approximation, such\nas Kriging, quadratic interpolation, or least squares regression.\nThe Surrogate Modeling Toolbox (SMT) is an open-source frame-\nwork that provides functions to efficiently build surrogate models [5].\n∗ Corresponding author at: ONERA/DTIS, Université de Toulouse, Toulouse, France.\nE-mail addresses: paul.saves@onera.fr (P. Saves), remi.lafage@onera.fr (R. Lafage), nathalie.bartoli@onera.fr (N. Bartoli), youssef.diouane@polymtl.ca\n(Y. Diouane), jasper.bussemaker@dlr.de (J. Bussemaker), thierry.lefebvre@onera.fr (T. Lefebvre), jhwang@eng.ucsd.edu (J.T. Hwang),\njoseph.morlier@isae-supaero.fr (J. Morlier), jrram@umich.edu (J.R.R.A. Martins).\n1 All authors contributed to this work, research and manuscript.\n2 https://github.com/SMTorg/SMT\nKriging models (also known as Gaussian processes) that take advantage\nof derivative information are one of SMT’s key features [6]. Numerical\nexperiments have shown that SMT achieved lower prediction error\nand computational cost than Scikit-learn [7] and UQLab [8] for a\nfixed number of points [9]. SMT has been applied to rocket engine\ncoaxial-injector optimization [10], aircraft engine consumption mod-\neling [11], numerical integration [12], multi-fidelity sensitivity analy-\nsis [13], high-order robust finite elements methods [14,15], planning\nfor photovoltaic solar energy [16], wind turbines design optimiza-\ntion [17], porous material optimization for a high pressure turbine\nvane [18], chemical process design [19] and many other applications.\nIn systems engineering, architecture-level choices significantly in-\nfluence the final system performance, and therefore, it is desirable to\nconsider such choices in the early design phases [20]. Architectural\nchoices are parameterized with discrete design variables; examples in-\nclude the selection of technologies, materials, component connections,\nhttps://doi.org/10.1016/j.advengsoft.2023.103571\nReceived 22 August 2023; Received in revised form 23 October 2023; Accepted 26 November 2023\nAdvances in Engineering Software 188 (2024) 103571\n2\nP. Saves et al.\nTable 1\nComparison of software packages for hierarchical and mixed Kriging models. ✓= implemented. * = user-defined.\nPackage\nBOTorch\nDakota\nDiceKriging\nKerGP\nLVGP\nParmoo\nSpearmint\nSMT 2.0\nReference\n[25]\n[26]\n[27]\n[32]\n[28]\n[29]\n[30]\nThis paper\nLicense\nMIT\nEPL\nGPL\nGPL\nGPL\nBSD\nGNU\nBSD\nLanguage\nPython\nC\nR\nR\nR\nPython\nPython\nPython\nMixed var.\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\nGD kernel\n✓\n✓\n✓\n*\n✓\nCR kernel\n✓\n✓\n✓\n✓\nHH kernel\n✓\n✓\nEHH kernel\n*\n✓\nHierarchical var.\n✓\nand number of instantiated elements. When design problems include\nboth discrete variables and continuous variables, they are said to have\nmixed variables.\nWhen architectural choices lead to different sets of design variables,\nwe have hierarchical variables [21,22]. For example, consider differ-\nent aircraft propulsion architectures [23]. A conventional gas turbine\nwould not require a variable to represent a choice in the electrical\npower source, while hybrid or pure electric propulsion would require\nsuch a variable. The relationship between the choices and the sets of\nvariables can be represented by a hierarchy.\nHandling hierarchical and mixed variables requires specialized sur-\nrogate modeling techniques [24]. To address these needs, SMT 2.0\nis offering researchers and practitioners a collection of cutting-edge\ntools to build surrogate models with continuous, mixed and hierarchical\nvariables. The main objective of this paper is to detail the new enhance-\nments that have been added in this release compared to the original\nSMT 0.2 release [5].\nThere are two new major capabilities in SMT 2.0: the ability\nto build surrogate models involving mixed variables and the support\nfor hierarchical variables within Kriging models. To handle mixed\nvariables in Kriging models, existing libraries such as BoTorch [25],\nDakota [26], DiceKriging [27], LVGP [28], Parmoo [29], and Spearmint\n[30] implement simple mixed models by using either continuous relax-\nation (CR), also known as one-hot encoding [30], or a Gower distance\n(GD) based correlation kernel [31]. KerGP [32] (developed in R) imple-\nments more general kernels but there is no Python open-source toolbox\nthat implements more general kernels to deal with mixed variables,\nsuch as the homoscedastic hypersphere (HH) [33] and exponential\nhomoscedastic hypersphere (EHH) [34] kernels. Such kernels require\nthe tuning of a large number of hyperparameters but lead to more\naccurate Kriging surrogates than simpler mixed kernels [34,35]. SMT\n2.0 implements all these kernels (CR, GD, HH, and EHH) through a\nunified framework and implementation. To handle hierarchical vari-\nables, no library in the literature can build peculiar surrogate models\nexcept SMT 2.0, which implements two Kriging methods for these\nvariables. Notwithstanding, most softwares are compatible with a naïve\nstrategy called the imputation method [24] but this method lacks depth\nand depends on arbitrary choices. This is why Hutter and Osborne\n[21] proposed a first kernel, called Arc-Kernel which in turn was\ngeneralized by Horn et al. [36] with a new kernel called the Wedge-\nKernel [37]. None of these kernels are available in any open-source\nmodeling software. Furthermore, thanks to the framework introduced\nin Audet et al. [38], our proposed kernels are sufficiently general so\nthat all existing hierarchical kernels are included within it. Section 4\ndescribes the two kernels implemented in SMT 2.0 that are referred\nas SMT Arc-Kernel and SMT Alg-Kernel. In particular, Alg-\nKernel is a novel hierarchical kernel introduced in this paper. Table 1\noutlines the main features of the state-of-the-art modeling software that\ncan handle hierarchical and mixed variables.\nSMT 2.0 introduces other enhancements, such as additional sam-\npling procedures, new surrogate models, new Kriging kernels (and their\nderivatives), Kriging variance derivatives, and an adaptive criterion for\nhigh-dimensional problems. SMT 2.0 adds applications of Bayesian\noptimization (BO) with hierarchical and mixed variables or noisy co-\nKriging that have been successfully applied to aircraft design [39], data\nfusion [40], and structural design [41]. The SMT 2.0 interface is more\nuser-friendly and offers an improved and more detailed documentation\nfor users and developers.3 SMT 2.0 is hosted publicly4 and can be\ndirectly imported within Python scripts. It is released under the New\nBSD License and runs on Linux, MacOS, and Windows operating sys-\ntems. Regression tests are run automatically for each operating system\nwhenever a change is committed to the repository. In short, SMT 2.0\nbuilds on the strengths of the original SMT package while adding new\nfeatures. On one hand, the emphasis on derivatives (including predic-\ntion, training and output derivatives) is maintained and improved in\nSMT 2.0. On the other hand, this new release includes support for\nhierarchical and mixed variables Kriging based models. For the sake\nof reproducibility, an open-source notebook is available that gathers\nall the methods and results presented on this paper.5\nThe remainder of the paper is organized as follows. First, we in-\ntroduce the organization and the main implemented features of the\nrelease in Section 2. Then, we describe the mixed-variable Kriging\nmodel with an example in Section 3. Similarly, we describe and provide\nan example for a hierarchical-variable Kriging model in Section 4.\nThe Bayesian optimization models and applications are described in\nSection 5. Finally, we describe the other relevant contributions in\nSection 6 and conclude in Section 7.\n2. SMT 2.0 : an improved surrogate modeling toolbox\nFrom a software point of view, SMT 2.0 maintains and improves\nthe modularity and generality of the original SMT version [5]. In this\nsection, we describe the software as follows. Section 2.1 describes the\nlegacy of SMT 0.2. Then, Section 2.2 describes the organization of the\nrepository. Finally, Section 2.3 shows the new capabilities implemented\nin the SMT 2.0 update.\n2.1. Background on SMT former version: SMT 0.2\nSMT [5] is an open-source collaborative work originally developed\nby ONERA, NASA Glenn, ISAE-SUPAERO/ICA and the University of\nMichigan. Now, both Polytechnique Montréal and the University of\nCalifornia San Diego are also contributors. SMT 2.0 updates and ex-\ntends the original SMT repository capabilities among which the original\npublication [5] focuses on different types of derivatives for surrogate\nmodels detailed hereafter.\n3 http://smt.readthedocs.io/en/latest\n4 https://github.com/SMTorg/smt\n5 https://github.com/SMTorg/smt/tree/master/tutorial/\nNotebookRunTestCases_Paper_SMT_v2.ipynb\nAdvances in Engineering Software 188 (2024) 103571\n3\nP. Saves et al.\nTable 2\nImpact of using Numba on training time of the hierarchical Goldstein problem. Speedup\nis calculated excluding the JIT compilation table, as this step is only needed once after\nSMT installation.\nTraining set\nWithout numba\nNumba\nSpeedup\nJIT overhead\n15 points\n1.3 s\n1.1 s\n15%\n24 s\n150 points\n38 s\n7.4 s\n80%\n23 s\nA Python surrogate modeling framework with derivatives. One of the\noriginal main motivations for SMT was derivative support. In fact, none\nof the existing packages for surrogate modeling such as Scikit-learn in\nPython [7], SUMO in Matlab [42] or GPML in Matlab and Octave [43]\nfocuses on derivatives. Three types of derivatives are distinguished:\nprediction derivatives, training derivatives, and output derivatives.\nSMT also includes new models with derivatives such as Kriging with\nPartial Least Squares (KPLS) [44] and Regularized Minimal-energy\nTensor-product Spline (RMTS) [3]. These developed derivatives were\neven used in a novel algorithm called Gradient-Enhanced Kriging with\nPartial Least Squares (GEKPLS) [6] to use with adjoint methods, for\nexample [45].\nSoftware architecture, documentation, and automatic testing. SMT is orga-\nnized along three main sub-modules that implement a set of sampling\ntechniques (sampling_methods), benchmarking functions (problems),\nand surrogate modeling techniques (surrogate_models). The toolbox\ndocumentation6 is created using reStructuredText and Sphinx, a doc-\numentation generation package for Python, with custom extensions.\nCode snippets in the documentation pages are taken directly from\nactual tests in the source code and are automatically updated. The\noutput from these code snippets and tables of options are generated\ndynamically by custom Sphinx extensions. This leads to high-quality\ndocumentation with minimal effort. Along with user documentation,\ndeveloper documentation is also provided to explain how to contribute\nto SMT. This includes a list of API methods for the SurrogateModel,\nSamplingMethod, and Problem classes, that must be implemented\nto create a new surrogate modeling method, sampling technique, or\nbenchmarking problem. When a developer submits a pull request, it is\nmerged only after passing the automated tests and receiving approval\nfrom at least one reviewer. The repository on GitHub7 is linked to\ncontinuous integration tests (GitHub Actions) for Windows, Linux and\nMacOS, to a coverage test on coveralls.io and to a dependency version\ncheck for Python with DependaBot. Various parts of the source code\nhave been accelerated using Numba [46], an LLVM-based just-in-time\n(JIT) compiler for numpy-heavy Python code. Numba is applied to con-\nventional Python code using function decorators, thereby minimizing\nits impact on the development process and not requiring an additional\nbuild step. For a mixed Kriging surrogate with 150 training points, a\nspeedup of up to 80% is observed, see Table 2. The JIT compilation\nstep only needs to be done once when installing or upgrading SMT\nand adds an overhead of approximately 24 s on a typical workstation\nIn this paper, all results are obtained using an Intel® Xeon® CPU\nE5-2650 v4 @ 2.20 GHz core and 128 GB of memory with a Broadwell-\ngeneration processor front-end and a compute node of a peak power of\n844 GFlops.\n2.2. Organization of SMT 2.0\nThe main features of the open-source repository SMT 2.0 are\ndescribed in Fig. 1. More precisely, Sampling Methods, Problems\nand Surrogate models are kept from SMT 0.2 and two new\nsections Models applications and Interactive notebooks\nhave been added to the architecture of the code. These sections are\n6 https://smt.readthedocs.org\n7 https://github.com/SMTorg/smt\nhighlighted in blue and detailed on Fig. 1. The new major features\nimplemented in SMT 2.0 are highlighted in lavender whereas the\nlegacy features that were already in present in the original publication\nfor SMT 0.2 [5] are in black.\n2.3. New features within SMT 2.0\nThe main objective of this new release is to enable Kriging surrogate\nmodels for use with both hierarchical and mixed variables. Moreover,\nfor each of these five sub-modules described in Section 2.2, several\nimprovements have been made between the original version and the\nSMT 2.0 release.\nHierarchical and mixed design space. A new design space definition\nclass DesignSpace has been added that implements hierarchical\nand mixed functionalities. Design variables can either be continu-\nous (FloatVariable), ordered (OrdinalVariable) or categorical\n(CategoricalVariable). The integer type (IntegerVariable) rep-\nresents a special case of the ordered variable, specified by bounds\n(inclusive) rather than a list of possible values. The hierarchical struc-\nture of the design space can be defined using declare_decreed_var:\nthis function declares that a variable is a decreed variable that is\nactivated when the associated meta variable takes one of a set of\nspecified values, see Section 4 for background. The DesignSpace\nclass also implements mechanisms for sampling valid design vectors\n(i.e. design vectors that adhere to the hierarchical structure of the\ndesign space) using any of the below-mentioned samplers, for cor-\nrecting and imputing design vectors, and for requesting which design\nvariables are acting in a given design vector. Correction ensures that\nvariables have valid values (e.g. integers for discrete variables) [24],\nand imputation replaces non-acting variables by some default value\n(0 for discrete variables, mid-way between the bounds for continuous\nvariables in SMT 2.0) [47].\nSampling. SMT implements three methods for sampling. The first one\nis a naïve approach, called Random that draws uniformly points along\nevery dimension. The second sampling method is called Full Fac-\ntorial and draws a point for every cross combination of variables,\nto have an ‘‘exhaustive’’ design of experiments. The last one is the\nLatin Hypercube Sampling (LHS) [48] that draws a point in\nevery Latin square parameterized by a certain criterion. For LHS, a\nnew criterion to manage the randomness has been implemented and\nthe sampling method was adapted for multi-fidelity and mixed or\nhierarchical variables. More details about the new sampling techniques\nare given in Section 6.1.\nProblems. SMT implements two new engineering problems: a mixed\nvariant of a cantilever beam described in Section 3 and a hierarchical\nneural network described in Section 4.\nSurrogate models. In order to keep up with state-of-art, several re-\nleases done from the original version developed new options for the\nalready existing surrogates. In particular, compared to the original\npublication [5], SMT 2.0 adds gradient-enhanced neural networks [45]\nand marginal Gaussian process [49] models to the list of available\nsurrogates. More details about the new models are given in Section 6.2.\nApplications. Several applications have been added to the toolbox to\ndemonstrate the surrogate models capabilities. The most relevant ap-\nplication is efficient global optimization (EGO), a Bayesian optimiza-\ntion algorithm [50,51]. EGO optimizes expensive-to-evaluate black-box\nproblems with a chosen surrogate model and a chosen optimization\ncriterion [52]. The usage of EGO with hierarchical and mixed variables\nis described in Section 5.\nAdvances in Engineering Software 188 (2024) 103571\n4\nP. Saves et al.\n<image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 1301, height: 1893, bpc: 8>Fig. 1. Functionalities of SMT 2.0. The new major features implemented in SMT 2.0 compared to SMT 0.2 are highlighted with the lavender color.\nInteractive notebooks. These tutorials introduce and explain how to use\nthe toolbox for different surrogate models and applications.8 Every\ntutorial is available both as a .ipynb file and directly on Google\ncolab.9 In particular, a hierarchical and mixed variables dedicated\nnotebook is available to reproduce the results presented on this paper.10\nIn the following, Section 3 details the Kriging based surrogate\nmodels for mixed variables, and Section 4 presents our new Kriging\nsurrogate for hierarchical variables. Section 5 details the EGO applica-\ntion and the other new relevant features aforementioned are described\nsuccinctly in Section 6.\n8 https://github.com/SMTorg/smt/tree/master/tutorial\n9 https://colab.research.google.com/github/SMTorg/smt/\n10 https://github.com/SMTorg/smt/tree/master/tutorial/\nNotebookRunTestCases_Paper_SMT_v2.ipynb\n3. Surrogate models with mixed variables in SMT 2.0\nAs mentioned in Section 1, design variables can be either of continu-\nous or discrete type, and a problem with both types is a mixed-variable\nproblem. Discrete variables can be ordinal or categorical. A discrete\nvariable is ordinal if there is an order relation within the set of possible\nvalues. An example of an ordinal design variable is the number of\nengines in an aircraft. A possible set of values in this case could be\n2, 4, 8. A discrete variable is categorical if no order relation is known\nbetween the possible choices the variable can take. One example of a\ncategorical variable is the color of a surface. A possible example of a\nset of choices could be blue, red, green. The possible choices are called\nthe levels of the variable.\nSeveral methods have been proposed to address the recent increase\ninterest in mixed Kriging based models [30–33,35,39,53,54]. The main\ndifference from a continuous Kriging model is in the estimation of\nAdvances in Engineering Software 188 (2024) 103571\n5\nP. Saves et al.\nTable 3\nCategorical kernels implemented in SMT 2.0.\nName\n\uD835\uDF05(\uD835\uDF19)\n\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)\n# of hyperparam.\nSMT GD\nexp(−\uD835\uDF19)\n[\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57,\uD835\uDC57 ∶= 1\n2 \uD835\uDF03\uD835\uDC56 ; [\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57≠\uD835\uDC57′ ∶= 0\n1\nSMT CR\nexp(−\uD835\uDF19)\n[\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57,\uD835\uDC57 ∶= [\uD835\uDEE9\uD835\uDC56]\uD835\uDC57,\uD835\uDC57 ; [\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57≠\uD835\uDC57′ ∶= 0\n\uD835\uDC3F\uD835\uDC56\nSMT EHH\nexp(−\uD835\uDF19)\n[\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57,\uD835\uDC57 ∶= 0 ; [\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57≠\uD835\uDC57′ ∶= log \uD835\uDF16\n2 ([\uD835\uDC36(\uD835\uDEE9\uD835\uDC56)\uD835\uDC36(\uD835\uDEE9\uD835\uDC56)⊤]\uD835\uDC57,\uD835\uDC57′ − 1)\n1\n2 (\uD835\uDC3F\uD835\uDC56)(\uD835\uDC3F\uD835\uDC56 − 1)\nSMT HH\n\uD835\uDF19\n[\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57,\uD835\uDC57 ∶= 1 ; [\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDC57≠\uD835\uDC57′ ∶= [\uD835\uDC36(\uD835\uDEE9\uD835\uDC56)\uD835\uDC36(\uD835\uDEE9\uD835\uDC56)⊤]\uD835\uDC57,\uD835\uDC57′\n1\n2 (\uD835\uDC3F\uD835\uDC56)(\uD835\uDC3F\uD835\uDC56 − 1)\nthe categorical correlation matrix, which is critical to determine the\nmean and variance predictions. As mentioned in Section 1, approaches\nsuch as CR [30,39], continuous latent variables [54], and GD [31]\nuse a kernel-based method to estimate the correlation matrix. Other\nmethods estimate the correlation matrix by modeling the correlation\nentries directly [32,35,53], such as HH [33] and EHH [34]. The HH\ncorrelation kernel is of particular interest because it generalizes simpler\nkernels such as CR and GD [34]. In SMT 2.0, the correlation kernel is\nan option that can be set to either CR (CONT_RELAX_KERNEL), GD\n(GOWER_KERNEL),\nHH\n(HOMO_HSPHERE_KERNEL)\nor\nEHH\n(EXP_HOMO_HSPHERE_KERNEL).\n3.1. Mixed Gaussian processes\nThe continuous and ordinal variables are both treated similarly\nin SMT 2.0 with a continuous kernel, where the ordinal values are\nconverted to continuous through relaxation. For categorical variables,\nfour models (GD, CR, EHH and HH) can be used in SMT 2.0 if\nspecified by the API. This is why we developed a unified mathematical\nformulation that allows a unique implementation for any model.\nDenote \uD835\uDC59 the number of categorical variables. For a given \uD835\uDC56 ∈\n{1, … , \uD835\uDC59}, the \uD835\uDC56th categorical variable is denoted \uD835\uDC50\uD835\uDC56 and its number\nof levels is denoted \uD835\uDC3F\uD835\uDC56. The hyperparameter matrix peculiar to this\nvariable \uD835\uDC50\uD835\uDC56 is\n\uD835\uDEE9\uD835\uDC56 =\n⎡\n⎢\n⎢\n⎢\n⎢⎣\n[\uD835\uDEE9\uD835\uDC56]1,1\n\uD835\uDC7A\uD835\uDC9A\uD835\uDC8E.\n[\uD835\uDEE9\uD835\uDC56]1,2\n[\uD835\uDEE9\uD835\uDC56]2,2\n⋮\n⋱\n⋱\n[\uD835\uDEE9\uD835\uDC56]1,\uD835\uDC3F\uD835\uDC56\n…\n[\uD835\uDEE9\uD835\uDC56]\uD835\uDC3F\uD835\uDC56−1,\uD835\uDC3F\uD835\uDC56\n[\uD835\uDEE9\uD835\uDC56]\uD835\uDC3F\uD835\uDC56,\uD835\uDC3F\uD835\uDC56\n⎤\n⎥\n⎥\n⎥\n⎥⎦\n,\nand the categorical parameters are defined as \uD835\uDF03\uD835\uDC50\uD835\uDC4E\uD835\uDC61 = {\uD835\uDEE91, … , \uD835\uDEE9\uD835\uDC59}. For\ntwo given inputs in the DoE, for example, the \uD835\uDC5Fth and \uD835\uDC60th points, let\n\uD835\uDC50\uD835\uDC5F\n\uD835\uDC56 and \uD835\uDC50\uD835\uDC60\n\uD835\uDC56 be the associated categorical variables taking respectively\nthe \uD835\uDCC1\uD835\uDC56\n\uD835\uDC5F and the \uD835\uDCC1\uD835\uDC56\n\uD835\uDC60 level on the categorical variable \uD835\uDC50\uD835\uDC56. The categorical\ncorrelation kernel is defined by\n\uD835\uDC58\uD835\uDC50\uD835\uDC4E\uD835\uDC61(\uD835\uDC50\uD835\uDC5F, \uD835\uDC50\uD835\uDC60, \uD835\uDF03\uD835\uDC50\uD835\uDC4E\uD835\uDC61) =\n\uD835\uDC59∏\n\uD835\uDC56=1\n\uD835\uDF05([\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDCC1\uD835\uDC5F\n\uD835\uDC56 ,\uD835\uDCC1\uD835\uDC60\n\uD835\uDC56 ) \uD835\uDF05([\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDCC1\uD835\uDC60\n\uD835\uDC56 ,\uD835\uDCC1\uD835\uDC5F\n\uD835\uDC56 )\uD835\uDF05([\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDCC1\uD835\uDC5F\n\uD835\uDC56 ,\uD835\uDCC1\uD835\uDC5F\n\uD835\uDC56 )\uD835\uDF05([\uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)]\uD835\uDCC1\uD835\uDC60\n\uD835\uDC56 ,\uD835\uDCC1\uD835\uDC60\n\uD835\uDC56 )\n(1)\nwhere \uD835\uDF05 is either a positive definite kernel or identity and \uD835\uDEF7(.) is a\nsymmetric positive definite (SPD) function such that the matrix \uD835\uDEF7(\uD835\uDEE9\uD835\uDC56)\nis SPD if \uD835\uDEE9\uD835\uDC56 is SPD. For an exponential kernel, Table 3 gives the\nparameterizations of \uD835\uDEF7 and \uD835\uDF05 that correspond to GD, CR, HH, and\nEHH kernels. The complexity of these different kernels depends on\nthe number of hyperparameters that characterizes them. As defined\nby Saves et al. [34], for every categorical variable \uD835\uDC56 ∈ {1, … , \uD835\uDC59}, the\nmatrix \uD835\uDC36(\uD835\uDEE9\uD835\uDC56) ∈ R\uD835\uDC3F\uD835\uDC56×\uD835\uDC3F\uD835\uDC56 is lower triangular and built using a hypersphere\ndecomposition [55,56] from the symmetric matrix \uD835\uDEE9\uD835\uDC56 ∈ R\uD835\uDC3F\uD835\uDC56×\uD835\uDC3F\uD835\uDC56 of\nhyperparameters. The variable \uD835\uDF16 is a small positive constant and the\nvariable \uD835\uDF03\uD835\uDC56 denotes the only positive hyperparameter that is used for\nthe Gower distance kernel.\nAnother Kriging based model that can use mixed variables is Kriging\nwith partial least squares (KPLS) [57]. KPLS adapts Kriging to high\ndimensional problems by using a reduced number of hyperparameters\nthanks to a projection into a smaller space. Also, for a general surrogate,\nnot necessarily Kriging, SMT 2.0 uses continuous relaxation to allow\nwhatever model to handle mixed variables. For example, we can use\nmixed variables with least squares (LS) or quadratic polynomial (QP)\nmodels. We now illustrate the abilities of the toolbox in terms of mixed\nmodeling over an engineering test case.\nTable 4\nResults of the cantilever beam models [34, Table 4].\nCategorical\nkernel\nDisplacement\nerror (cm)\nLikelihood\n# of\nhyperparam.\nSMT GD\n1.3861\n111.13\n3\nSMT CR\n1.1671\n155.32\n14\nSMT EHH\n0.1613\n236.25\n68\nSMT HH\n0.2033\n235.66\n68\n3.2. An engineering design test-case\nA classic engineering problem commonly used for model validation\nis the beam bending problem [32,58]. This problem is illustrated\non Fig. 2(a) and consists of a cantilever beam in its linear range loaded\nat its free end with a force \uD835\uDC39. As in Cheng et al. [58], the Young\nmodulus is \uD835\uDC38 = 200 GPa and the chosen load is \uD835\uDC39 = 50 kN. Also, as\nin Roustant et al. [32], 12 possible cross-sections can be used. These\n12 sections consist of 4 possible shapes that can be either hollow, thick\nor full as illustrated in Fig. 2(b).\nTo compare the mixed Kriging models of SMT 2.0, we draw a 98\npoint LHS as training set and the validation set is a grid of 12 × 30 ×\n30 = 10800 points. For the four implemented methods, displacement\nerror (computed with a root-mean-square error criterion), likelihood,\nnumber of hyperparameters and computational time for every model\nare shown in Table 4. For the continuous variables, we use the square\nexponential kernel. More details are found in [34]. As expected, the\ncomplex EHH and HH models lead to a lower displacement error and a\nhigher likelihood value, but use more hyperparameters and increase\nthe computational cost compared to GD and CR. On this test case,\nthe kernel EHH is easier to optimize than HH but in general, they\nare similar in terms of performance. Also, by default SMT 2.0 uses\nCR as it is known to be a good trade-off between complexity and\nperformance [59].\n4. Surrogate models with hierarchical variables in SMT 2.0\nTo introduce the newly developed Kriging model for hierarchical\nvariables implemented in SMT 2.0, we present the general mathe-\nmatical framework for hierarchical and mixed variables established\nby Audet et al. [38]. In SMT 2.0, two variants of our new method\nare implemented, namely SMT Alg-Kernel and SMT Arc-Kernel.\nIn particular, the SMT Alg-Kernel is a novel correlation kernel\nintroduced in this paper.\n4.1. The hierarchical variables framework\nA problem structure is classified as hierarchical when the sets of\nactive variables depend on architectural choices. This occurs frequently\nin industrial design problems. In hierarchical problems, we can classify\nvariables as neutral, meta (also known as dimensional) or decreed\n(also known as conditionally active) as detailed in Audet et al. [38].\nNeutral variables are the variables that are not affected by the hierarchy\nwhereas the value assigned to meta variables determines which decreed\nvariables are activated. For example, a meta variable could be the\nnumber of engines. If the number of engines changes, the number of\ndecreed bypass ratios that every engine should specify also changes.\nAdvances in Engineering Software 188 (2024) 103571\n6\nP. Saves et al.\n<image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 1735, height: 452, bpc: 8>Fig. 2. Cantilever beam problem [34, Figure 6].\n<image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 894, height: 866, bpc: 8><image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 767, height: 1010, bpc: 8><image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 894, height: 147, bpc: 8>Fig. 3. Variables classification as used in SMT 2.0.\nHowever, the wing aspect ratio being neutral, it is not affected by this\nhierarchy.\nProblems involving hierarchical variables are generally dependant\non discrete architectures and as such involve mixed variables. Hence,\nin addition to their role (neutral, meta or decreed), each variable also\nhas a variable type amongst categorical, ordinal or continuous. For the\nsake of simplicity and because both continuous and ordinal variables\nare treated similarly [34], we chose to regroup them as quantitative\nvariables. For instance, the neutral variables \uD835\uDC65neu may be partitioned\ninto different variable types, such that \uD835\uDC65neu = (\uD835\uDC65cat\nneu, \uD835\uDC65qnt\nneu) where \uD835\uDC65cat\nneu\nrepresents the categorical variables and \uD835\uDC65qnt\nneu are the quantitative ones.\nThe variable classification scheme in SMT 2.0 is detailed in Fig. 3.\nTo explain the framework and the new Kriging model, we illustrate\nthe inputs variables of the model using a classical machine learn-\ning problem related to the hyperparameters optimization of a fully-\nconnected Multi-Layer Perceptron (MLP) [38] on Fig. 4. In\nTable 5,\nwe detail the input variables of the model related to the MLP problem\n(i.e., the hyperparameters of the neural network, together with their\ntypes and roles). To keep things clear and concise, the chosen problem\nis a simplification of the original problem developed by Audet et al.\n[38]. Regarding the MLP problem of Fig. 4 and following the classi-\nfication scheme of Fig. 3, we start by separating the input variables\naccording to their role. In fact,\n1. changing the number of hidden layers modifies the number\nof inputs variables. Therefore, ‘‘# of hidden layers’’ is a meta\nvariable.\n2. The number of neurons in the hidden layer number \uD835\uDC58 is either\nincluded or excluded. For example, the ‘‘# of neurons in the 3rd\nlayer’’ would be excluded for an input that only has 2 hidden\nlayers. Therefore, ‘‘# of neurons hidden layer \uD835\uDC58’’ are decreed\nvariables.\n3. The ‘‘Learning rate’’, ‘‘Momentum’’, ‘‘Activation function’’ and\n‘‘Batch size’’ are not affected by the hierarchy choice. Therefore,\nthey are neutral variables.\nAccording to their types, the MLP input variables can be classified as\nfollows:\n4. The meta variable ‘‘# of hidden layers’’ is an integer and, as\nsuch, is represented by the component \uD835\uDC65qnt\nmet.\n5. The decreed variables ‘‘# of neurons hidden layer \uD835\uDC58’’ are integers\nand, as such, are represented by the component \uD835\uDC65qnt\ndec.\n6. The ‘‘Learning rate’’, ‘‘Momentum’’, ‘‘Activation function’’ and\n‘‘Batch size’’ are, respectively, continuous, for the first two (ev-\nery value between two bounds), categorical (qualitative between\nthree choices) and integer (quantitative between 6 choices).\nTherefore, the ‘‘Activation function’’ and the ‘‘Momentum’’ are\nrepresented by the component \uD835\uDC65cat\nneu. The ‘‘Learning rate’’ and the\n‘‘Batch size’’ are represented by the component \uD835\uDC65qnt\nneu.\nTo model hierarchical variables, as proposed in [38], we separate\nthe input space  as (neu, met, dec) where dec =\n⋃\n\uD835\uDC65met∈met\ninc(\uD835\uDC65met).\nAdvances in Engineering Software 188 (2024) 103571\n7\nP. Saves et al.\nFig. 4. The Multi-Layer Perceptron (MLP) problem.\nSource: Figure adapted from [38, Figure 1].\nTable 5\nA detailed description of the variables in the MLP problem.\nMLP\nHyperparameters\nVariable\nDomain\nType\nRole\nLearning rate\n\uD835\uDC5F\n[10−5, 10−2]\nFLOAT\nNEUTRAL\nMomentum\n\uD835\uDEFC\n[0, 1]\nFLOAT\nNEUTRAL\nActivation\nfunction\n\uD835\uDC4E\n{\uD835\uDC45\uD835\uDC52\uD835\uDC3F\uD835\uDC48, \uD835\uDC46\uD835\uDC56\uD835\uDC54\uD835\uDC5A\uD835\uDC5C\uD835\uDC56\uD835\uDC51, \uD835\uDC47 \uD835\uDC4E\uD835\uDC5Bℎ}\nENUM\nNEUTRAL\nBatch size\n\uD835\uDC4F\n{8, 16, … , 128, 256}\nORD\nNEUTRAL\n# of hidden\nlayers\n\uD835\uDC59\n{1, 2, 3}\nORD\nMETA\n# of neurons\nhidden layer \uD835\uDC58\n\uD835\uDC5B\uD835\uDC58\n{50, 51, … , 55}\nORD\nDECREED\nHence, for a given point \uD835\uDC65 ∈ , one has \uD835\uDC65 = (\uD835\uDC65neu, \uD835\uDC65met, \uD835\uDC65inc(\uD835\uDC65met)), where\n\uD835\uDC65neu ∈ neu, \uD835\uDC65met ∈ met and \uD835\uDC65inc(\uD835\uDC62met) ∈ inc(\uD835\uDC62met) are defined as follows:\n• The components \uD835\uDC65neu ∈ neu gather all neutral variables that\nare not impacted by the meta variables but needed. For ex-\nample, in the MLP problem, neu gathers the possible learning\nrates, momentum, activation functions and batch sizes. Namely,\nfrom Table 5, neu = [10−5, 10−2]×[0, 1] × {ReLu, Sigmoid, Tanh}×\n{8, 16, … , 256}.\n• The components \uD835\uDC65met gather the meta (also known as dimen-\nsional) variables that determine the inclusion or exclusion of\nother variables. For example, in the MLP problem, met represents\nthe possible numbers of layers in the MLP. Namely, from Table 5,\nmet = {1, 2, 3}.\n• The components \uD835\uDC65inc(\uD835\uDC65met), contain the decreed variables whose\ninclusion (decreed-included) or exclusion (decreed-excluded) is\ndetermined by the values of the meta components \uD835\uDC65met. For exam-\nple, in the MLP problem, dec represents the number of neurons\nin the decreed layers. Namely, from Table 5, inc(\uD835\uDC65met = 3) =\n[50, 55]3, inc(\uD835\uDC65met = 2) = [50, 55]2 and inc(\uD835\uDC65met = 1) = [50, 55].\n4.2. A Kriging model for hierarchical variables\nIn this section, a new method to build a Kriging model with hierar-\nchical variables is introduced based on the framework aforementioned.\nThe proposed methods are included in SMT 2.0.\n4.2.1. Motivation and state-of-the-art\nAssuming that the decreed variables are quantitative, Hutter and\nOsborne [21] proposed several kernels for the hierarchical context. A\nclassic approach, called the imputation method (Imp-Kernel) leads\nto an efficient paradigm in practice that can be easily integrated into\na more general framework as proposed by Bussemaker et al. [24].\nHowever, this kernel lacks depth and depends on arbitrary choices.\nTherefore, Hutter and Osborne [21] also proposed a more general\nkernel, called Arc-Kernel and Horn et al. [36] generalized this\nkernel even more and proposed a new formulation called the Wedge-\nKernel [37]. The drawbacks of these two methods are that they add\nsome extra hyperparameters for every decreed dimension (respectively\none extra hyperparameter for the Arc-Kernel and two hyperparam-\neters for the Wedge-Kernel) and that they need a normalization\naccording to the bounds. More recently, Pelamatti et al. [60] developed\na hierarchical kernel for Bayesian optimization. However, our work\nis also more general thanks to the framework introduced earlier [38]\nthat considers variable-wise formulation and is more flexible as we are\nallowing sub-problems to be intersecting.\nIn the following, we describe our new method to build a correlation\nkernel for hierarchical variables. In particular, we introduce a new alge-\nbraic kernel called Alg-Kernel that behaves like the Arc-Kernel\nwhilst correcting most of its drawbacks. In particular, our kernel does\nnot add any hyperparameters, and the normalization is handled in a\nnatural way.\n4.2.2. A new hierarchical correlation kernel\nFor modeling purposes, we assume that the decreed space is quan-\ntitative, i.e., dec = qnt\ndec. Let \uD835\uDC62 ∈  be an input point partitioned as\nAdvances in Engineering Software 188 (2024) 103571\n8\nP. Saves et al.\n\uD835\uDC62 = (\uD835\uDC62neu, \uD835\uDC62met, \uD835\uDC62inc(\uD835\uDC62met)) and, similarly, \uD835\uDC63 ∈  is another input such\nthat \uD835\uDC63 = (\uD835\uDC63neu, \uD835\uDC63met, \uD835\uDC63inc(\uD835\uDC63met)). The new kernel \uD835\uDC58 that we propose for\nhierarchical variables is given by\n\uD835\uDC58(\uD835\uDC62, \uD835\uDC63) = \uD835\uDC58neu(\uD835\uDC62neu, \uD835\uDC63neu) × \uD835\uDC58met(\uD835\uDC62met, \uD835\uDC63met)\n× \uD835\uDC58met,dec([\uD835\uDC62met, \uD835\uDC62inc(\uD835\uDC62met)], [\uD835\uDC63met, \uD835\uDC63inc(\uD835\uDC63met)]),\n(2)\nwhere \uD835\uDC58neu, \uD835\uDC58met and \uD835\uDC58met,dec are as follows:\n• \uD835\uDC58neu represents the neutral kernel that encompasses both categor-\nical and quantitative neutral variables, i.e., \uD835\uDC58neu can be decom-\nposed into two parts \uD835\uDC58neu(\uD835\uDC62neu, \uD835\uDC63neu) = \uD835\uDC58cat(\uD835\uDC62cat\nneu, \uD835\uDC63cat\nneu)\uD835\uDC58qnt(\uD835\uDC62qnt\nneu, \uD835\uDC63qnt\nneu).\nThe categorical kernel, denoted \uD835\uDC58cat, could be any Symmetric\nPositive Definite (SPD) [34] mixed kernel (see Section 3). For\nthe quantitative (integer or continuous) variables, a distance-\nbased kernel is used. The chosen quantitative kernel (Exponential,\nMatérn, ...), always depends on a given distance \uD835\uDC51. For example,\nthe \uD835\uDC5B-dimensional exponential kernel gives\n\uD835\uDC58qnt(\uD835\uDC62qnt, \uD835\uDC63qnt) =\n\uD835\uDC5B\n∏\n\uD835\uDC56=1\nexp(−\uD835\uDC51(\uD835\uDC62qnt\n\uD835\uDC56\n, \uD835\uDC63qnt\n\uD835\uDC56\n)).\n(3)\n• \uD835\uDC58met is the meta variables related kernel. It is also separated into\ntwo parts: \uD835\uDC58met(\uD835\uDC62met, \uD835\uDC63met) = \uD835\uDC58cat(\uD835\uDC62cat\nmet, \uD835\uDC63cat\nmet)\uD835\uDC58qnt(\uD835\uDC62qnt\nmet, \uD835\uDC63qnt\nmet) where the\nquantitative kernel is ordered and not continuous because meta\nvariables take value in a finite set.\n• \uD835\uDC58met,dec is an SPD kernel that models the correlations between the\nmeta levels (all the possible subspaces) and the decreed variables.\nIn what comes next, we detailed this kernel.\n4.2.3. Towards an algebraic meta-decreed kernel\nMeta-decreed\nkernels\nlike\nthe\nimputation\nkernel\nor\nthe\nArc-Kernel were first proposed in [21,47] and the distance-based\nkernels such as Arc-Kernel or Wedge-Kernel [37] were proven\nto be SPD. Nevertheless, to guarantee this SPD property, the same\nhyperparameters are used to model the correlations between the meta\nlevels and between the decreed variables [47]. For this reason, the\nArc-Kernel includes additional continuous hyperparameters which\nmakes the training of the GP models more expensive and introduces\nmore numerical stability issues. In this context, we are proposing a\nnew algebraic meta-decreed kernel (denoted as Alg-Kernel) that\nenjoys similar properties as Arc-Kernel but without using additional\ncontinuous hyperparameters nor rescaling. In the SMT 2.0 release, we\nincluded Alg-Kernel and a simpler version of Arc-Kernel that do\nnot relies on additional hyperparameters.\nOur proposed Alg-Kernel kernel is given by\n\uD835\uDC58alg\nmet,dec([\uD835\uDC62met, \uD835\uDC62inc(\uD835\uDC62met)], [\uD835\uDC63met, \uD835\uDC63inc(\uD835\uDC63met)])\n= \uD835\uDC58alg\nmet(\uD835\uDC62met, \uD835\uDC63met) × \uD835\uDC58alg\ndec(\uD835\uDC62inc(\uD835\uDC62met), \uD835\uDC63inc(\uD835\uDC63met)).\n(4)\nMathematically, we could consider that there is only one meta variable\nwhose levels correspond to every possible included subspace. Let \uD835\uDC3Csub\ndenotes the components indices of possible subspaces, the subspaces\nparameterized by the meta component \uD835\uDC62met are defined as inc(\uD835\uDC62met =\n\uD835\uDC59), \uD835\uDC59 ∈ \uD835\uDC3Csub. It follows that the fully extended continuous decreed\nspace writes as dec = ⋃\n\uD835\uDC59∈\uD835\uDC3Csub inc(\uD835\uDC62met = \uD835\uDC59) and \uD835\uDC3Cdec is the set of the\nassociated indices. Let \uD835\uDC3C\uD835\uDC56\uD835\uDC5B\uD835\uDC61\uD835\uDC52\uD835\uDC5F\n\uD835\uDC62,\uD835\uDC63\ndenotes the set of components related to\nthe space inc(\uD835\uDC62met, \uD835\uDC63met) containing the variables decreed-included in\nboth inc(\uD835\uDC62met) and inc(\uD835\uDC63met).\nSince the decreed variables are quantitative, one has\n\uD835\uDC58alg\ndec(\uD835\uDC62inc(\uD835\uDC62met), \uD835\uDC63inc(\uD835\uDC63met)) = \uD835\uDC58qnt(\uD835\uDC62inc(\uD835\uDC62met), \uD835\uDC63inc(\uD835\uDC63met))\n=\n∏\n\uD835\uDC56∈\uD835\uDC3C\uD835\uDC56\uD835\uDC5B\uD835\uDC61\uD835\uDC52\uD835\uDC5F\n\uD835\uDC62,\uD835\uDC63\n\uD835\uDC58qnt([\uD835\uDC62inc(\uD835\uDC62met)]\uD835\uDC56, [\uD835\uDC63inc(\uD835\uDC63met)]\uD835\uDC56)\n(5)\nThe construction of the quantitative kernel \uD835\uDC58qnt depends on a given\ndistance denoted \uD835\uDC51alg. The kernel \uD835\uDC58alg\nmet is an induced meta kernel that\ndepends on the same distance \uD835\uDC51alg to preserve the SPD property of\n\uD835\uDC58alg\nmet,dec. For every \uD835\uDC56 ∈ \uD835\uDC3Cdec, if \uD835\uDC56 ∈ \uD835\uDC3C\uD835\uDC56\uD835\uDC5B\uD835\uDC61\uD835\uDC52\uD835\uDC5F\n\uD835\uDC62,\uD835\uDC63 , the new algebraic distance is\ngiven by\n\uD835\uDC51alg([\uD835\uDC62inc(\uD835\uDC62met)]\uD835\uDC56, [\uD835\uDC63inc(\uD835\uDC63met)]\uD835\uDC56) =\n⎛\n⎜\n⎜\n⎜⎝\n2|[\uD835\uDC62inc(\uD835\uDC62met)]\uD835\uDC56 − [\uD835\uDC63inc(\uD835\uDC63met)]\uD835\uDC56|\n√\n[\uD835\uDC62inc(\uD835\uDC62met)]\uD835\uDC56\n2 + 1\n√\n[\uD835\uDC63inc(\uD835\uDC63met)]\uD835\uDC56\n2 + 1\n⎞\n⎟\n⎟\n⎟⎠\n\uD835\uDF03\uD835\uDC56,\n(6)\nwhere \uD835\uDF03\uD835\uDC56 ∈ R+ is a continuous hyperparameter. Otherwise, if \uD835\uDC56 ∈ \uD835\uDC3Cdec\nbut \uD835\uDC56 ∉ \uD835\uDC3C\uD835\uDC56\uD835\uDC5B\uD835\uDC61\uD835\uDC52\uD835\uDC5F\n\uD835\uDC62,\uD835\uDC63 , there should be a non-zero residual distance between the\ntwo different subspaces inc(\uD835\uDC62met) and inc(\uD835\uDC63met) to ensure the kernel\nSPD property. To have a residual not depending on the decreed values,\nour model considers that there is a unit distance\n\uD835\uDC51alg([\uD835\uDC62inc(\uD835\uDC62met)]\uD835\uDC56, [\uD835\uDC63inc(\uD835\uDC63met)]\uD835\uDC56) = 1.0 \uD835\uDF03\uD835\uDC56, ∀\uD835\uDC56 ∈ \uD835\uDC3Cdec ⧵ \uD835\uDC3C\uD835\uDC56\uD835\uDC5B\uD835\uDC61\uD835\uDC52\uD835\uDC5F\n\uD835\uDC62,\uD835\uDC63 .\nThe induced meta kernel \uD835\uDC58alg\nmet(\uD835\uDC62met, \uD835\uDC63met) to preserve the SPD property\nof \uD835\uDC58alg is defined as:\n\uD835\uDC58alg\nmet(\uD835\uDC62met, \uD835\uDC63met) =\n∏\n\uD835\uDC56∈\uD835\uDC3Cmet\n\uD835\uDC58qnt(1.0 \uD835\uDF03\uD835\uDC56).\n(7)\nNot only our kernel of Eq. (2) uses less hyperparameters than the Arc-\nKernel (as we cut off its extra parameters) but it is also a more flexible\nkernel as it allows different kernels for meta and decreed variables.\nMoreover, another advantage of our kernel is that it is numerically\nmore stable thanks to the new non-stationary [61] algebraic distance\ndefined in Eq. (7) [62]. Our proposed distance also does not need any\nrescaling by the bounds to have values between 0 and 1.\nIn what comes next, we will refer to the implementation of the\nkernels Arc-Kernel and Alg-Kernel by SMT Arc-Kernel and\nSMT Alg-Kernel. We note also that the implementation of SMT\nArc-Kernel differs slightly from the original Arc-Kernel as we\nfixed some hyperparameters to 1 in order to avoid adding extra hy-\nperparameters and use the formulation of Eq. (2) and rescaling of the\ndata.\n4.2.4. Illustration on the MLP problem\nIn this section, we illustrate the hierarchical Arc-Kernel on the\nMLP example. For that sake, we consider two design variables \uD835\uDC62 and\n\uD835\uDC63 such that \uD835\uDC62 = (2.10−4, 0.9, ReLU, 16, 2, 55, 51) and \uD835\uDC63 = (5.10−3, 0.8,\nSigmoid, 64, 3, 50, 54, 53). Since the value of \uD835\uDC62met (i.e., the number of\nhidden layers) differs from one point to another (namely, 2 for \uD835\uDC62 and 3\nfor \uD835\uDC63), the associated variables \uD835\uDC62inc(\uD835\uDC62met) have either 2 or 3 variables\nfor the number of neurons in each layer (namely 55 and 51 for \uD835\uDC62,\nand 50, 54 and 53 for the point \uD835\uDC63). In our case, 8 hyperparame-\nters ([\uD835\uDC451]1,2, \uD835\uDF031, … , \uD835\uDF037) will have to be optimized where \uD835\uDC58 is given by\nEq. (2). These 7 hyperparameters can be described using our proposed\nframework as follows:\n• For the neutral components, we have \uD835\uDC62neu = (2.10−4, 0.9, ReLU, 16)\nand \uD835\uDC63neu = (5.10−3, 0.8, Sigmoid, 64). Therefore, for a categorical\nmatrix kernel \uD835\uDC451 and a square exponential quantitative kernel,\n\uD835\uDC58neu(\uD835\uDC62neu, \uD835\uDC63neu) = \uD835\uDC58cat(\uD835\uDC62cat\nneu, \uD835\uDC63cat\nneu)\uD835\uDC58qnt(\uD835\uDC62qnt\nneu, \uD835\uDC63qnt\nneu)\n= [\uD835\uDC451]1,2 exp [−\uD835\uDF031(2.10−4 − 5.10−3)2]\nexp [−\uD835\uDF032(0.9 − 0.8)2] exp [−\uD835\uDF033(16 − 64)2].\nThe values [\uD835\uDC451]1,2, \uD835\uDF031, \uD835\uDF032 and \uD835\uDF033 need to be optimized. Here,\n[\uD835\uDC451]1,2 is the correlation between \"ReLU\" and \"Sigmoid\".\n• For the meta components, we have \uD835\uDC62met\n= 2 and \uD835\uDC63met\n= 3.\nTherefore, for a square exponential quantitative kernel,\n\uD835\uDC58met(\uD835\uDC62met, \uD835\uDC63met) = \uD835\uDC58cat(\uD835\uDC62cat\nmet, \uD835\uDC63cat\nmet)\uD835\uDC58qnt(\uD835\uDC62qnt\nmet, \uD835\uDC63qnt\nmet)\n= exp [−\uD835\uDF034(3 − 2)2].\nThe value \uD835\uDF034 needs to be optimized.\nAdvances in Engineering Software 188 (2024) 103571\n9\nP. Saves et al.\n• For the meta-decreed kernel, we have [\uD835\uDC62met, \uD835\uDC62inc(\uD835\uDC62met)] = [2, (55, 51)]\nand [\uD835\uDC63met, \uD835\uDC63inc(\uD835\uDC63met)] = [3, (50, 54, 53)] which gives\n\uD835\uDC58alg\nmet,dec([\uD835\uDC62met, \uD835\uDC62inc(\uD835\uDC62met)], [\uD835\uDC63met, \uD835\uDC63inc(\uD835\uDC63met)])\n= \uD835\uDC58alg\nmet(2, 3) \uD835\uDC58alg\ndec((55, 51), (50, 54, 53)).\nThe distance \uD835\uDC51alg(51, 54) =\n(\n2×|51−54|\n√\n512+1\n√\n542+1\n)\n\uD835\uDF036 = 2.178.10−3 \uD835\uDF036. In\ngeneral, for surrogate models, and in particular in SMT 2.0, the\ninput data are normalized. With a unit normalization from [50, 55]\nto [0, 1], we would have \uD835\uDC51alg(0.2, 0.8) =\n(\n2×0.6\n√\n0.22+1\n√\n0.62+1\n)\n\uD835\uDF036 =\n0.919 \uD835\uDF036. Similarly, we have, between 55 and 50, \uD835\uDC51alg(0, 1) =\n1.414 \uD835\uDF035. Hence, for a square exponential quantitative kernel, one\ngets\n\uD835\uDC58alg\nmet,dec([\uD835\uDC62met, \uD835\uDC62inc(\uD835\uDC62met)], [\uD835\uDC63met, \uD835\uDC63inc(\uD835\uDC63met)])\n= exp [−\uD835\uDF037] × exp [−1.414 \uD835\uDF035] × exp [−0.919 \uD835\uDF036],\nwhere the meta induced component is \uD835\uDC58alg\nmet(\uD835\uDC62met, \uD835\uDC63met) = exp [−\uD835\uDF037]\nbecause the decreed value 53 in \uD835\uDC63 has nothing to be compared\nwith in \uD835\uDC62 as in Eq. (7). The values \uD835\uDF035, \uD835\uDF036 and \uD835\uDF037 need to be opti-\nmized which complete the description of the hyperparameters.\nWe note that for the MLP problem, Alg-Kernel models use\n10 hyperparameters whereas the Arc-Kernel would require\n12 hyperparameters without the meta kernel (\uD835\uDF034) but with 3\nextra decreed hyperparameters and the Wedge-Kernel would\nrequire 15 hyperparameters. For deep learning applications, a\nmore complex perceptron with up to 10 hidden layers would\nrequire 17 hyperparameters with SMT 2.0 models against 26\nfor Arc-Kernel and 36 for Wedge-Kernel. The next section\nillustrates the interest of our method to build a surrogate model\nfor this neural network engineering problem.\n4.3. A neural network test-case using SMT 2.0\nIn this section, we apply our models to the hyperparameters opti-\nmization of a MLP problem aforementioned of Fig. 4. Within SMT 2.0\nan example illustrates this MLP problem. For the sake of showing the\nKriging surrogate abilities, we implemented a dummy function with no\nsignificance to replace the real black-box that would require training\na whole Neural Network (NN) with big data. This function requires a\nnumber of variables that depends on the value of the meta variable,\ni.e the number of hidden layers. To simplify, we have chosen only\n1, 2 or 3 hidden layers and therefore, we have 3 decreed variables\nbut deep neural networks could also be investigated as our model can\ntackle a few dozen variables. A test case (test_hierarchical_variables_NN)\nshows that our model SMT Alg-Kernel interpolates the data prop-\nerly, checks that the data dimension is correct and also asserts that\nthe inactive decreed variables have no influence over the prediction.\nIn Fig. 5 we illustrate the usage of Kriging surrogates with hierarchical\nand mixed variables based on the implementation of SMT 2.0 for\ntest_hierarchical_variables_NN.\nTo compare the hierarchical models of SMT 2.0 (SMT Alg-Kernel\nand SMT Arc-Kernel) with the state-of-the-art imputation method\npreviously used on industrial application (Imp-Kernel) [24], we\ndraw a 99 point LHS (33 points by meta level) as a training set and the\nvalidation set is a LHS of 3×1000 = 3000 points. For the Imp-Kernel,\nthe decreed-excluded values are replaced by 52 because the mean value\n52.5 is not an integer (by default, SMT rounds to the floor value).\nFor the three methods, the precision (computed with a root-mean-\nsquare error RMSE criterion), the likelihood and the computational\ntime are shown in Table 6. For this problem, we can see that SMT Alg-\nkernel gives better performance than the imputation method or SMT\nArc-kernel. Also, as all methods use the same number of hyperpa-\nrameters, they have similar time performances. A direct application of\nTable 6\nResults on the neural network model.\nHierarchical method\nPrediction\nerror (RMSE)\nLikelihood\n# of\nhyperparam.\nSMT Alg-kernel\n3.7610\n176.11\n10\nSMT Arc-kernel\n4.9208\n162.01\n10\nImp-Kernel\n4.5455\n170.64\n10\nour modeling method is Bayesian optimization to perform quickly the\nhyperparameter optimization of a neural network [63].\n5. Bayesian optimization within SMT 2.0\nEfficient global optimization (EGO) is a sequential Bayesian op-\ntimization algorithm designed to find the optimum of a black-box\nfunction that may be expensive to evaluate [52]. EGO starts by fitting\na Kriging model to an initial DoE, and then uses an acquisition function\nto select the next point to evaluate. The most used acquisition function\nis the expected improvement. Once a new point has been evaluated, the\nKriging model is updated. Successive updates increase the model accu-\nracy over iterations. This enrichment process repeats until a stopping\ncriterion is met.\nBecause SMT 2.0 implements Kriging models that handle mixed\nand hierarchical variables, we can use EGO to solve problems in-\nvolving such design variables. Other Bayesian optimization algorithms\noften adopt approaches based on solving subproblems with contin-\nuous or non-hierarchical Kriging. This subproblem approach is less\nefficient and scales poorly, but it can only solve simple problems.\nSeveral Bayesian optimization software packages can handle mixed or\nhierarchical variables with such a subproblem approach. The pack-\nages include BoTorch [25], SMAC [65], Trieste [66], HEBO [67],\nOpenBox [68], and Dragonfly [69].\n5.1. A mixed optimization problem\nFig. 6 compares the four EGO methods implemented in SMT 2.0:\nSMT GD, SMT CR, SMT EHH and SMT HH. The mixed test case that\nillustrates Bayesian optimization is a toy test case [64] detailed in Ap-\npendix A. This test case has two variables, one continuous and one\ncategorical with 10 levels. To assess the performance of our algorithm,\nwe performed 20 runs with different initial DoE sampled by LHS.\nEvery DoE consists of 5 points and we chose a budget of 55 infill\npoints. Fig. 6(a) plots the convergence curves for the four methods. In\nparticular, the median is the solid line, and the first and third quantiles\nare plotted in dotted lines. To visualize better the data dispersion,\nthe boxplots of the 20 best solutions after 20 evaluations are plotted\nin Fig. 6(b). As expected, the more a method is complex, the better\nthe optimization. Both SMT HH and SMT EHH converged in around 18\nevaluations whereas SMT CR and SMT GD take around 26 iterations as\nshown on Fig. 6(a). Also, the more complex the model, the closer the\noptimum is to the real value as shown on Fig. 6(b).\nIn Fig. 7 we illustrate how to use EGO with mixed variables based\non the implementation of SMT 2.0. The illustrated problem is a mixed\nvariant of the Branin function [70].\nNote that a dedicated notebook is available to reproduce the results\npresented in this paper and the mixed integer notebook also includes\nan extra mechanical application with composite materials [41].11\n11 https://colab.research.google.com/github/SMTorg/smt/blob/master/\ntutorial/SMT_MixedInteger_application.ipynb\nAdvances in Engineering Software 188 (2024) 103571\n10\nP. Saves et al.\n<image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 1626, height: 2631, bpc: 8>Fig. 5. Example of usage of Hierarchical and Mixed Kriging surrogate.\nAdvances in Engineering Software 188 (2024) 103571\n11\nP. Saves et al.\n<image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 1589, height: 595, bpc: 8>Fig. 6. Optimization results for the Toy function [64].\nFig. 7. Example of usage of mixed surrogates for Bayesian optimization.\nAdvances in Engineering Software 188 (2024) 103571\n12\nP. Saves et al.\n<image: ICCBased(RGB,sRGB v4 ICC preference perceptual intent beta), width: 1589, height: 594, bpc: 8>Fig. 8. Optimization results for the hierarchical Goldstein function.\n5.2. A hierarchical optimization problem\nThe hierarchical test case considered in this paper to illustrate\nBayesian optimization is a modified Goldstein function [60] detailed\nin Appendix B. The resulting optimization problem involves 11 vari-\nables: 5 are continuous, 4 are integer (ordinal) and 2 are categorical.\nThese variables consist in 6 neutral variables, 1 dimensional (or meta)\nvariable and 4 decreed variables. Depending on the meta variable\nvalues, 4 different sub-problems can be identified. The optimization\nproblem is given by:\nmin \uD835\uDC53(\uD835\uDC65cat\nneu, \uD835\uDC65qnt\nneu, \uD835\uDC65cat\n\uD835\uDC5A , \uD835\uDC65qnt\ndec)\nw.r.t. \uD835\uDC65cat\nneu = \uD835\uDC642 ∈ {0, 1}\n\uD835\uDC65qnt\nneu = (\uD835\uDC651, \uD835\uDC652, \uD835\uDC655, \uD835\uDC673, \uD835\uDC674) ∈ {0, 100}3 × {0, 1, 2}2\n\uD835\uDC65cat\n\uD835\uDC5A = \uD835\uDC641 ∈ {0, 1, 2, 3}\n\uD835\uDC65qnt\ndec = (\uD835\uDC653, \uD835\uDC654, \uD835\uDC671, \uD835\uDC672) ∈ {0, 100}2 × {0, 1, 2}2\n(8)\nCompared to the model choice of Pelamatti et al. [60], we chose to\nmodel \uD835\uDC655 and \uD835\uDC642 as neutral variables even if \uD835\uDC53 does not depend on\n\uD835\uDC655 when \uD835\uDC642 = 0. Other modeling choices are kept; for example, \uD835\uDC642 is\na so-called ‘‘binary variable’’ and not a categorical one [71]. Similarly,\nwe also keep the formulation of \uD835\uDC641 as a categorical variable but a better\nmodel would be to model it as a ‘‘cyclic variable’’ [72]. The resulting\nproblem is described in Appendix B. To assess the performance of our\nalgorithm, we performed 20 runs with different initial DoE sampled by\nLHS. Every DoE consists of \uD835\uDC5B + 1 = 12 points and we chose a budget\nof 5\uD835\uDC5B = 55 infill points. To compare our method with a baseline, we\nalso tested the random search method thanks to the expand_lhs\nnew method [40] described in Section 6.1 and we also optimized the\nGoldstein function using EGO with a classic Kriging model based on\nimputation method (Imp-Kernel). This method replaces the decreed-\nexcluded variables by their mean values: 50 or 1 respectively for (\uD835\uDC653, \uD835\uDC654)\nand (\uD835\uDC671, \uD835\uDC672). Fig. 8(a) plots the convergence curves for the four methods.\nIn particular, the median is the solid line and the first and third\nquantiles are plotted in dotted lines. To visualize better the correspond-\ning data dispersion, the boxplots of the 20 best solutions are plotted\nin Fig. 8(b). The results in Fig. 8 show that the hierarchical Kriging\nmodels of SMT 2.0 lead to better results than the imputation method\nor the random search both in terms of final objective value and variance\nover the 20 runs and in term of convergence rate. More precisely, SMT\nArc-Kernel and SMT Alg-Kernel Kriging model gave the best\nEGO results and managed to converge correctly as shown in Fig. 8(b).\nMore precisely, the 20 sampled DoEs led to similar performance and\nfrom one DoE, the method SMT Alg-Kernel managed to find the true\nminimum. However, this result has not been reproduced in other runs\nand is therefore not statistically significant. The variance between the\nruns is of similar magnitude regardless of the considered methods.\n6. Other relevant contributions in SMT 2.0\nThe new release SMT 2.0 introduces several improvements be-\nsides Kriging for hierarchical and mixed variables. This section details\nthe most important new contributions. Recall from Section 2.2 that\nfive sub-modules are present in the code: Sampling, Problems,\nSurrogate Models, Applications and Notebooks.\n6.1. Contributions to Sampling\nPseudo-random sampling. The Latin Hypercube Sampling (LHS) is a\nstochastic sampling technique to generate quasi-random sampling dis-\ntributions. It is among the most popular sampling method in computer\nexperiments thanks to its simplicity and projection properties with\nhigh-dimensional problems. The LHS method uses the pyDOE package\n(Design Of Experiments for Python). Five criteria for the construction\nof LHS are implemented in SMT. The first four criteria (center,\nmaximin, centermaximin, correlation) are the same as in\npyDOE.12 The last criterion ese, is implemented by the authors of\nSMT [48]. In SMT 2.0 a new LHS method was developed for the\nNested design of experiments (NestedLHS) [73] to use with multi-\nfidelity surrogates. A new mathematical method (expand_lhs) [40]\nwas developed in SMT 2.0 to increase the size of a design of exper-\niments while maintaining the ese property. Moreover, we proposed\na sampling method for mixed variables, and the aforementioned LHS\nmethod was applied to hierarchical variables in Fig. 8.\n6.2. Contributions to Surrogate models\nNew kernels and their derivatives for Kriging. Kriging surrogates are\nbased on hyperparameters and on a correlation kernel. Four correla-\ntion kernels are now implemented in SMT 2.0 [74]. In SMT, these\ncorrelation functions are absolute exponential (abs_exp), Gaussian\n(squar_exp), Matern 5/2 (matern52) and Matern 3/2 (matern32).\nIn addition, the implementation of gradient and Hessian for each kernel\nmakes it possible to calculate both the first and second derivatives of\nthe GP likelihood with respect to the hyperparameters [5].\nVariance derivatives for Kriging. To perform uncertainty quantification\nfor system analysis purposes, it could be interesting to know more\nabout the variance derivatives of a model [75–77]. For that purpose\nand also to pursue the original publication about derivatives [5], SMT\n2.0 extends the derivative support to Kriging variances and kernels.\n12 https://pythonhosted.org/pyDOE/index.html\nAdvances in Engineering Software 188 (2024) 103571\n13\nP. Saves et al.\nNoisy Kriging. In engineering and in big data contexts with real exper-\niments, surrogate models for noisy data are of significant interest. In\nparticular, there is a growing need for techniques like noisy Kriging\nand noisy Multi-Fidelity Kriging (MFK) for data fusion [78]. For that\npurpose, SMT 2.0 has been designed to accommodate Kriging and MFK\nto noisy data including the option to incorporate heteroscedastic noise\n(using the use_het_noise option) and to account for different noise\nlevels for each data source [40].\nKriging with partial least squares. Beside MGP, for high-dimensional\nproblems, the toolbox implements Kriging with partial least squares\n(KPLS) [57] and its extension KPLSK [44]. The PLS information is\ncomputed by projecting the data into a smaller space spanned by the\nprincipal components. By integrating this PLS information into the\nKriging correlation matrix, the number of inputs can be scaled down,\nthereby reducing the number of hyperparameters required. The result-\ning number of hyperparameters \uD835\uDC51\uD835\uDC52 is indeed much smaller than the\noriginal problem dimension \uD835\uDC51. Recently, in SMT 2.0, we extended the\nKPLS method for multi-fidelity Kriging (MFKPLS and MFKPLSK) [73,79,\n80]. We also proposed an automatic criterion to choose automatically\nthe reduced dimension \uD835\uDC51\uD835\uDC52 based on Wold’s R criterion [81]. This\ncriterion has been applied to aircraft optimization with EGO where the\nnumber \uD835\uDC51\uD835\uDC52 (\uD835\uDE97_\uD835\uDE8C\uD835\uDE98\uD835\uDE96\uD835\uDE99 in the code) for the model is automatically selected\nat every iteration [39]. Special efforts have been made to accommodate\nKPLS for multi-fidelity and mixed integer data [79,80].\nMarginal Gaussian process. SMT 2.0 implements Marginal Gaussian\nProcess (MGP) surrogate models for high dimensional problems [82].\nMGP are Gaussian processes taking into account hyperparameters un-\ncertainty defined as a density probability function. Especially we sup-\npose that the function to model \uD835\uDC53 ∶ \uD835\uDEFA ↦ R, where \uD835\uDEFA ⊂ R\uD835\uDC51 and \uD835\uDC51 is\nthe number of design variables, lies in a linear embedding  such as\n = {\uD835\uDC62 = \uD835\uDC34\uD835\uDC65, \uD835\uDC65 ∈ \uD835\uDEFA}, \uD835\uDC34 ∈ R\uD835\uDC51×\uD835\uDC51\uD835\uDC52 and \uD835\uDC53(\uD835\uDC65) = \uD835\uDC53(\uD835\uDC34\uD835\uDC65) with \uD835\uDC53(\uD835\uDC65) = \uD835\uDC53 ∶\n ↦ R and \uD835\uDC51\uD835\uDC52 ≪ \uD835\uDC51. Then, we must use a kernel \uD835\uDC58(\uD835\uDC65, \uD835\uDC65′) = \uD835\uDC58(\uD835\uDC34\uD835\uDC65, \uD835\uDC34\uD835\uDC65′)\nwhose each component of the transfer matrix \uD835\uDC34 is an hyperparameter.\nThus we have \uD835\uDC51\uD835\uDC52 × \uD835\uDC51 hyperparameters to find. Note that \uD835\uDC51\uD835\uDC52 is defined\nas \uD835\uDE97_\uD835\uDE8C\uD835\uDE98\uD835\uDE96\uD835\uDE99 in the code [49].\nGradient-enhanced neural network. The new release SMT 2.0 imple-\nments Gradient-Enhanced Neural Network (GENN) models [45].\nGradient-Enhanced Neural Networks (GENN) are fully connected multi-\nlayer perceptrons whose training process was modified to account for\ngradient information. Specifically, the model is trained to minimize not\nonly the prediction error of the response but also the prediction error\nof the partial derivatives: the chief benefit of gradient enhancement is\nbetter accuracy with fewer training points. Note that GENN applies to\nregression (single-output or multi-output), but not classification since\nthere is no gradient in that case. The implementation is fully vectorized\nand uses ADAM optimization, mini-batch, and L2-norm regularization.\nFor example, GENN can be used to learn airfoil geometries from a\ndatabase. This usage is documented in SMT 2.0.13\n6.3. Contributions to Applications\nKriging trajectory and sampling. Sampling a GP with high resolution\nis usually expensive due to the large dimension of the associated\ncovariance matrix. Several methods are proposed to draw samples\nof a GP on a given set of points. To sample a conditioned GP, the\nclassic method consists in using a Cholesky decomposition (or eigende-\ncomposition) of the conditioned covariance matrix of the process but\nsome numerical computational errors can lead to non SPD matrix. A\nmore recent approach based on Karhunen–Loève decomposition of the\ncovariance kernel with the Nyström method has been proposed in [83]\n13 https://smt.readthedocs.io/en/latest/_src_docs/examples/airfoil_\nparameters/learning_airfoil_parameters.html\nwhere the paths can be sampled by generating independent standard\nNormal distributed samples. The different methods are documented in\nthe tutorial Gaussian Process Trajectory Sampling [84].\nParallel Bayesian optimization. Due to the recent progress made in\nhardware configurations, it has been of high interest to perform parallel\noptimizations. A parallel criterion called qEI [85] was developed to\nperform Efficient Global Optimization (EGO): the goal is to be able\nto run batch optimization. At each iteration of the algorithm, multiple\nnew sampling points are extracted from the known ones. These new\nsampling points are then evaluated using a parallel computing environ-\nment. Five criteria are implemented in SMT 2.0: Kriging Believer (KB),\nKriging Believer Upper Bound (KBUB), Kriging Believer Lower Bound\n(KBLB), Kriging Believer Random Bound (KBRand) and Constant Liar\n(CLmin) [86].\n7.\nConclusion\nSMT 2.0 introduces significant upgrades to the Surrogate Modeling\nToolbox. This new release adds support for hierarchical and mixed\nvariables and improves the surrogate models with a particular focus\non Kriging (Gaussian process) models. SMT 2.0 is distributed through\nan open-source license and is freely available online.14 We provide\ndocumentation that caters to both users and potential developers.15\nSMT 2.0 enables users and developers collaborating on the same\nproject to have a common surrogate modeling tool that facilitates the\nexchange of methods and reproducibility of results.\nSMT has been widely used in aerospace and mechanical modeling\napplications. Moreover, the toolbox is general and can be useful for\nanyone who needs to use or develop surrogate modeling techniques,\nregardless of the targeted applications. SMT is currently the only open-\nsource toolbox that can build hierarchical and mixed surrogate models.\nDeclaration of competing interest\nThe authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\nData availability\nData will be made available on request. Results can be reproduced\nfreely online at https://colab.research.google.com/github/SMTorg/smt/\nblob/master/tutorial/NotebookRunTestCases_Paper_SMT_v2.ipynb.\nAcknowledgments\nWe want to thank all those who contribute to this release. Namely,\nM. A. Bouhlel, I. Cardoso, R. Carreira Rufato, R. Charayron, R. Conde\nArenzana, S. Dubreuil, A. F. López-Lopera, M. Meliani, M. Menz, N.\nMoëllo, A. Thouvenot, R. Priem, E. Roux and F. Vergnes. This work is\npart of the activities of ONERA - ISAE - ENAC joint research group. We\nalso acknowledge the partners institutions: ONERA, NASA Glenn, ISAE-\nSUPAERO, Institut Clément Ader (ICA), the University of Michigan,\nPolytechnique Montréal and the University of California San Diego.\nThe research presented in this paper has been performed in the\nframework of the AGILE 4.0 project (Towards cyber-physical collabo-\nrative aircraft development), funded by the European Union Horizon\n2020 research and innovation framework programme under grant\nagreement n◦ 815122 and in the COLOSSUS project (Collaborative\nSystem of Systems Exploration of Aviation Products, Services and\n14 https://github.com/SMTorg/SMT\n15 https://smt.readthedocs.io/en/latest/\nAdvances in Engineering Software 188 (2024) 103571\n14\nP. Saves et al.\nBusiness Models) funded by the European Union Horizon Europe re-\nsearch and innovation framework programme under grant agreement\nn◦ 101097120.\nWe also are grateful to E. Hallé-Hannan from Polytechnique Mon-\ntréal for the hierarchical variables framework.\nAppendix A. Toy test function\nThis Appendix gives the detail of the toy function of Section 5.1.16\nFirst, we recall the optimization problem:\nmin \uD835\uDC53(\uD835\uDC65cat, \uD835\uDC65qnt)\nw.r.t. \uD835\uDC65cat = \uD835\uDC501 ∈ {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\uD835\uDC65qnt = \uD835\uDC651 ∈ [0, 1]\n(A.1)\nThe toy function \uD835\uDC53 is defined as\n\uD835\uDC53(\uD835\uDC65, \uD835\uDC501) =1\uD835\uDC501=0 cos(3.6\uD835\uDF0B(\uD835\uDC65 − 2)) + \uD835\uDC65 − 1\n+1\uD835\uDC501=1 2 cos(1.1\uD835\uDF0B exp(\uD835\uDC65)) − \uD835\uDC65\n2 + 2\n+1\uD835\uDC501=2 cos(2\uD835\uDF0B\uD835\uDC65) + 1\n2\uD835\uDC65\n+1\uD835\uDC501=3 \uD835\uDC65(cos(3.4\uD835\uDF0B(\uD835\uDC65 − 1)) − \uD835\uDC65 − 1\n2\n)\n+1\uD835\uDC501=4 − \uD835\uDC652\n2\n+1\uD835\uDC501=5 2 cos(0.25\uD835\uDF0B exp(−\uD835\uDC654))2 − \uD835\uDC65\n2 + 1\n+1\uD835\uDC501=6 \uD835\uDC65 cos(3.4\uD835\uDF0B\uD835\uDC65) − \uD835\uDC65\n2 + 1\n+1\uD835\uDC501=7 − \uD835\uDC65(cos(3.5\uD835\uDF0B\uD835\uDC65) + \uD835\uDC65\n2 ) + 2\n+1\uD835\uDC501=8 − \uD835\uDC655\n2 + 1\n+1\uD835\uDC501=9 − cos(2.5\uD835\uDF0B\uD835\uDC65)2√\n\uD835\uDC65 − 0.5 ln(\uD835\uDC65 + 0.5) − 1.3\n(A.2)\nAppendix B. Hierarchical Goldstein test function\nThis Appendix gives the detail of the hierarchical Goldstein problem\nof Section 5.2.17 First, we recall the optimization problem:\nmin \uD835\uDC53(\uD835\uDC65cat\nneu, \uD835\uDC65qnt\nneu, \uD835\uDC65cat\n\uD835\uDC5A , \uD835\uDC65qnt\ndec)\nw.r.t. \uD835\uDC65cat\nneu = \uD835\uDC642 ∈ {0, 1}\n\uD835\uDC65qnt\nneu = (\uD835\uDC651, \uD835\uDC652, \uD835\uDC655, \uD835\uDC673, \uD835\uDC674) ∈ [0, 100]3 × {0, 1, 2}2\n\uD835\uDC65cat\n\uD835\uDC5A = \uD835\uDC641 ∈ {0, 1, 2, 3}\n\uD835\uDC65qnt\ndec = (\uD835\uDC653, \uD835\uDC654, \uD835\uDC671, \uD835\uDC672) ∈ [0, 100]2 × {0, 1, 2}2\n(B.1)\nThe hierarchical and mixed function \uD835\uDC53 is defined as a hierarchical\nfunction that depends on \uD835\uDC530, \uD835\uDC531, \uD835\uDC532 and \uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont as describes in the\nfollowing.\n\uD835\uDC53(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, \uD835\uDC654, \uD835\uDC671, \uD835\uDC672, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC641, \uD835\uDC642) =\n1\uD835\uDC641=0\uD835\uDC530(\uD835\uDC651, \uD835\uDC652, \uD835\uDC671, \uD835\uDC672, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC641=1\uD835\uDC531(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, \uD835\uDC672, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC641=2\uD835\uDC532(\uD835\uDC651, \uD835\uDC652, \uD835\uDC654, \uD835\uDC671, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC641=3\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, \uD835\uDC654, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642).\n(B.2)\n16 https://github.com/jbussemaker/SBArchOpt\n17 https://github.com/jbussemaker/SBArchOpt\nThen, the functions \uD835\uDC530, \uD835\uDC531 and \uD835\uDC532 are defined as mixed variants of\n\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont as such\n\uD835\uDC530(\uD835\uDC651, \uD835\uDC652, \uD835\uDC671, \uD835\uDC672, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) =\n1\uD835\uDC672=0\n( 1\uD835\uDC671=0\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 20, 20, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=1\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 50, 20, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=2\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 80, 20, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) )\n1\uD835\uDC672=1\n( 1\uD835\uDC671=0\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 20, 50, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=1\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 50, 50, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=2\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 80, 50, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) )\n1\uD835\uDC672=2\n( 1\uD835\uDC671=0\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 20, 80, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=1\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 50, 80, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=2\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 80, 80, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) )\n(B.3)\n\uD835\uDC531(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, \uD835\uDC672, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) =\n1\uD835\uDC672=0\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, 20, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC672=1\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, 50, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC672=2\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, 80, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n\uD835\uDC532(\uD835\uDC651, \uD835\uDC652, \uD835\uDC654, \uD835\uDC671, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) =\n1\uD835\uDC671=0\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 20, \uD835\uDC654, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=1\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, 50, \uD835\uDC652, \uD835\uDC654, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\n+ 1\uD835\uDC671=2\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, 80, \uD835\uDC654, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642)\nTo finish with, the function \uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont is given by\n\uD835\uDC3A\uD835\uDC5C\uD835\uDC59\uD835\uDC51cont(\uD835\uDC651, \uD835\uDC652, \uD835\uDC653, \uD835\uDC654, \uD835\uDC673, \uD835\uDC674, \uD835\uDC655, \uD835\uDC642) = 53.3108 + 0.184901\uD835\uDC651\n− 5.02914\uD835\uDC651\n3.10−6 + 7.72522\uD835\uDC651\n\uD835\uDC673.10−8 − 0.0870775\uD835\uDC652 − 0.106959\uD835\uDC653\n+ 7.98772\uD835\uDC653\n\uD835\uDC674.10−6 + 0.00242482\uD835\uDC654 + 1.32851\uD835\uDC654\n3.10−6 − 0.00146393\uD835\uDC651\uD835\uDC652\n− 0.00301588\uD835\uDC651\uD835\uDC653 − 0.00272291\uD835\uDC651\uD835\uDC654 + 0.0017004\uD835\uDC652\uD835\uDC653 + 0.0038428\uD835\uDC652\uD835\uDC654\n− 0.000198969\uD835\uDC653\uD835\uDC654 + 1.86025\uD835\uDC651\uD835\uDC652\uD835\uDC653.10−5 − 1.88719\uD835\uDC651\uD835\uDC652\uD835\uDC654.10−6\n+ 2.50923\uD835\uDC651\uD835\uDC653\uD835\uDC654.10−5 − 5.62199\uD835\uDC652\uD835\uDC653\uD835\uDC654.10−5 + \uD835\uDC642\n(\n5 cos\n( 2\uD835\uDF0B\n100 \uD835\uDC655\n)\n− 2\n)\n.\n(B.4)\nAppendix C. Supplementary data\nMore at https://colab.research.google.com/github/SMTorg/smt/blob/\nmaster/tutorial/NotebookRunTestCases_Paper_SMT_v2.ipynb.\nSupplementary material related to this article can be found online\nat https://doi.org/10.1016/j.advengsoft.2023.103571.\n",
            "pdfUrl" : "",
            "reference" : "[1] Mader CA, Martins JRRA, Alonso JJ, van der Weide E. ADjoint: An approach\nfor the rapid development of discrete adjoint solvers. AIAA J 2008;46:863–73.\n[2] Kennedy M, O’Hagan A. Bayesian calibration of computer models. J R Stat Soc\nSer B Stat Methodol 2001;63:425–64.\n[3] Hwang JT, Martins JRRA. A fast-prediction surrogate model for large datasets.\nAerosp Sci Technol 2018;75:74–87.\n[4] Martins JRRA, Ning A. Engineering design optimization. Cambridge University\nPress; 2021.\n[5] Bouhlel\nMA,\nHwang\nJT,\nBartoli\nN,\nLafage\nR,\nMorlier\nJ,\nMartins\nJRA.\nA Python surrogate modeling framework with derivatives. Adv Eng Softw\n2019;135:102662.\n[6] Bouhlel\nMA,\nMartins\nJ.\nGradient-enhanced\nkriging\nfor\nhigh-dimensional\nproblems. Eng Comput 2019;35:157–73.\n[7] Pedregosa F, Varoquaux G, Gramfort A, Thirion VMB, Grisel O, et al. Scikit-learn:\nMachine learning in Python. J Mach Learn Res 2011;12:2825–30.\nAdvances in Engineering Software 188 (2024) 103571\n15\nP. Saves et al.\n[8] Lataniotis C, Marelli S, Sudret B. Uqlab 2.0 and uqcloud: open-source vs.\ncloud-based uncertainty quantification. In: SIAM conference on uncertainty\nquantification. 2022.\n[9] Faraci A, Beaurepaire P, Gayton N. Review on Python toolboxes for Kriging\nsurrogate modelling. In: ESREL. 2022.\n[10] Krügener M, Zapata Usandivaras J, Bauerheim M, Urbano A. Coaxial-injector\nsurrogate modeling based on Reynolds-averaged Navier–Stokes simulations using\ndeep learning. J Propuls Power 2022;38:783–98.\n[11] Ming D, Williamson D, Guillas S. Deep Gaussian process emulation using\nstochastic imputation. Technometrics 2022;1–12.\n[12] Eliáš J, Vořechovsk`y M, Sadílekv V. Periodic version of the minimax distance\ncriterion for Monte Carlo integration. Adv Eng Softw 2020;149:102900.\n[13] Drouet V, Balesdent M, Brevault L, Dubreuil S, Morio J. Multi-fidelity algo-\nrithm for the sensitivity analysis of multidisciplinary problems. J Mech Des\n2023;145:1–22.\n[14] Karban P, Pánek D, Orosz T, Petrášová I, Doležel I. FEM based robust design\noptimization with Agros and ¯Artap. Comput Math Appl 2021;81:618–33.\n[15] Kudela J, Matousek R. Recent advances and applications of surrogate models for\nfinite element method computations: a review. Soft Comput 2022;26:13709–33.\n[16] Chen Y, Dababneh F, Zhang B, Kassaee S, Smith BT, Liu K, et al. Surrogate mod-\neling for capacity planning of charging station equipped with photovoltaic panel\nand hydropneumatic energy storage. J Energy Res Technol 2020;142:050907.\n[17] Jasa\nJ,\nBortolotti\nP,\nZalkind\nD,\nBarter\nG.\nEffectively\nusing\nmultifidelity\noptimization for wind turbine design. Wind Energy Sci 2022;7:991–1006.\n[18] Wang W, Tao G, Ke D, Luo J, Cui J. Transpiration cooling of high pres-\nsure turbine vane with optimized porosity distribution. Appl Therm Eng\n2023;223:119831.\n[19] Savage T, Almeida-Trasvina HF, del Río-Chanona EA, Smith R, Zhang D.\nAn adaptive data-driven modelling and optimization framework for complex\nchemical process design. Comput Aided Chem Eng 2020;48:73–8.\n[20] Chan A, Pires AF, Polacsek T. Trying to elicit and assign goals to the right actors.\nIn: Conceptual modeling: 41st international conference. 2022.\n[21] Hutter F, Osborne MA. A kernel for hierarchical parameter spaces. 2013, arXiv.\n[22] Bussemaker JH, Ciampa PD, Nagel B. System architecture design space explo-\nration: An approach to modeling and optimization. In: AIAA aviation 2020 forum.\n2020.\n[23] Fouda MEA, Adler EJ, Bussemaker J, Martins JRRA, Kurtulus DF, Boggero L,\net al. Automated hybrid propulsion model construction for conceptual aircraft\ndesign and optimization. In: 33rd congress of the international council of the\naeronautical sciences. 2022.\n[24] Bussemaker JH, Bartoli N, Lefebvre T, Ciampa PD, Nagel B. Effectiveness of\nsurrogate-based optimization algorithms for system architecture optimization. In:\nAIAA aviation 2021 forum. 2021.\n[25] Balandat M, Karrer B, Jiang D, Daulton S, Letham B, Wilson A, et al. BoTorch:\nA framework for efficient Monte-Carlo Bayesian optimization. Adv Neural Inf\nProcess Syst 2020;33:21524–38.\n[26] Adams B, Bohnhoff W, Dalbey K, Ebeida M, Eddy J, Eldred M, et al. Dakota,\na multilevel parallel object-oriented framework for design optimization, pa-\nrameter estimation, uncertainty quantification, and sensitivity analysis: Version\n6.13 user’s manual. Technical report, Albuquerque, NM (United States: Sandia\nNational Lab.(SNL-NM); 2020.\n[27] Roustant O, Ginsbourger D, Deville Y. DiceKriging, DiceOptim: Two R packages\nfor the analysis of computer experiments by Kriging-based metamodeling and\noptimization. J Stat Softw 2012;51:1–55.\n[28] Zhang Y, Tao S, Chen W, Apley D. A latent variable approach to Gaus-\nsian process modeling with qualitative and quantitative factors. Technometrics\n2020;62:291–302.\n[29] Chang TH, Wild SM. ParMOO: A Python library for parallel multiobjective\nsimulation optimization. J Open Source Softw 2023;8:4468.\n[30] Garrido-Merchán\nEC,\nHernández-Lobato\nD.\nDealing\nwith\ncategorical\nand\ninteger-valued variables in Bayesian optimization with Gaussian processes.\nNeurocomputing 2020;380:20–35.\n[31] Halstrup M. Black-box optimization of mixed discrete-continuous optimization\nproblems (Ph.D. thesis), TU Dortmund; 2016.\n[32] Roustant O, Padonou E, Deville Y, Clément A, Perrin G, Giorla J, et al.\nGroup kernels for gaussian process metamodels with categorical inputs. SIAM\nJ Uncertain Quant 2020;8:775–806.\n[33] Zhou Q, Qian PZG, Zhou S. A simple approach to emulation for computer models\nwith qualitative and quantitative factors. Technometrics 2011;53:266–73.\n[34] Saves P, Diouane Y, Bartoli N, Lefebvre T, Morlier J. A mixed-categorical\ncorrelation kernel for Gaussian process. Neurocomputing 2023;550:126472.\n[35] Pelamatti\nJ,\nBrevault\nL,\nBalesdent\nM,\nTalbi\nE-G,\nGuerin\nY.\nEfficient\nglobal optimization of constrained mixed variable problems. J Global Optim\n2019;73:583–613.\n[36] Horn D, Stork J, ler N-JS, Zaefferer M. Surrogates for hierarchical search spaces:\nThe Wedge-Kernel and an automated analysis. In: Proceedings of the genetic and\nevolutionary computation conference. 2019.\n[37] Hung Y, Joseph VR, Melkote SN. Design and analysis of computer experiments\nwith branching and nested factors. Technometrics 2009;51:354–65.\n[38] Audet C, Hallé-Hannan E, Le Digabel S. A general mathematical framework\nfor constrained mixed-variable blackbox optimization problems with meta and\ncategorical variables. Oper Res Forum 2023;4:1–37.\n[39] Saves P, Nguyen Van E, Bartoli N, Diouane Y, Lefebvre T, David C, Defoort S,\nMorlier J. Bayesian optimization for mixed variables using an adaptive dimension\nreduction process: applications to aircraft design. In: AIAA scitech 2022. 2022.\n[40] Conde Arenzana R, López-Lopera A, Mouton S, Bartoli N, Lefebvre T. Multi-\nfidelity Gaussian process model for CFD and wind tunnel data fusion. In:\nECCOMAS aerobest. 2021.\n[41] Rufato RC, Diouane Y, Henry J, Ahlfeld R, Morlier J. A mixed-categorical\ndata-driven approach for prediction and optimization of hybrid discontinuous\ncomposites performance. In: AIAA aviation 2022 forum. 2022.\n[42] Gorissen D, Crombecq K, Couckuyt I, Dhaene T, Demeester P. A surrogate\nmodeling and adaptive sampling toolbox for computer based design. J Mach\nLearn Res 2010;11:2051–5.\n[43] Williams CK, Rasmussen CE. Gaussian processes for machine learning. MA: MIT\npress Cambridge; 2006.\n[44] Bouhlel MA, Bartoli N, Regis R, Otsmane A, Morlier J. Efficient Global Opti-\nmization for high-dimensional constrained problems by using the Kriging models\ncombined with the Partial Least Squares method. Eng Optim 2018;50:2038–53.\n[45] Bouhlel MA, He S, Martins J. Scalable gradient-enhanced artificial neural\nnetworks for airfoil shape design in the subsonic and transonic regimes. Struct\nMultidiscip Optim 2020;61:1363–76.\n[46] Kwan LS, Pitrou A, Seibert S. Numba: A LLVM-based python JIT compiler. In:\nProceedings of the second workshop on the LLVM compiler infrastructure in\nHPC. 2015.\n[47] Zaefferer M, Horn D. A first analysis of kernels for Kriging-based optimization\nin hierarchical search spaces. 2018, arXiv.\n[48] Jin R, Chen W, Sudjianto A. An efficient algorithm for constructing optimal\ndesign of computer experiments. J Statist Plann Inference 2005;2:545–54.\n[49] Garnett R, Osborne M, Hennig P. Active learning of linear embeddings for\nGaussian processes. In: Uncertainty in artificial intelligence - Proceedings of the\n30th conference. 2013.\n[50] Jones D. A taxonomy of global optimization methods based on response surfaces.\nJ Global Optim 2001;21:345–83.\n[51] Lafage R. egobox, a Rust toolbox for efficient global optimization. J Open Source\nSoftw 2022;7:4737.\n[52] Jones DR, Schonlau M, Welch WJ. Efficient global optimization of expensive\nblack-box functions. J Global Optim 1998;13:455–92.\n[53] Deng X, Lin CD, Liu K, Rowe RK. Additive Gaussian process for computer models\nwith qualitative and quantitative factors. Technometrics 2017;59:283–92.\n[54] Cuesta-Ramirez J, Le Riche R, Roustant O, Perrin G, Durantin C, Gliere A. A\ncomparison of mixed-variables Bayesian optimization approaches. Adv Model\nSimul Eng Sci 2021;9:1–29.\n[55] Rebonato R, Jaeckel P. The most general methodology to create a valid\ncorrelation matrix for risk management and option pricing purposes. J Risk\n2001;2:17–27.\n[56] Rapisarda F, Brigo D, Mercurio F. Parameterizing correlations: a geometric\ninterpretation. IMA J Manag Math 2007;18:55–73.\n[57] Bouhlel\nMA,\nBartoli\nN,\nRegis\nR,\nOtsmane\nA,\nMorlier\nJ.\nAn\nimproved\napproach for estimating the hyperparameters of the Kriging model for high-\ndimensional problems through the Partial Least Squares method. Math Probl\nEng 2016;2016:6723410.\n[58] Cheng GH, Younis A, Hajikolaei KH, Wang GG. Trust region based mode pursuing\nsampling method for global optimization of high dimensional design problems.\nJ Mech Des 2015;137:021407.\n[59] Karlsson R, Bliek L, Verwer S, de Weerdt M. Continuous surrogate-based\noptimization algorithms are well-suited for expensive discrete problems. In:\nArtificial intelligence and machine learning. 2021.\n[60] Pelamatti J, Brevault L, Balesdent M, Talbi E-G, Guerin Y. Bayesian optimization\nof variable-size design space problems. Opt Eng 2021;22:387–447.\n[61] Hebbal A, Brevault L, Balesdent M, Talbi E-G, Melab N. Bayesian optimization\nusing deep Gaussian processes with applications to aerospace system design. Opt\nEng 2021;22:321–61.\n[62] Wildberger N. A rational approach to trigonometry. Math Horiz 2007;15:16–20.\n[63] Cho H, Kim Y, Lee E, Choi D, Lee Y, Rhee W. Basic enhancement strategies when\nusing bayesian optimization for hyperparameter tuning of deep neural networks.\nIEEE Access 2020;8:52588–608.\n[64] Zuniga MM, Sinoquet D. Global optimization for mixed categorical-continuous\nvariables based on Gaussian process models with a randomized categorical space\nexploration step. INFOR Inf Syst Oper Res 2020;58:310–41.\n[65] Lindauer M, Eggensperger K, Feurer M, AB, Deng D, Benjamins C, et al. SMAC3:\nA versatile Bayesian optimization package for hyperparameter optimization. J\nMach Learn Res 2022;23:1–9.\n[66] Picheny V, Berkeley J, Moss H, Stojic H, Granta U, Ober S, et al. Trieste:\nEfficiently exploring the depths of black-box functions with TensorFlow. 2023,\narXiv.\n[67] Cowen-Rivers AI, Ly W, Wang Z, Tutunov R, Jianye H, Wang J, et al. HEBO:\nHeteroscedastic evolutionary Bayesian optimisation. 2020, arXiv.\n[68] Jiang H, Shen Y, Li Y, Zhang W, Zhang C, Cui B. OpenBox: A Python toolkit for\ngeneralized black-box optimization. 2023, arXiv.\nAdvances in Engineering Software 188 (2024) 103571\n16\nP. Saves et al.\n[69] Kandasamy K, Vysyaraju KR, Neiswanger W, Paria B, Collins C, Schneider J, et\nal. Tuning hyperparameters without grad students: Scalable and robust bayesian\noptimisation with dragonfly. J Mach Learn Res 2020;21:3098–124.\n[70] Roy S, Crossley WA, Stanford BK, Moore KT, Gray JS. A mixed integer efficient\nglobal optimization algorithm with multiple infill strategy - Applied to a wing\ntopology optimization problem. In: AIAA scitech 2019 forum. 2019.\n[71] Müller J, Shoemaker CA, Piché R. SO-MI: A surrogate model algorithm for\ncomputationally expensive nonlinear mixed-integer black-box global optimization\nproblems. Comput Oper Res 2013;40:1383–400.\n[72] Tran T, Sinoquet D, Da Veiga S, Mongeau M. Derivative-free mixed binary\nnecklace optimization for cyclic-symmetry optimal design problems. Opt Eng\n2021.\n[73] Meliani M, Bartoli N, Lefebvre T, Bouhlel MA, Martins JRRA, Morlier J. Multi-\nfidelity efficient global optimization: Methodology and application to airfoil\nshape design. In: AIAA aviation 2019 forum. 2019.\n[74] Lee H. Gaussian processes. Springer Berlin Heidelberg; 2011, p. 575–7.\n[75] López-Lopera AF, Idier D, Rohmer J, Bachoc F. Multioutput Gaussian processes\nwith functional data: A study on coastal flood hazard assessment. Reliab Eng\nSyst Saf 2022;218:108139.\n[76] Berthelin G, Dubreuil S, Salaün M, Bartoli N, Gogu C. Disciplinary proper\northogonal decomposition and interpolation for the resolution of parameterized\nmultidisciplinary analysis. Internat J Numer Methods Engrg 2022;123:3594–626.\n[77] Cardoso I, Dubreuil S, Bartoli N, Gogu C, Salaün M, Lafage R. Disciplinary\nsurrogates for gradient-based optimization of multidisciplinary systems. In:\nECCOMAS Aerobest. 2023.\n[78] Platt J, Penny S, Smith T, Chen T, Abarbanel H. A systematic exploration of\nreservoir computing for forecasting complex spatiotemporal dynamics. Neural\nNetw 2022;153:530–52.\n[79] Charayron R, Lefebvre T, Bartoli N, Morlier J. Multi-fidelity Bayesian optimiza-\ntion strategy applied to overall drone design. In: AIAA scitech 2023 forum.\n2023.\n[80] Charayron R, Lefebvre T, Bartoli N, Morlier J. Towards a multi-fidelity and\nmulti-objective Bayesian optimization efficient algorithm. Aerosp Sci Technol\n2023;142:108673.\n[81] Wold H. Soft modelling by latent variables: The non-linear iterative partial least\nsquares (NIPALS) approach. J Appl Probab 1975;12:117–42.\n[82] Priem R, Diouane Y, Bartoli N, Dubreuil S, Saves P. High-dimensional efficient\nglobal optimization using both random and supervised embeddings. In: AIAA\naviation 2023 forum. 2023.\n[83] Betz W, Papaioannou I, Straub D. Numerical methods for the discretization of\nrandom fields by means of the Karhunen–Loève expansion. Comput Methods\nAppl Mech Engrg 2014;271:109–29.\n[84] Menz M, Dubreuil S, Morio J, Gogu C, Bartoli N, Chiron M. Variance based sen-\nsitivity analysis for Monte Carlo and importance sampling reliability assessment\nwith Gaussian processes. Struct Saf 2021;93:102116.\n[85] Ginsbourger D, Le Riche R, Carraro L. Kriging is well-suited to parallelize\noptimization. Springer Berlin Heidelberg; 2010, p. 131–62.\n[86] Roux E, Tillier Y, Kraria S, Bouchard P-O. An efficient parallel global opti-\nmization strategy based on Kriging properties suitable for material parameters\nidentification. Arch Mech Eng 2020;67.\n",
            "keyWords" : "Surrogate modeling\nGaussian process\nKriging\nHierarchical problems\nHierarchical and mixed-categorical inputs\nMeta variables\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "17",
          "_score" : 1.0,
          "_source" : {
            "title" : "Machine learning and deep learning",
            "samary" : "Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describesthe capacity of systems to learn from problem-specific training data to automate the process of analytical model building andsolve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications,deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, wesummarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodicalunderpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms andconcepts, explain the process of automated analytical model building through machine learning and deep learning, and discussthe challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business.These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligenceservitization.",
            "authors" : "Christian Janiesch1\n& Patrick Zschech2\n& Kai Heinrich3\nReceived: 7 October 2020 /Accepted: 19 March 2021\n# The Author(s) 2021\n",
            "institutions" : "",
            "integralText" : "Introduction\nIt is considered easier to explain to a child the nature of what\nconstitutes a sports car as opposed to a normal car by showing\nhim or her examples, rather than trying to formulate explicit\nrules that define a sports car.\nSimilarly, instead of codifying knowledge into computers,\nmachine learning (ML) seeks to automatically learn\nmeaningful relationships and patterns from examples and ob-\nservations (Bishop 2006). Advances in ML have enabled the\nrecent rise of intelligent systems with human-like cognitive\ncapacity that penetrate our business and personal life and\nshape the networked interactions on electronic markets in ev-\nery conceivable way, with companies augmenting decision-\nmaking for productivity, engagement, and employee retention\n(Shrestha et al. 2021), trainable assistant systems adapting to\nindividual user preferences (Fischer et al. 2020), and trading\nagents shaking traditional finance trading markets (Jayanth\nBalaji et al. 2018).\nThe capacity of such systems for advanced problem solv-\ning, generally termed artificial intelligence (AI), is based on\nanalytical models that generate predictions, rules, answers,\nrecommendations, or similar outcomes. First attempts to build\nanalytical models relied on explicitly programming known\nrelationships, procedures, and decision logic into intelligent\nsystems through handcrafted rules (e.g., expert systems for\nmedical diagnoses) (Russell and Norvig 2021). Fueled by\nthe practicability of new programming frameworks, data\navailability, and the broad access to necessary computing\npower, analytical models are nowadays increasingly built\nusing what is generally referred to as ML (Brynjolfsson and\nMcAfee 2017; Goodfellow et al. 2016). ML relieves the hu-\nman of the burden to explicate and formalize his or her\n<image: DeviceGray, width: 1100, height: 90, bpc: 1>Responsible Editor: Fabio Lobato\n* Christian Janiesch\nchristian.janiesch@uni-wuerzburg.de\nPatrick Zschech\npatrick.zschech@fau.de\nKai Heinrich\nkai.heinrich@ovgu.de\n1\nFaculty of Business Management & Economics, University of\nWürzburg, Sanderring 2, 97070 Würzburg, Germany\n2\nInstitute of Information Systems, Friedrich-Alexander University\nErlangen-Nürnberg, Lange Gasse 20, 90403 Nürnberg, Germany\n3\nFaculty of Economics and Management,\nOtto-von-Guericke-Universität Magdeburg, Universitätsplatz 2,\n39106 Magdeburg, Germany\nElectronic Markets\nhttps://doi.org/10.1007/s12525-021-00475-2\nknowledge into a machine-accessible form and allows to de-\nvelop intelligent systems more efficiently.\nDuring the last decades, the field of ML has brought forth a\nvariety of remarkable advancements in sophisticated learning\nalgorithms and efficient pre-processing techniques. One of\nthese advancements was the evolution of artificial neural net-\nworks (ANNs) towards increasingly deep neural network ar-\nchitectures with improved learning capabilities summarized as\ndeep learning (DL) (Goodfellow et al. 2016; LeCun et al.\n2015). For specific applications in closed environments, DL\nalready shows superhuman performance by excelling human\ncapabilities (Madani et al. 2018; Silver et al. 2018). However,\nsuch benefits also come at a price as there are several chal-\nlenges to overcome for successfully implementing analytical\nmodels in real business settings. These include the suitable\nchoice from manifold implementation options, bias and drift\nin data, the mitigation of black-box properties, and the reuse of\npreconfigured models (as a service).\nBeyond its hyped appearance, scholars, as well as profes-\nsionals, require a solid understanding of the underlying con-\ncepts, processes as well as challenges for implementing such\ntechnology. Against this background, the goal of this article is\nto convey a fundamental understanding of ML and DL in the\ncontext of electronic markets. In this way, the community can\nbenefit from these technological achievements – be it for the\npurpose of examining large and high-dimensional data assets\ncollected in digital ecosystems or for the sake of designing\nnovel intelligent systems for electronic markets. Following\nrecent advances in the field, this article focuses on analytical\nmodel building and challenges of implementing intelligent\nsystems based on ML and DL. As we examine the field from\na technical perspective, we do not elaborate on the related\nissues of AI technology adoption, policy, and impact on orga-\nnizational culture (for further implications cf. e.g. Stone et al.\n2016).\nIn the next section, we provide a conceptual distinction\nbetween relevant terms and concepts. Subsequently, we shed\nlight on the process of automated analytical model building\nby highlighting the particularities of ML and DL. Then, we\nproceed to discuss several induced challenges when\nimplementing intelligent systems within organizations or\nelectronic markets. In doing so, we highlight environmental\nfactors of implementation and application rather than view-\ning the engineered system itself as the only unit of observa-\ntion. We summarize the article with a brief conclusion.\nConceptual distinction\nTo provide a fundamental understanding of the field, it is\nnecessary to distinguish several relevant terms and concepts\nfrom each other. For this purpose, we first present basic foun-\ndations of AI, before we distinguish i) machine learning\nalgorithms, ii) artificial neural networks, and iii) deep neural\nnetworks. The hierarchical relationship between those terms is\nsummarized in Venn diagram of Fig. 1.\nBroadly defined, AI comprises any technique that enables\ncomputers to mimic human behavior and reproduce or excel\nover human decision-making to solve complex tasks inde-\npendently or with minimal human intervention (Russell and\nNorvig 2021). As such, it is concerned with a variety of\ncentral problems, including knowledge representation, rea-\nsoning, learning, planning, perception, and communication,\nand refers to a variety of tools and methods (e.g., case-based\nreasoning, rule-based systems, genetic algorithms, fuzzy\nmodels, multi-agent systems) (Chen et al. 2008). Early AI\nresearch focused primarily on hard-coded statements in for-\nmal languages, which a computer can then automatically\nreason about based on logical inference rules. This is also\nknown as the knowledge base approach (Goodfellow et al.\n2016). However, the paradigm faces several limitations as\nhumans generally struggle to explicate all their tacit knowl-\nedge that is required to perform complex tasks (Brynjolfsson\nand McAfee 2017).\nMachine learning overcomes such limitations. Generally\nspeaking, ML means that a computer program’s performance\nimproves with experience with respect to some class of tasks\nand performance measures (Jordan and Mitchell 2015). As\nsuch, it aims at automating the task of analytical model build-\ning to perform cognitive tasks like object detection or natural\nlanguage translation. This is achieved by applying algorithms\nthat iteratively learn from problem-specific training data,\nwhich allows computers to find hidden insights and complex\npatterns without explicitly being programmed (Bishop 2006).\nEspecially in tasks related to high-dimensional data such as\nclassification, regression, and clustering, ML shows good ap-\nplicability. By learning from previous computations and\nextracting regularities from massive databases, it can help to\nproduce reliable and repeatable decisions. For this reason, ML\nalgorithms have been successfully applied in many areas, such\nas fraud detection, credit scoring, next-best offer analysis,\nspeech and image recognition, or natural language processing\n(NLP).\nBased on the given problem and the available data, we can\ndistinguish three types of ML: supervised learning, unsuper-\nvised learning, and reinforcement learning. While many ap-\nplications in electronic markets use supervised learning\n(Brynjolfsson and McAfee 2017), for example, to forecast\nstock markets (Jayanth Balaji et al. 2018), to understand cus-\ntomer perceptions (Ramaswamy and DeClerck 2018), to ana-\nlyze customer needs (Kühl et al. 2020), or to search products\n(Bastan et al. 2020), there are implementations of all types, for\nexample, market-making with reinforcement learning\n(Spooner et al. 2018) or unsupervised market segmentation\nusing customer reviews (Ahani et al. 2019). See Table 1 for\nan overview of all three types.\nC. Janiesch et al.\nDepending on the learning task, the field offers various\nclasses of ML algorithms, each of them coming in multiple\nspecifications and variants, including regressions models,\ninstance-based algorithms, decision trees, Bayesian methods,\nand ANNs.\nThe family of artificial neural networks is of particular\ninterest since their flexible structure allows them to be modi-\nfied for a wide variety of contexts across all three types of ML.\nInspired by the principle of information processing in biolog-\nical systems, ANNs consist of mathematical representations of\nconnected processing units called artificial neurons. Like syn-\napses in a brain, each connection between neurons transmits\nsignals whose strength can be amplified or attenuated by a\nweight that is continuously adjusted during the learning pro-\ncess. Signals are only processed by subsequent neurons if a\ncertain threshold is exceeded as determined by an activation\nfunction. Typically, neurons are organized into networks with\ndifferent layers. An input layer usually receives the data input\n(e.g., product images of an online shop), and an output layer\nproduces the ultimate result (e.g., categorization of products).\nIn between, there are zero or more hidden layers that are re-\nsponsible for learning a non-linear mapping between input\nand output (Bishop 2006; Goodfellow et al. 2016). The num-\nber of layers and neurons, among other property choices, such\nas learning rate or activation function, cannot be learned by\nthe learning algorithm. They constitute a model’s\nhyperparameters and must be set manually or determined by\nan optimization routine.\nDeep neural networks typically consist of more than one\nhidden layer, organized in deeply nested network architec-\ntures. Furthermore, they usually contain advanced neurons\nin contrast to simple ANNs. That is, they may use advanced\noperations (e.g., convolutions) or multiple activations in one\nneuron rather than using a simple activation function. These\ncharacteristics allow deep neural networks to be fed with raw\ninput data and automatically discover a representation that is\nArtificial neural networks\nDeep neural networks\ne.g., support vector machine, decision tree, k-nearest neighbors, … \ne.g., shallow autoencoders, …\ne.g., convolutional neural networks, \nrecurrent neural networks, …\nDeep\nlearning\nShallow\nmachine\nlearning\nMachine\nlearning\nMachine learning algorithms\nFig. 1 Venn diagram of machine\nlearning concepts and classes\n(inspired by Goodfellow et al.\n2016, p. 9)\nTable 1\nOverview of types of machine learning\nType\nDescription\nSupervised learning Supervised learning requires a training dataset that covers examples for the input as well as labeled answers or target values for the\noutput. An example could be the prediction of active users subscribed to a market platform in a month’s time as output\n(considered as the target variable or y variable) based on different input characteristics, such as the number of sold products or\npositive user reviews (often referred to as input features or x variables). The pairs of input and output data in the training set are\nthen used to calibrate the open parameters of the ML model. Once the model has been successfully trained, it can be used to\npredict the target variable y given new or unseen data points of the input features x. Regarding the type of supervised learning,\nwe can further distinguish between regression problems, where a numeric value is predicted (e.g., number of users), and\nclassification problems, where the prediction result is a categorical class affiliation such as “lookers” or “buyers”.\nUnsupervised\nlearning\nUnsupervised learning takes place when the learning system is supposed to detect patterns without any pre-existing labels or\nspecifications. Thus, training data only consists of variables x with the goal of finding structural information of interest, such as\ngroups of elements that share common properties (known as clustering) or data representations that are projected from a\nhigh-dimensional space into a lower one (known as dimensionality reduction) (Bishop 2006). A prominent example of\nunsupervised learning in electronic markets is applying clustering techniques to group customers or markets into segments for\nthe purpose of a more target-group specific communication.\nReinforcement\nlearning\nIn a reinforcement learning system, instead of providing input and output pairs, we describe the current state of the system, specify\na goal, provide a list of allowable actions and their environmental constraints for their outcomes, and let the ML model\nexperience the process of achieving the goal by itself using the principle of trial and error to maximize a reward. Reinforcement\nlearning models have been applied with great success in closed world environments such as games (Silver et al. 2018), but they\nare also relevant for multi-agent systems such as electronic markets (Peters et al. 2013).\nMachine learning and deep learning\nneeded for the corresponding learning task. This is the net-\nworks’ core capability, which is commonly known as deep\nlearning. Simple ANNs (e.g., shallow autoencoders) and oth-\ner ML algorithms (e.g., decision trees) can be subsumed under\nthe term shallow machine learning since they do not provide\nsuch functionalities. As there is still no exact demarcation\nbetween the two concepts in literature (see also\nSchmidhuber 2015), we use a dashed line in Fig. 1. While\nsome shallow ML algorithms are considered inherently inter-\npretable by humans and, thus, white boxes, the decision mak-\ning of most advanced ML algorithms is per se untraceable\nunless explained otherwise and, thus, constitutes a black box.\nDL is particularly useful in domains with large and high-\ndimensional data, which is why deep neural networks outper-\nform shallow ML algorithms for most applications in which\ntext, image, video, speech, and audio data needs to be proc-\nessed (LeCun et al. 2015). However, for low-dimensional data\ninput, especially in cases of limited training data availability,\nshallow ML can still produce superior results (Zhang and Ling\n2018), which even tend to be better interpretable than those\ngenerated by deep neural networks (Rudin 2019). Further,\nwhile DL performance can be superhuman, problems that re-\nquire strong AI capabilities such as literal understanding and\nintentionality still cannot be solved as pointedly outlined in\nSearle (1980)'s Chinese room argument.\nProcess of analytical model building\nIn this section, we provide a framework on the process of\nanalytical model building for explicit programming, shallow\nML, and DL as they constitute three distinct concepts to build\nan analytical model. Due to their importance for electronic\nmarkets, we focus the subsequent discussion on the related\naspects of data input, feature extraction, model building, and\nmodel assessment of shallow ML and DL (cf. Figure 2). With\nexplicit programming, feature extraction and model building\nare performed manually by a human when handcrafting rules\nto specify the analytical model.\nData input\nElectronic markets have different stakeholder touchpoints,\nsuch as websites, apps, and social media platforms. Apart\nfrom common numerical data, they generate a vast amount\nof versatile data, in particular unstructured and non-cross-\nsectional data such as time series, image, and text. This data\ncan be exploited for analytical model building towards better\ndecision support or business automation purposes. However,\nextracting patterns and relationships by hand would exceed\nthe cognitive capacity of human operators, which is why\nalgorithmic support is indispensable when dealing with large\nand high-dimensional data.\nTime series data implies a sequential dependency and pat-\nterns over time that need to be detected to form forecasts, often\nresulting in regression problems or trend classification tasks.\nTypical examples involve forecasting financial markets or\npredicting process behavior (Heinrich et al. 2021). Image data\nis often encountered in the context of object recognition or\nobject counting with fields of application ranging from crop\ndetection for yield prediction to autonomous driving\n(Grigorescu et al. 2020). Text data is present when analyzing\nlarge volumes of documents such as corporate e-mails or so-\ncial media posts. Example applications are sentiment analysis\nor machine-based translation and summarization of docu-\nments (Young et al. 2018).\nRecent advancements in DL allow for processing data of\ndifferent types in combination, often referred to as cross-\nmodal learning. This is useful in applications where content\nis subject to multiple forms of representation, such as e-\ncommerce websites where product information is commonly\nrepresented by images, brief descriptions, and other comple-\nmentary text metadata. Once such cross-modal representa-\ntions are learned, they can be used, for example, to improve\nretrieval and recommendation tasks or to detect misinforma-\ntion and fraud (Bastan et al. 2020).\nFeature extraction\nAn important step for the automated identification of patterns\nand relationships from large data assets is the extraction of\nfeatures that can be exploited for model building. In general,\na feature describes a property derived from the raw data input\nwith the purpose of providing a suitable representation. Thus,\nfeature extraction aims to preserve discriminatory information\nand separate factors of variation relevant to the overall learn-\ning task (Goodfellow et al. 2016). For example, when classi-\nfying the helpfulness of customer reviews of an online-shop,\nuseful feature candidates could be the choice of words, the\nlength of the review, and the syntactical properties of the text.\nShallow ML heavily relies on such well-defined features,\nand therefore its performance is dependent on a successful\nextraction process. Multiple feature extraction techniques\nhave emerged over time that are applicable to different types\nof data. For example, when analyzing time-series data, it is\ncommon to apply techniques to extract time-domain features\n(e.g., mean, range, skewness) and frequency-domain features\n(e.g., frequency bands) (Goyal and Pabla 2015); for image\nanalysis, suitable approaches include histograms of oriented\ngradients (HOG) (Dalal and Triggs 2005), scale-invariant fea-\nture transform (SIFT) (Lowe 2004), and the Viola-Jones\nmethod (Viola and Jones 2001); and in NLP, it is common\nto use term frequency-inverse document frequency (TF-IDF)\nC. Janiesch et al.\nvectors (Salton and Buckley 1988), part-of-speech (POS) tag-\nging, and word shape features (Wu et al. 2018). Manual fea-\nture design is a tedious task as it usually requires a lot of\ndomain expertise within an application-specific engineering\nprocess. For this reason, it is considered time-consuming, la-\nbor-intensive, and inflexible.\nDeep neural networks overcome this limitation of\nhandcrafted feature engineering. Their advanced architecture\ngives them the capability of automated feature learning to\nextract discriminative feature representations with minimal\nhuman effort. For this reason, DL better copes with large-\nscale, noisy, and unstructured data. The process of feature\nlearning generally proceeds in a hierarchical manner, with\nhigh-level abstract features being assembled by simpler ones.\nNevertheless, depending on the type of data and the choice of\nDL architecture, there are different mechanisms of feature\nlearning in conjunction with the step of model building.\nModel building\nDuring automated model building, the input is used by a learn-\ning algorithm to identify patterns and relationships that are\nrelevant for the respective learning task. As described above,\nshallow ML requires well-designed features for this task. On\nthis basis, each family of learning algorithms applies different\nmechanisms for analytical model building. For example,\nwhen building a classification model, decision tree algorithms\nexploit the features space by incrementally splitting data re-\ncords into increasingly homogenous partitions following a\nhierarchical, tree-like structure. A support vector machine\n(SVM) seeks to construct a discriminatory hyperplane be-\ntween data points of different classes where the input data is\noften projected into a higher-dimensional feature space for\nbetter separability. These examples demonstrate that there\nare different ways of analytical model building, each of them\nwith individual advantages and disadvantages depending on\nthe input data and the derived features (Kotsiantis et al. 2006).\nBy contrast, DL can directly operate on high-dimensional\nraw input data to perform the task of model building with its\ncapability of automated feature learning. Therefore, DL archi-\ntectures are often organized as end-to-end systems combining\nboth aspects in one pipeline. However, DL can also be applied\nonly for extracting a feature representation, which is subse-\nquently fed into other learning subsystems to exploit the\nstrengths of competing ML algorithms, such as decision trees\nor SVMs.\nVarious DL architectures have emerged over time (Leijnen\nand van Veen 2020; Pouyanfar et al. 2019; Young et al. 2018).\nAlthough basically every architecture can be used for every\ntask, some architectures are more suited for specific data such\nas time series or images. Architectural variants are mostly\ncharacterized by the types of layers, neural units, and connec-\ntions they use. Table 2 summarizes the five groups of\nconvolutional neural networks (CNNs), recurrent neural net-\nworks (RNNs), distributed representations, autoencoders, and\ngenerative adversarial neural networks (GANs). They provide\npromising applications in the field of electronic markets.\nModel assessment\nFor the assessment of a model’s quality, multiple aspects have\nto be taken into account, such as performance, computational\nresources, and interpretability. Performance-based metrics\nevaluate how well a model satisfies the objective specified\nby the learning task. In the area of supervised learning, there\nare well-established guidelines for this purpose. Here, it is\ncommon practice to use k-fold cross-validation to prevent a\nmodel from overfitting and determine its performance on out-\nof-sample data that was not included in the training samples.\nCross-validation provides the opportunity to compare the re-\nliability of ML models by providing multiple out-of-sample\ndata instances that enable comparative statistical testing\n(García and Herrera 2008). Regression models are evaluated\nby measuring estimation errors such as the root mean square\nerror (RMSE) or the mean absolute percentage error (MAPE),\nInput\nInput\nInput\nHandcrafted model building\nOutput\nOutput\nExplicit \nprogramming\nShallow\nmachine\nlearning\nDeep\nlearning\nHandcrafted\nfeature engineering\nAutomated\nmodel building\nFeature learning + automated model building\nOutput\nData input\nFeature extraction\nModel building\nModel assessment\nFig. 2 Process of analytical\nmodel building (inspired by\nGoodfellow et al. 2016, p. 10)\nMachine learning and deep learning\nwhereas classification models are assessed by calculating dif-\nferent ratios of correctly and incorrectly predicted instances,\nsuch as accuracy, recall, precision, and F1 score. Furthermore,\nit is common to apply cost-sensitive measures such as average\ncost per predicted observation, which is helpful in situations\nwhere prediction errors are associated with asymmetric cost\nstructures (Shmueli and Koppius 2011). That is the case, for\nexample, when analyzing transactions in financial markets,\nand the costs of failing to detect a fraudulent transaction are\nremarkably higher than the costs of incorrectly classifying a\nnon-fraudulent transaction.\nTo identify a suitable prediction model for a specific task, it\nis reasonable to compare alternative models of varying com-\nplexities, that is, considering competing model classes as well\nas alternative variants of the same model class. As introduced\nabove, a model’s complexity can be characterized by several\nTable 2\nOverview of deep learning architectures\nArchitecture\nDescription\nConvolutional neural network\n(CNN)\nCNNs are mainly applied for tasks related to computer vision and speech recognition. They are able to address tasks\ninvolving datasets with spatial relationships, where the columns and rows are not interchangeable (e.g., image\ndata). Their network architecture comprises a series of stages that allow hierarchical feature learning as\ndetermined by the respective modeling task. For example, when considering object recognition in images, the\nfirst few layers of the network are responsible for extracting basic features in the form of edges and corners.\nThese are then incrementally aggregated into more complex features in the last few layers resembling the actual\nobjects of interest, such as animals, houses, or cars. Subsequently, the auto-generated features are used for\nprediction purposes to recognize objects of interest in new images (Goodfellow et al. 2016).\nRecurrent neural network (RNN)\nRNNs are designed explicitly for sequential data structures such as time-series data, event sequences, and natural\nlanguage. Their architecture offers internal feedback loops and therefore enables sequential pattern learning to\nmodel time dependencies by forming a memory. Simple RNN architectures are problematic since they suffer\nfrom vanishing gradients, resulting in little or no influence of early memories. More sophisticated architectures,\nsuch as long short-term memory (LSTM) networks with advanced attention mechanisms, attend to this problem.\nRNNs are typically applied for time series forecasting, predicting process behavior (Heinrich et al. 2021), and\nNLP tasks such as sequence transduction and neural machine translation (LeCun et al. 2015).\nDistributed representation\nDistributed representations play an essential role in feature learning and language modeling in NLP tasks, where\nlanguage entities such as words, phrases, and sentences are projected into numerical representations within a\nunified semantic space in the form of embeddings. Word embeddings, for example, encode discrete words into\ndense feature vectors with low dimensionality. Thus, in contrast to classic text representation models, such as\none-hot encodings and bag-of-words (BoW), word embeddings overcome the problem of sparse encodings\nwhile preserving semantic relationships between words. This means that words, which occur in similar contexts\nin a corpus, are also closely positioned to each other in the vector space. On this basis, advanced language models\ncan be developed to perform challenging downstream tasks, such as question-answering, sentiment analysis, and\nnamed entity recognition (Liu et al. 2020). Distributed representations are often applied in combination with\nRNNs to perform tasks with sequential dependencies.\nAutoencoder\nAutoencoders work similarly to word embeddings since they provide a dense feature representation of the input\ndata. However, they are not limited to natural language data but can be applied to any type of input. Such\narchitectures usually consist of an encoding stage where the input is compressed into a low-dimensional rep-\nresentation and a decoding stage in which the network tries to reconstruct the original input from the learned\nfeatures. In this way, the network is forced to keep meaningful information in the latent representation while\ndisregarding irrelevant noise (Goodfellow et al. 2016). Autoencoders are commonly applied for unsupervised\nfeature learning and dimensionality reduction in combination with other subsequent learning systems. However,\ndue to their capability of quantifying reconstruction errors, which are assumed to be significantly higher for\nanomalous samples than for regular instances, they can also be applied for detecting anomalies, such as fraud-\nulent activities in financial markets (Paula et al. 2016).\nGenerative adversarial neural\nnetwork (GAN)\nGenerative adversarial neural networks belong to the family of generative models that aim at learning a probability\ndistribution over a set of training data so that the network can randomly generate new data samples with some\nvariation. For this purpose, GANs consist of two competing sub-networks. The first network is a generator\nnetwork that captures the distribution of the input and generates new examples. The second network is a\ndiscriminator network trying to distinguish real examples from artificially generated ones. Both networks are\ntrained together in a non-cooperative zero-sum game where one network’s gain is another one’s loss until the\ndiscriminator can no longer distinguish between both types of samples. On this basis, GANs are likely to\nrevolutionize domains in which continuously new content or novel product configurations are created (e.g., the\ncomposition of art and music, design of fashion), or where content is converted from one representation to\nanother (e.g., text to image for product descriptions) (Pan et al. 2019). At the same time, however, such ap-\nproaches also pose severe threats with societal implications when abusing them for malicious purposes. In\nparticular, the generation of “deepfake” content in the form of abusive speeches and misleading news to\nmanipulate public opinions or distort financial markets is concerning (Westerlund 2019).\nC. Janiesch et al.\nproperties such as the type of learning mechanisms (e.g., shal-\nlow ML vs. DL), the number and type of manually generated\nor self-extracted features, and the number of trainable param-\neters (e.g., network weights in ANNs). Simpler models usual-\nly do not tend to be flexible enough to capture (non-linear)\nregularities and patterns that are relevant for the learning task.\nOverly complex models, on the other hand, entail a higher risk\nof overfitting. Furthermore, their reasoning is more difficult to\ninterpret (cf. next section), and they are likely to be computa-\ntionally more expensive. Computational costs are expressed\nby memory requirements and the inference time to execute a\nmodel on new data. These criteria are particularly important\nwhen assessing deep neural networks, where several million\nmodel parameters may be processed and stored, which places\nspecial demands on hardware resources. Consequently, it is\ncrucial for business settings with limited resources (such as\nenvironments that heavily rely on mobile devices) to not only\nselect a model at the sweet spot between underfitting and\noverfitting. They should also to evaluate a model’s complexity\nconcerning further trade-off relationships, such as accuracy\nvs. memory usage and speed (Heinrich et al. 2019).\nChallenges for intelligent systems based\non machine learning and deep learning\nElectronic markets are at the dawn of a technology-induced\nshift towards data-driven insights provided by intelligent sys-\ntems (Selz 2020). Already today, shallow ML and DL are\nused to build analytical models for them, and further diffusion\nis foreseeable. For any real-world application, intelligent sys-\ntems do not only face the task of model building, system\nspecification, and implementation. They are prone to several\nissues rooted in how ML and DL operate, which constitute\nchallenges relevant to the Information Systems community.\nThey do require not only technical knowledge but also involve\nhuman and business aspects that go beyond the system’s con-\nfinements to consider the circumstances and the ecosystem of\napplication.\nManaging the triangle of architecture,\nhyperparameters, and training data\nWhen building shallow ML and DL models for intelligent\nsystems, there are nearly endless options for algorithms or\narchitectures, hyperparameters, and training data (Duin\n1994; Heinrich et al. 2021). At the same time, there is a lack\nof established guidelines on how a model should be built for a\nspecific problem to ensure not only performance and cost-\nefficiency but also its robustness and privacy. Moreover, as\noutlined above, there are often several trade-off relations to be\nconsidered in business environments with limited resources,\nsuch as prediction quality vs. computational costs. Therefore,\nthe task of analytical model building is the most crucial since it\nalso determines the business success of an intelligent system.\nFor example, a model that can perform at 99.9% accuracy but\ntakes too long to put out a classification decision is rendered\nuseless and is equal to a 0%-accuracy model in the context of\ntime-critical applications such as proactive monitoring or\nquality assurance in smart factories. Further, different\nimplementations can only be accurately compared when vary-\ning only one of the three edges of the triangle at a time and\nreporting the same metrics. Ultimately, one should consider\nthe necessary skills, available tool support, and the required\nimplementation effort to develop and modify a particular DL\narchitecture (Wanner et al. 2020).\nThus, applications with excellent accuracy achieved in a\nlaboratory setting or on a different dataset may not translate\ninto business success when applied in a real-world environ-\nment in electronic markets as other factors may outweigh the\nML model’s theoretical achievements. This implies that re-\nsearchers should be aware of the situational characteristics of\na models' real-world application to develop an efficacious in-\ntelligent system. It is needless to say that researchers cannot\nknow all factors a priori, but they should familiarize them-\nselves with the fact that there are several architectural options\nwith different baseline variants, which suit different scenarios,\neach with their characteristic properties. Furthermore, multiple\nmetrics such as accuracy and F1 score should be reviewed on\nconsistent benchmarking data across models before making a\nchoice for a model.\nAwareness of bias and drift in data\nIn terms of automated analytical model building, one needs to\nbe aware of (cognitive) biases that are introduced into any\nshallow ML or DL model by using human-generated data.\nThese biases will be heavily adopted by the model (Fuchs\n2018; Howard et al. 2017). That is, the models will exhibit\nthe same (human-)induced tendencies that are present in the\ndata or even amplify them. A cognitive bias is an illogical\ninference or belief that individuals adopt due to flawed\nreporting of facts or due to flawed decision heuristics\n(Haselton et al. 2015). While data-introduced bias is not a\nparticularly new concept, it is amplified in the context of\nML and DL if training data has not been properly selected\nor pre-processed, has class imbalances, or when inferences\nare not reviewed responsibly. Striking examples include\nAmazon’s AI recruiting software that showed discrimination\nagainst women or Google’s Vision AI that produced starkly\ndifferent image labels based on skin color.\nFurther, the validity of recommendations based on data is\nprone to concept drift, which describes a scenario, where “the\nrelation between the input data and the target variable changes\nMachine learning and deep learning\nover time” (Gama et al. 2014). That is, ML models for intel-\nligent systems may not produce satisfactory results, when his-\ntorical data does not describe the present situation adequately\nanymore, for example due to new competitors entering a mar-\nket, new production capabilities becoming available, or un-\nprecedented governmental restrictions. Drift does not have to\nbe sudden but can be incremental, gradual, or reoccurring\n(Gama et al. 2014) and thus hard to detect. While techniques\nfor automated learning exist that involve using trusted data\nwindows and concept descriptions (Widmer and Kubat\n1996), automated strategies for discovering and solving\nbusiness-related problems are a challenge (Pentland et al.\n2020).\nFor applications in electronic markets, considering bias is\nof high importance as most data points will have human points\nof contact. These can be as obvious as social media posts or as\ndisguised as omitted variables. Further, poisoning attacks dur-\ning model retraining can be used to purposefully insert devi-\nating patterns. This entails that training data needs to be care-\nfully reviewed for such human prejudgments. Applications\nbased on this data should be understood as inherently biased\nrather than as impartial AI. This implies that researchers need\nto review their datasets and make public any biases they are\naware of. Again, it is unrealistic to assume that all bias effects\ncan be explicated in large datasets with high-dimensional data.\nNevertheless, to better understand and trust an ML model, it is\nimportant to detect and highlight those effects that have or\nmay have an impact on predictions. Lastly, as constant drift\ncan be assumed in any real-world electronic market, a trained\nmodel is never finished. Companies must put strategies in\nplace to identify, track, and counter concept drift that impacts\nthe quality of their intelligent system’s decisions. Currently,\nmanual checks and periodic model retraining prevail.\nUnpredictability of predictions and the need\nfor explainability\nThe complexity of DL models and some shallow ML models\nsuch as random forest and SVMs, often referred to as of black-\nbox nature, makes it nearly impossible to predict how they\nwill perform in a specific context (Adadi and Berrada 2018).\nThis also entails that users may not be able to review and\nunderstand the recommendations of intelligent systems based\non these models. Moreover, this makes it very difficult to\nprepare for adversarial attacks, which trick and break DL\nmodels (Heinrich et al. 2020). They can be a threat to high-\nstake applications, for example, in terms of perturbations of\nstreet signs for autonomous driving (Eykholt et al. 2018).\nThus, it may become necessary to explain the decision of a\nblack-box model also to ease organizational adoption. Not\nonly do humans prefer simple explanations to trust and adopt\na model, but the requirement of explainability may even be\nenforced by law (Miller 2019).\nThe field of explainable AI (XAI) deals with the augmen-\ntation of existing DL models to produce explanations for out-\nput predictions. For image data, this involves highlighting\nareas of the input image that are responsible for generating a\nspecific output decision (Adadi and Berrada 2018).\nConcerning time series data, methods have been developed\nto highlight the particular important time steps influencing a\nforecast (Assaf and Schumann 2019). A similar approach can\nbe used for highlighting words in a text that lead to specific\nclassification outputs.\nThus, applications in electronic markets with different crit-\nicality and human interaction requirements should be de-\nsigned or augmented distinctively to address the respective\nconcerns. Researchers must review the applications in partic-\nular of DL models for their criticality and accountability.\nPossibly, they must choose an explainable white-box model\nover a more accurate black-box model (Rudin 2019) or con-\nsider XAI augmentations to make the model’s predictions\nmore accessible to its users (Adadi and Berrada 2018).\nResource limitations and transfer learning\nLastly, building and training comprehensive analytical\nmodels with shallow ML or DL is costly and requires large\ndatasets to avoid a cold start. Fortunately, models do not\nalways have to be trained from scratch. The concept of\ntransfer learning allows models that are trained on general\ndatasets (e.g., large-scale image datasets) to be specialized\nfor specific tasks by using a considerably smaller dataset\nthat is problem-specific (Pouyanfar et al. 2019). However,\nusing pre-trained models from foreign sources can pose a\nrisk as the models can be subject to biases and adversarial\nattacks, as introduced above. For example, pre-trained\nmodels may not properly reflect certain environmental\nconstraints or contain backdoors by inserting classification\ntriggers, for example, to misclassify medical images\n(Wang et al. 2020). Governmental interventions to redirect\nor suppress predictions are conceivable as well. Hence, in\nhigh-stake situations, the reuse of publicly available ana-\nlytical models may not be an option. Nevertheless, transfer\nlearning offers a feasible option for small and medium-\nsized enterprises to deploy intelligent systems or enables\nlarge companies to repurpose their own general analytical\nmodels for specific applications.\nIn the context of transfer learning, new markets and\necosystems of AI as a service (AIaaS) are already emerg-\ning. Such marketplaces, for example by Microsoft or\nAmazon Web Services, offer cloud AI applications, AI\nplatforms, and AI infrastructure. In addition to cloud-\nbased benefits for deployments, they also enable transfer\nC. Janiesch et al.\nlearning from already established models to other applica-\ntions. That is, they allow customers with limited AI devel-\nopment resources to purchase pre-trained models and inte-\ngrate them into their own business environments (e.g.,\nNLP models for chatbot applications). New types of ven-\ndors can participate in such markets, for example, by of-\nfering transfer learning results for highly domain-specific\ntasks, such as predictive maintenance for complex ma-\nchines. As outlined above, consumers of servitized DL\nmodels in particular need to be aware of the risks their\nblack-box nature poses and establish similarly strict proto-\ncols as with human operators for similar decisions. As the\nmarket of AIaaS is only emerging, guidelines for respon-\nsible transfer learning have yet to be established (e.g.,\nAmorós et al. 2020).\nConclusion\nWith this fundamentals article, we provide a broad introduc-\ntion to ML and DL. Often subsumed as AI technology, both\nfuel the analytical models underlying contemporary and future\nintelligent systems. We have conceptualized ML, shallow\nML, and DL as well as their algorithms and architectures.\nFurther, we have described the general process of automated\nanalytical model building with its four aspects of data input,\nfeature extraction, model building, and model assessment.\nLastly, we contribute to the ongoing diffusion into electronics\nmarkets by discussing four fundamental challenges for intel-\nligent systems based on ML and DL in real-world ecosystems.\nHere, in particular, AIaaS constitutes a new and unexplored\nelectronic market and will heavily influence other established\nservice platforms. They will, for example, augment the smart-\nness of so-called smart services by providing new ways to learn\nfrom customer data and provide advice or instructions to them\nwithout being explicitly programmed to do so. We estimate that\nmuch of the upcoming research on electronic markets will be\nagainst the backdrop of AIaaS and their ecosystems and devise\nnew applications, roles, and business models for intelligent sys-\ntems based on DL. Related future research will need to address\nand factor in the challenges we presented by providing struc-\ntured methodological guidance to build analytical models, as-\nsess data collections and model performance, and make predic-\ntions safe and accessible to the user.\nFunding This research and development project is funded by the\nBayerische Staatsministerium für Wirtschaft, Landesentwicklung und\nEnergie (StMWi) within the framework concept “Informations- und\nKommunikationstechnik” (grant no. DIK0143/02) and managed by the\nproject management agency VDI+VDE Innovation + Technik GmbH..\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as long as\nyou give appropriate credit to the original author(s) and the source, pro-\nvide a link to the Creative Commons licence, and indicate if changes were\nmade. The images or other third party material in this article are included\nin the article's Creative Commons licence, unless indicated otherwise in a\ncredit line to the material. If material is not included in the article's\nCreative Commons licence and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain\npermission directly from the copyright holder. To view a copy of this\nlicence, visit http://creativecommons.org/licenses/by/4.0/.\n",
            "pdfUrl" : "",
            "reference" : "Adadi, A., & Berrada, M. (2018). Peeking inside the black-box: A\nsurvey on explainable artificial intelligence (XAI). IEEE Access,\n6, 52138–52160. https://doi.org/10.1109/ACCESS.2018.\n2870052.\nAhani, A., Nilashi, M., Ibrahim, O., Sanzogni, L., & Weaven, S. (2019).\nMarket segmentation and travel choice prediction in Spa hotels\nthrough TripAdvisor’s online reviews. International Journal of\nHospitality Management, 80, 52–77. https://doi.org/10.1016/j.\nijhm.2019.01.003.\nAmorós, L., Hafiz, S. M., Lee, K., & Tol, M. C. (2020). Gimme that\nmodel!: A trusted ML model trading protocol. arXiv:2003.00610\n[cs]. http://arxiv.org/abs/2003.00610\nAssaf, R., & Schumann, A. (2019). Explainable deep neural networks for\nmultivariate time series predictions. Proceedings of the 28th\nInternational Joint Conference on Artificial Intelligence, 6488–\n6490. https://doi.org/10.24963/ijcai.2019/932.\nBastan, M., Ramisa, A., & Tek, M. (2020). Cross-modal fashion product\nsearch with transformer-based Embeddings. CVPR Workshop - 3rd\nworkshop on Computer Vision for Fashion, Art and Design, Seattle:\nWashington.\nBishop, C. M. (2006). Pattern recognition and machine learning\n(Information science and statistics). Springer-Verlag New York,\nInc.\nBrynjolfsson, E., & McAfee, A. (2017). The business of artificial intelli-\ngence. Harvard Business Review, 1–20.\nChen, S. H., Jakeman, A. J., & Norton, J. P. (2008). Artificial intelligence\ntechniques: An introduction to their use for modelling environmen-\ntal systems. Mathematics and Computers in Simulation, 78(2–3),\n379–400. https://doi.org/10.1016/j.matcom.2008.01.028.\nDalal, N., & Triggs, B. (2005). Histograms of oriented gradients for\nhuman detection. 2005 IEEE Computer Society Conference on\nComputer Vision and Pattern Recognition (CVPR’05), 1, 886–\n893. https://doi.org/10.1109/CVPR.2005.177.\nDuin, R. P. W. (1994). Superlearning and neural network magic. Pattern\nRecognition Letters, 15(3), 215–217. https://doi.org/10.1016/0167-\n8655(94)90052-3.\nEykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C.,\nPrakash, A., Kohno, T., & Song, D. (2018). Robust physical-world\nattacks on deep learning visual classification. IEEE/CVF\nConference on Computer Vision and Pattern Recognition, 2018,\n1625–1634. https://doi.org/10.1109/CVPR.2018.00175.\nFischer, M., Heim, D., Hofmann, A., Janiesch, C., Klima, C., &\nWinkelmann, A. (2020). A taxonomy and archetypes of smart ser-\nvices for smart living. Electronic Markets, 30(1), 131–149. https://\ndoi.org/10.1007/s12525-019-00384-5.\nMachine learning and deep learning\nFuchs, D. J. (2018). The dangers of human-like Bias in machine-learning\nalgorithms. Missouri S&T’s Peer to Peer, 2(1), 15.\nGama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M., & Bouchachia, A.\n(2014). A survey on concept drift adaptation. ACM Computing\nSurveys, 46(4), 1–37. https://doi.org/10.1145/2523813.\nGarcía, S., & Herrera, F. (2008). An extension on “statistical comparisons\nof classifiers over multiple data sets” for all pairwise comparisons.\nJournal of Machine Learning Research, 9(89), 2677–2694.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. The\nMIT Press.\nGoyal, D., & Pabla, B. S. (2015). Condition based maintenance of\nmachine tools—A review. CIRP Journal of Manufacturing\nScience and Technology, 10, 24–35. https://doi.org/10.1016/j.\ncirpj.2015.05.004.\nGrigorescu, S., Trasnea, B., Cocias, T., & Macesanu, G. (2020). A survey\nof deep learning techniques for autonomous driving. Journal of\nField Robotics, 37(3), 362–386. https://doi.org/10.1002/rob.21918.\nHaselton, M. G., Nettle, D., & Andrews, P. W. (2015). The evolution of\ncognitive Bias. In: D. M. Buss (Ed.), The handbook of evolutionary\npsychology (pp. 724–746). Inc: John Wiley & Sons. https://doi.org/\n10.1002/9780470939376.ch25.\nHeinrich, K., Graf, J., Chen, J., Laurisch, J., & Zschech, P. (2020).\nFool me once, shame on you, fool me twice, shame on me: A\ntaxonomy of attack and defense patterns for AI security.\nProceedings of the 28th European Conference on Information\nSystems (ECIS).\nHeinrich, K., Möller, B., Janiesch, C., & Zschech, P. (2019). Is Bigger\nAlways Better? Lessons Learnt from the Evolution of Deep\nLearning Architectures for Image Classification. Proceedings of\nthe 2019 Pre-ICIS SIGDSA Symposium. https://aisel.aisnet.org/\nsigdsa2019/20\nHeinrich, K., Zschech, P., Janiesch, C., & Bonin, M. (2021). Process data\nproperties matter: Introducing gated convolutional neural networks\n(GCNN) and key-value-predict attention networks (KVP) for next\nevent prediction with deep learning. Decision Support Systems, 143,\n113494. https://doi.org/10.1016/j.dss.2021.113494.\nHoward, A., Zhang, C., & Horvitz, E. (2017). Addressing bias in machine\nlearning algorithms: A pilot study on emotion recognition for intel-\nligent systems. IEEE Workshop on Advanced Robotics and its\nSocial Impacts (ARSO), 1–7. https://doi.org/10.1109/ARSO.2017.\n8025197.\nJayanth Balaji, A., Harish Ram, D. S., & Nair, B. B. (2018). Applicability\nof deep learning models for stock Price forecasting an empirical\nstudy on BANKEX data. Procedia Computer Science, 143, 947–\n953. https://doi.org/10.1016/j.procs.2018.10.340.\nJordan, M. I., & Mitchell, T. M. (2015). Machine learning: Trends, per-\nspectives, and prospects. Science, 349(6245), 255–260. https://doi.\norg/10.1126/science.aaa8415.\nKotsiantis, S. B., Zaharakis, I. D., & Pintelas, P. E. (2006). Machine\nlearning: A review of classification and combining techniques.\nArtificial Intelligence Review, 26(3), 159–190. https://doi.org/10.\n1007/s10462-007-9052-3.\nKühl, N., Mühlthaler, M., & Goutier, M. (2020). Supporting customer-\noriented marketing with artificial intelligence: Automatically quan-\ntifying customer needs from social media. Electronic Markets,\n30(2), 351–367. https://doi.org/10.1007/s12525-019-00351-0.\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature,\n521(7553), 436–444. https://doi.org/10.1038/nature14539.\nLeijnen, S., & van Veen, F. (2020). The Neural Network Zoo.\nP r o c e e d i n g s , 4 7 ( 1 ) , 9 . h t t p s : / / d o i . o r g / 1 0 . 3 3 9 0 /\nproceedings47010009.\nLiu, Z., Lin, Y., & Sun, M. (2020). Representation learning for natural\nlanguage processing. Springer Singapore. https://doi.org/10.1007/\n978-981-15-5573-2.\nLowe, D. G. (2004). Distinctive image features from scale-invariant\nKeypoints. International Journal of Computer Vision, 60(2), 91–\n110. https://doi.org/10.1023/B:VISI.0000029664.99615.94.\nMadani, A., Arnaout, R., Mofrad, M., & Arnaout, R. (2018). Fast and\naccurate view classification of echocardiograms using deep learn-\ning. Npj Digital Medicine, 1(1). https://doi.org/10.1038/s41746-\n017-0013-1.\nMiller, T. (2019). Explanation in artificial intelligence: Insights from the\nsocial sciences. Artificial Intelligence, 267, 1–38. https://doi.org/10.\n1016/j.artint.2018.07.007.\nPan, Z., Yu, W., Yi, X., Khan, A., Yuan, F., & Zheng, Y. (2019). Recent\nProgress on generative adversarial networks (GANs): A survey.\nIEEE Access, 7, 36322–36333. https://doi.org/10.1109/ACCESS.\n2019.2905015.\nPaula, E. L., Ladeira, M., Carvalho, R. N., & Marzagão, T. (2016). Deep\nlearning anomaly detection as support fraud investigation in\nBrazilian exports and anti-money laundering. 15th IEEE\nInternational Conference on Machine Learning and Applications\n(ICMLA), 954–960. https://doi.org/10.1109/ICMLA.2016.0172.\nPentland, B. T., Liu, P., Kremser, W., & Haerem, T. (2020). The dynam-\nics of drift in digitized processes. MIS Quarterly, 44(1), 19–47.\nhttps://doi.org/10.25300/MISQ/2020/14458.\nPeters, M., Ketter, W., Saar-Tsechansky, M., & Collins, J. (2013). A\nreinforcement learning approach to autonomous decision-making\nin smart electricity markets. Machine Learning, 92(1), 5–39.\nhttps://doi.org/10.1007/s10994-013-5340-0.\nPouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M. P.,\nShyu, M.-L., Chen, S.-C., & Iyengar, S. S. (2019). A survey on\ndeep learning: Algorithms, techniques, and applications. ACM\nComputing Surveys, 51(5), 1–36. https://doi.org/10.1145/\n3234150.\nRamaswamy, S., & DeClerck, N. (2018). Customer perception analysis\nusing deep learning and NLP. Procedia Computer Science, 140,\n170–178. https://doi.org/10.1016/j.procs.2018.10.326.\nRudin, C. (2019). Stop explaining black box machine learning models for\nhigh stakes decisions and use interpretable models instead. Nature\nMachine Intelligence, 1(5), 206–215. https://doi.org/10.1038/\ns42256-019-0048-x.\nRussell, S. J., & Norvig, P. (2021). Artificial intelligence: A modern\napproach (4th ed.). Pearson.\nSalton, G., & Buckley, C. (1988). Term-weighting approaches in\nautomatic text retrieval. Information Processing &\nManagement, 24(5), 513–523. https://doi.org/10.1016/0306-\n4573(88)90021-0.\nSchmidhuber, J. (2015). Deep learning in neural networks: An overview.\nNeural Networks, 61, 85–117. https://doi.org/10.1016/j.neunet.\n2014.09.003.\nSearle, J. R. (1980). Minds, brains, and programs. Behavioral and Brain\nSciences, 3(3), 417–424. https://doi.org/10.1017/\nS0140525X00005756.\nSelz, D. (2020). From electronic markets to data driven insights.\nElectronic Markets, 30(1), 57–59. https://doi.org/10.1007/s12525-\n019-00393-4.\nShmueli, G., & Koppius, O. (2011). Predictive analytics in information\nsystems research. Management Information Systems Quarterly,\n35(3), 553–572. https://doi.org/10.2307/23042796.\nShrestha, Y. R., Krishna, V., & von Krogh, G. (2021). Augmenting\norganizational decision-making with deep learning algorithms:\nPrinciples, promises, and challenges. Journal of Business\nResearch, 123, 588–603. https://doi.org/10.1016/j.jbusres.2020.\n09.068.\nSilver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A.,\nLanctot, M., Sifre, L., Kumaran, D., Graepel, T., Lillicrap, T.,\nSimonyan, K., & Hassabis, D. (2018). A general reinforcement\nlearning algorithm that masters chess, shogi, and go through self-\nC. Janiesch et al.\nplay. Science, 362(6419), 1140–1144. https://doi.org/10.1126/\nscience.aar6404.\nSpooner, T., Fearnley, J., Savani, R., & Koukorinis, A. (2018). Market\nmaking via reinforcement learning. Proceedings of the 17th\nInternational Conference on Autonomous Agents and MultiAgent\nsystems, 434–442. arXiv:1804.04216v1\nStone, P., Brooks, R., Brynjolfsson, E., Calo, R., Etzioni, O., Hager, G.,\nHirschberg, J., Kalyanakrishnan, S., Kamar, E., Kraus, S., Leyton-\nBrown, Kevin, Parkes, D., Press, W., Saxenian, A. L., Shah, J.,\nMilind Tambe, & Teller, A. (2016). Artificial Intelligence and Life\nin 2030: the one hundred year study on artificial\nintelligence (Report of the 2015–2016 study panel). Stanford\nUniversity. https://ai100.stanford.edu/2016-report\nViola, P., & Jones, M. (2001). Rapid object detection using a boosted\ncascade of simple features. Proceedings of the 2001 IEEE Computer\nSociety Conference on Computer Vision and Pattern Recognition.\nCVPR 2001, 1, I-511–I-518. https://doi.org/10.1109/CVPR.2001.\n990517.\nWang, S., Nepal, S., Rudolph, C., Grobler, M., Chen, S., & Chen, T.\n(2020). Backdoor attacks against transfer learning with pre-trained\ndeep learning models. IEEE Transactions on Services Computing,\n1–1. https://doi.org/10.1109/TSC.2020.3000900.\nWanner, J., Heinrich, K., Janiesch, C., & Zschech, P. (2020). How much\nAI do you require? Decision factors for adopting AI technology.\nProceedings of the 41st International Conference on Information\nSystems (ICIS).\nWesterlund, M. (2019). The emergence of Deepfake technology: A re-\nview. Technology Innovation Management Review, 9(11), 39–52.\nhttps://doi.org/10.22215/timreview/1282\nWidmer, G., & Kubat, M. (1996). Learning in the presence of concept\ndrift and hidden contexts. Machine Learning, 23(1), 69–101. https://\ndoi.org/10.1007/BF00116900.\nWu, M., Liu, F., & Cohn, T. (2018). Evaluating the utility of hand-crafted\nfeatures in sequence labelling. Proceedings of the 2018 Conference\non Empirical Methods in Natural Language Processing, 2850–\n2856. https://doi.org/10.18653/v1/D18-1310.\nYoung, T., Hazarika, D., Poria, S., & Cambria, E. (2018). Recent trends\nin deep learning based natural language processing [review article].\nIEEE Computational Intelligence Magazine, 13(3), 55–75. https://\ndoi.org/10.1109/MCI.2018.2840738.\nZhang, Y., & Ling, C. (2018). A strategy to apply machine learning to\nsmall datasets in materials science. npj Computational Materials,\n4(1). https://doi.org/10.1038/s41524-018-0081-z.\nPublisher’s note Springer Nature remains neutral with regard to jurisdic-\ntional claims in published maps and institutional affiliations.\nMachine learning and deep learning\n",
            "keyWords" : "Machine learning . Deep learning . Artificial intelligence . Artificial neural networks . Analytical model building\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "20",
          "_score" : 1.0,
          "_source" : {
            "title" : "Towards a Quantum Software Modeling Language",
            "samary" : "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
            "authors" : "Carlos A. Pérez-Delgado∗\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Autónoma de San Luis Potosí\nSan Luis Potosí, SLP, México\nhectorgerardo@uaslp.mx\n",
            "institutions" : "",
            "integralText" : "1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n∗Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW’20, May 23–29, 2020, Seoul, Republic of Korea\n© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively ‘in the small.’ A general understanding of quantum\ncomputation, or, quantum programming ‘in the large’ is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers—hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration—which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module’s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\n<image: CalRGB, width: 1003, height: 1004, bpc: 8>and not appear as part of its interface. For instance, take a module\nimplementing Shor’s algorithm. Shor’s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information—and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor’s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor’s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us—especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources—which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both ‘set’ messages are quantum. Likewise, the return mes-\nsages ρ and ρ′ are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe’ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\n",
            "pdfUrl" : "",
            "reference" : "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505–510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7–11.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107–120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC ’96). ACM, New York, NY, USA, 212–219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. Pérez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124–134.\n[8] Liming Zhao, Carlos A. Pérez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
            "keyWords" : "quantum computing, software engineering, UML\n"
          }
        },
        {
          "_index" : "articleindex",
          "_id" : "24",
          "_score" : 1.0,
          "_source" : {
            "title" : "Numerical computing in engineering mathematics",
            "samary" : "The rapid advances in technology over the lastdecade have signiﬁcantly altered the nature of engineering knowl-edge and skills required in the modern industries. In response tothe changing professional requirements, engineering institutionshave updated their curriculum and pedagogical practices. How-ever, most of the changes in the curriculum have been focused onthe core engineering courses without much consideration for theauxiliary courses in mathematics and sciences. In this paper, weaim to propose a new, augmented mathematics curriculum aimedat meeting the requirements of the modern, technology-basedengineering workplace. The proposed updates require minimalresources and can be seamlessly integrated into the existingcurriculum.Index Terms—engineering mathematics; numerical computing;education; Industry 4.0",
            "authors" : "Firuz Kamalov\nDepartment of Electrical Engineering\nCanadian University Dubai\nDubai, UAE\nﬁruz@cud.ac.ae\nHo-Hon Leung\nDepartment of Mathematical Sciences\nUnited Arab Emirates University\nAl Ain, UAE\nhohon.leung@uaeu.ac.ae\n",
            "institutions" : "",
            "integralText" : "I. INTRODUCTION\nThe 4th Industrial Revolution has had a dramatic impact\non the engineering profession. The modern technologies such\nas artiﬁcial intelligence, the internet of things, and advanced\nrobotics have altered engineering systems and processes. To-\nday’s engineers are expected to be able to leverage these\nresources to produce their products. To meet the new profes-\nsional requirements, engineering educational institutions have\nrevised their curricula. The changes in the curricula include\nboth updating the existing programs as well as introduc-\ning completely new programs. Given the rapid technological\nprogress, universities and colleges around the world are con-\ntinuously adapting to the ever-changing environment. While a\nsigniﬁcant progress in modernizing the engineering curriculum\nhas been achieved, there still remains room for improvement.\nCatalyzed by the exponential increase in computational\npower and interconnectedness, the modern industrial revolu-\ntion has reshaped the skills and competencies required of the\nengineers. The changes in engineering curricula in response to\nIndustry 4.0 have been threefold: i) modernizing the existing\nprograms, ii) introduction of new programs, and iii) revising\nthe pedagogical approach. Modernizing the existing programs\ninvolves introduction of new courses in the study plan related\nto emerging technologies. In addition, existing courses can be\nupdated with new content. Fresh new programs in emerging\n© 2022 IEEE. Personal use of this material is permitted. Permission from\nIEEE must be obtained for all other uses, in any current or future media,\nincluding reprinting/republishing this material for advertising or promotional\npurposes, creating new collective works, for resale or redistribution to servers\nor lists, or reuse of any copyrighted component of this work in other works\ntechnologies are also introduced by universities and colleges.\nMany institutions now offer degrees in artiﬁcial intelligence\nand mechatronics which were not there 20 years ago. Finally,\nuniversities have revised their approaches to course delivery.\nStudent-centered learning, project-based learning, and applied\nlearning have become popular in the new engineering educa-\ntional paradigm.\nWhile signiﬁcant effort has been made to revise the core\nengineering courses, the auxiliary courses in mathematics and\nsciences received little consideration. The mathematics and\nsciences courses play a key role in the engineering curriculum.\nGiven their importance, the curriculum updates must also be\nextended to the auxiliary courses. By implementing a com-\nprehensive update of the engineering curriculum that includes\nboth the core and auxiliary courses, a more effective outcome\ncan be achieved.\nThe goal of this paper is to propose a modernized engineer-\ning mathematics curriculum in line with the broader efforts to\nupdate engineering education to adapt to Industry 4.0. The key\nfeature of the new curriculum is the introduction numerical\ncomputing in the existing mathematics courses. The latest\nindustrial revolution has been driven largely by the dramatic\nincrease in computational power. Therefore, today’s engineers\nmust be well-equipped to leverage the computing power in\ntheir work.\nSince mathematics courses are usually taken at the begin-\nning of the study plan, it offers a natural avenue for introducing\nnumerical computing to students. Furthermore, many problems\nin mathematics can be solved numerically making it natural\nto integrate numerical computing in mathematics courses.\nBy studying numerical computing in mathematics courses,\nstudents will acquire the necessary theoretical and practical\nskills to apply in their downstream, specialized engineering\ncourses.\nThis paper is structured as follows. Section 2 provides an\noverview of the existing efforts to update the engineering\ncurriculum in response to Industry 4.0. Section 3 discusses\nthe current approaches to integrate scientiﬁc computing in\nmathematics courses. In Section 4, we present our proposal\nfor modernizing the mathematics curriculum to integrate nu-\nmerical computing. Section 5 concludes the paper with ﬁnal\nremarks.\nII. ENGINEERING EDUCATION AND INDUSTRY 4.0\nEngineering departments in colleges and universities have\nmade signiﬁcant changes in their curricula in response to\nthe new environment created by the recent, rapid advances\nin technology. In particular, the existing programs have been\nupdated to include courses that target emerging technologies.\nCompletely new programs related to AI and mechatronics\nhave also been adopted by universities. Innovations in the\nﬁeld of engineering education continue to take place with new\ndevelopments on the horizon.\nThere exist several studies investigating the modern en-\ngineering curricula and evaluating their effectiveness. It is\nargued in [6] that engineering educators must prepare their\nstudents to face three key challenges: sustainability, the 4th\nIndustrial Revolution, and employability. The authors ﬁnd that\ncolleges and universities are responding to these challenges by\nemphasizing student-centered learning, integration of theory\nand practice, digital and online learning, and the deﬁnition of\nprofessional competencies. In particular, response to the needs\nof Industry 4.0 require interdisciplinary collaboration across\nseveral programs and disciplines. Interaction and integration\nof technologies plays a key role in this process [10], [12]. In-\nterdisciplinary engineering education requires sound pedagogy\nand teaming experiences to encourage student in collaborative\nand interdisciplinary practice [23].\nDigital and online learning have become an important part\nof modern education including in the ﬁeld of engineering.\nInformation technologies play a vital role in delivering digital\nlearning to students. Colleges and universities have made\nsigniﬁcant investments to improve their information and com-\nmunication technology (ICT) capacities [7].\nIn response to the needs of Industry 4.0, some univer-\nsities have adopted the framework of Education 4.0 [15],\n[19]. The new education framework consists of four main\ncomponents: i) competencies, ii) learning methods, iii) ICT,\nand iv) infrastructure. Students competencies are based on\ntechnological knowledge and skills for successful workplace\nperformance, while the learning methods are based on problem\nsolving and challenge-based learning. In particular, active and\nproject-based learning plays an important role in Education\n4.0 [4], [8]. Other innovative approaches to learning such as\nvirtual-reality based engineering education can help improve\nthe learning process related to Industry 4.0 [20].\nIn addition to technological progress, socio-cultural shifts\nmust be taken into account in revising engineering curriculum.\nThe new generation of students has its unique worldview\nwhich needs to be considered by the educators. In particular,\nthe new generation is signiﬁcantly affected by mobile devices\nand digital media. Educational content must be tailored to\nthe new student preferences to achieve effective learning\noutcomes [16]. Innovative approaches such gamiﬁcation may\nhelp improve the learning process [13], [17].\nMany universities have also introduced nontechnical updates\nto their engineering curriculum. The most signiﬁcant nontech-\nnical update has been the introduction of entrepreneurship\ncourses and experiences for students. A lot of attention has\nrecently been given to equipping students with entrepreneurial\nskills. Students learn about entrepreneurship in their courses\nas well as through university incubators.\nIII. UNIVERSITY MATHEMATICS CURRICULUM\nThe mathematics curriculum changed very little in the\ncurrent century. It remains a largely analytic domain, where so-\nlutions are mainly obtained manually. The current mathematics\ncurriculum emphasizes theory over practical approaches. For\ninstance, when ﬁnding the extreme values of a function,\nderivative-based approach is preferred over the gradient de-\ncent. There are two key reasons for why analytical approaches\nare favored over numerical methods. First, analytical solutions\nare reliable and elegant. An analytical solution is guaranteed\nto be exact. Second, mathematics courses are usually taught\nby pure mathematicians who have an inherent preference\nfor analytical solutions. Pure mathematics which is based on\ntheorem proving is not amenable to numerical methods.\nDespite the popularity of analytical approaches to problem\nsolving in mathematics, there has been a growing push to inte-\ngrate computer algebra systems as part of the learning process.\nComputer algebra systems such as Matlab and Mathematica\nare now routinely used in many mathematics courses. The\nstudy by Cretchley et al. [5] found that engineering students\nwere positive about the use of technology as a learning tool\nin mathematics courses. The increased use of technology in\nclass helped improve student focus and interest in lectures.\nStudent evaluations also indicated that they had a greater level\nof enjoyment towards the lectures due to the use of technology.\nIt is noteworthy that students chose not to rely too heavily on\ntechnology during the examinations despite the freedom to do\nso. The students found it extremely important to be competent\nwith analytical mathematical skills as opposed to purely com-\nputational skills. Some revealed that they learn the subjects\nequally well without the help of scientiﬁc packages, although\nthe perception towards the use of computer is in general highly\npositive. Almost all students responded positively to Matlab\nas an effective tool for computation and graphing. Many\nused Matlab for non-examination purposes. For example, they\nutilized it to check their handwritten mathematical steps in\nassignments and practice problems; and others used it for\nexploration beyond the standard syllabus and curriculum.\nThe inﬂuence of computer technology on students’ aca-\ndemic performance and learning experience has been inves-\ntigated by several authors. Abdul Majid et al. [1], [2] used\nMatlab as an aid to teach calculus to engineering students.\nThe software package was used for various course learning\noutcomes such as graphical display of mathematical functions,\nexploration, identifying and predicting structural patterns in\nevaluating a series of complex indeﬁnite integrals, and numeri-\ncal approximations in applied mathematics. The study showed\na positive impact on students’ academic performance in the\nﬁnal examinations. The study concluded that the integration\nof scientiﬁc packages into engineering mathematics courses\ncould be effective under certain conditions. Similarly, other\nstudies [18], [21] also found a positive impact from the use\nof scientiﬁc software packages on students’ motivation in\nlearning mathematics.\nIn a separate study by Brake [3], the authors investigated the\nuse of Matlab in engineering mathematics courses to increase\nstudent conﬁdence level and mathematical abilities. Matlab\nwas used to solve concrete engineering problems which require\na deep understanding of underlying mathematical principles.\nThe study found generally positive student response to the\nuse of software in their mathematics courses. However, the\nresults of the study must be considered carefully given the\nsmall sample size of the subjects.\nAlthough the majority of the studies were based on the\nuse of Matlab, several other studies considered alternative\nmathematics software packages. The study by Kilicman et al.\n[11] focused on the use of Maple to help students understand\nboth the theoretical and computational aspects of linear algebra\nfor engineering students. In particular, it was shown that the\nuse of Maple facilitates the understanding of computational as-\npects of eigenvalues and eigenvectors. It allows students more\ntime to focus on the theoretical aspects and the underlying\nmathematical principles.\nIn a recent study by Mezhennaya and Pugachev [14], the\nauthors compared engineering students’ perceptions regarding\nseveral mathematical software: Matlab, Mathematica and Ex-\ncel. The study found that all the scientiﬁc packages considered\ncan be used in education, under the condition that the policies\nfor software usage are carefully implemented. The study\nfound that many students lack hands-on experience on how\nto use the software. The students particularly struggled with\nMatlab and Mathematica ﬁnding them non user friendly. The\nstudy concluded that additional classes are required to prepare\nstudents to use software in their courses.\nIV. NUMERICAL COMPUTING IN MATHEMATICS\nCURRICULUM\nMathematics lies at the foundation of science and engineer-\ning. The importance of mathematics courses in engineering\neducation cannot be underestimated. These courses equip stu-\ndents with the fundamental skills and knowledge to study the\nmore specialized engineering courses. Thus, student success in\nengineering studies depends directly on the mathematics and\nsciences courses. Given the signiﬁcance of the mathematics\ncourses in the engineering curriculum, it is paramount to\nensure their currency with respect to the Industry 4.0.\nThe technological advances over the last decade have\ncreated demand for more computationally proﬁcient experts.\nTo meet this demand, numerical computing must become a\ncore part of engineering studies. Mathematics courses offer\na natural and convenient avenue for introducing numerical\ncomputing to engineering students. There are two main fac-\ntors that make mathematics courses particularly amenable\nto numerical computing. First, in many cases mathematical\nproblems have numerical solutions. For instance, ﬁnding the\nroot of a polynomial or the minimum value of a function\ncan be done numerically. Therefore, it is both logical and\nappropriate to apply numerical computing to mathematical\nproblems. Second, mathematics courses are usually taken\nat the beginning of the study plan. Thus, students become\nacquainted with numerical computing at an early stage. The\ncomputing and programming skills acquired in this manner\nwill have a positive effect in the more advanced, downstream\nengineering courses.\nThe key idea for the proposed curriculum update is the\naddition of computing tutorials (labs) to mathematics courses.\nIn particular, we propose adding weekly computing tutorials\n(labs) related to the main lecture material. For instance, in the\nweek in which students cover ﬁnding the extreme values of a\nfunction, there will be a computing tutorial where students\nlearn and implement the gradient descent algorithm. The\nsuggested length of each tutorial is 1 hour. It is enough\ntime to implement most of the numerical algorithms at the\nundergraduate level. At the same time, 1 extra hour per week\nwill not overburden the students.\nThe exact details of numerical computing content is left\nfor individual universities and instructors. Depending on the\nsyllabus and course learning outcomes, the numerical com-\nputing labs will be different for each university and instructor.\nNevertheless, the general ideas will be broadly similar across\ndifferent curricula. To illustrate the proposed numerical com-\nputing content, we will focus on the three main concept in\ncalculus: limits, derivatives, and integrals.\nA. Limits\nLimit is a fundamental concept in calculus. Students are\nusually taught to calculate limits using analytical approaches.\nAlthough analytical approaches work well, there is no single\nuniversal rule for calculating limits. On the other hand, in most\ncases, limits can be calculated numerically using essentially\nthe same approach. To illustrate, suppose we want to calculate\nlimx→a+ f(x). Then we can loop for k = 0 to n and calculate\nf(a+10−k). As k increases, a+10−k approaches a, so f(a+\n10−k) will, in most cases, approach the limit value. We can\ndeduce the limit by observing the values of f(a + 10−k) or\ndetermine that the limit does not exist if there is no pattern of\nconvergence. The value of n can be chosen manually or using\na stopping criterion. For instance, the algorithm may continue\nto iterate until the difference between consecutive values of\nf(a + 10−k) is below a certain threshold. The value of the\nlimit can also be deduced automatically based on the values\nof f(a + 10−k) using various heuristics.\nAnother common limit problem is limx→∞ f(x). In this\ncase, we can loop for k = 0 to n and calculate f(10k). As k\nincreases, 10k approaches ∞, so f(10k) will, in most cases,\napproach the limit value. Then the limit can be determined\nbased on the values of f(10k). Various extensions and cus-\ntomizations of this basic approach can be made. For instance,\nto avoid issues with periodic functions f(10k + ǫk), where ǫk\nare randomly generated, can be used. Other values than 10k\ncan also be used as long as the sequence approaches inﬁnity.\nA degree of automization can be introduced using different\nheuristics.\nB. Derivative\nDerivative is arguably the most important concept in cal-\nculus. There exist several rules such as the power rule, the\nproduct rule, the chain rule, and others to ﬁnd the derivative\nof a function by hand. However, manual differentiation may\nbe cumbersome when dealing with complex function. On the\nother hand, calculating the derivative at a point numerically is\nrelatively straightforward. To illustrate, suppose that we want\nto calculate f ′(a). Recall that\nf ′(a) = lim\nx→a\nf(a + h) − f(a)\n<image: None, width: 1, height: 1, bpc: 1>h\n.\n(1)\nTherefore, to calculate f ′(a) numerically we use the same\napproach as with the limits. In particular, we can loop for k =\n0 to n and calculate f(a+10−k)−f(a)\n<image: None, width: 1, height: 1, bpc: 1>10−k\n. Then the limit, and by\nextension the derivative, can be deduced (approximated) based\non the calculated values. The accuracy of the approximation\ndepends in large part on the value of n.\nOne of the most important applications of the derivative is\nﬁnding the extreme values of a function. Traditionally, this is\ndone by ﬁrst ﬁnding the critical points of the function and\nthen applying the second derivative test. However, ﬁnding the\ncritical points is not always possible, so numerical approaches\ncan be used in such cases. The most popular numerical\napproach for ﬁnding the extreme values is based on the\ngradient descent (ascent) algorithm. In gradient descent, the\noptimal value of x is iteratively updated based on the gradient.\nIn particular, for k = 0 to n, the updated optimal value of x\nis given by\nxk+1 = xk − α∇f(xk),\n(2)\nwhere ∇f(x) is the gradient and α is the step size. In the\ncase of a single-variable function, the gradient equals simply\nto the derivative ∇f(x) = f ′(x). The step size α can be\neither ﬁxed or dynamic. While a large value of α accelerates\nthe convergence at the beginning, it may hurt the convergence\nin the region near the optimal value.\nThere exist several extensions of the basic gradient descent\nalgorithm. One such extension is gradient descent with mo-\nmentum which uses the second derivative to anticipate the\nlocation of the next optimal point and thus accelerates the\nconvergence.\nC. Integrals\nIntegration is an important concept in engineering mathe-\nmatics. Although there exist a number of rules for ﬁnding the\nintegral, it is signiﬁcantly more challenging than differentia-\ntion. Moreover, in many cases, the indeﬁnite integral does not\neven exist. Therefore, numerical approaches are particularly\nuseful for integration.\nTo illustrate the application of numerical integration, sup-\npose that we want to calculate\n� b\na f(x) dx. There exist several\nnumerical methods for calculating the integral. One simple\nmethod is based on the Riemann sums. The interval [a, b] is\ndivided into n equal subintervals with endpoints x0, x1, ..., xn.\nLet δ = xk+1 −xk be the length of each subinterval. Then the\nright Riemann sum is deﬁned as δ �n\nk=1 f(xk). The Riemann\nsum provides an approximation of the integral. Indeed,\n� b\na\nf(x) dx = lim\nn→∞ δ\nn\n�\nk=1\nf(xk).\n(3)\nThe Riemann sums can be quickly calculated on a computer\nproviding a simple, yet effective approach to calculating\nintegrals numerically. Other popular integral approximation\nmethods include the trapezoid rule and the Simpson’s rule.\nD. Additional considerations\nThe above discussion about numerical methods for cal-\nculating limits, derivatives, and integrals is easily extended\nto multivariate calculus. For instance, to ﬁnd the partial\nderivative fx(a, b), we can loop for k = 0 to n and calculate\nf(a+10−k,b)−f(a,b)\n<image: None, width: 1, height: 1, bpc: 1>10−k\n. Many problems related to sequences and\nseries can similarly be solved using numerical techniques. In\nparticular, the convergence of a series can be deduced from its\npartial sums. By calculating the partial sums on the computer\nand observing the results, we can intuit the nature of the series.\nVectorization is an important aspect of numerical com-\nputing. Since the modern computer chips are optimized for\nmatrix multiplication, it is more efﬁcient to employ vector\noperations. In particular, some algorithms based on for-loops\ncan be converted into vector operations resulting in higher\nefﬁciency and speed. For instance, the Riemann sum can be\ncalculated with a single vector operation:\nδ\nn\n�\nk=1\nf(xk) = δS\n�\nf(x)\n�\n,\n(4)\nwhere x = [x1, ..., xn] is the vector of endpoints, f(x) is\na vectorized function operation, and S is the vector func-\ntion which returns the sum of all the coordinates. Similarly,\nlimit calculations can be vectorized and made more efﬁcient.\nVectorization is also useful in multi-variate calculus, where\noperations can be performed on a vector of variables.\nThe choice of the programming language for numerical\ncomputing requires careful consideration. There are several\nsuitable candidates for this purpose including Python, Java,\nC++, Matlab, and others. Based on our experience with\ndifferent programming languages, we recommend the use of\nPython. Python is currently the most popular programming\nlanguage on the planet. It has a simple and intuitive syntax\nmaking it easy to learn and apply. Python has libraries to\nﬁt any purpose including an extensive collection of libraries\nrelated to numerical computing. The basic Python libraries\nrelated to computing are NumPy, SciPy, and SymPy. More\nadvanced packages such as OR-Tools are also available for\noptimization tasks. Since Python is a universal programming\nlanguage, it can be used for almost any task. Thus, students\nwho learn Python in their mathematics courses can employ\nit in their other courses. In addition, numerical computing\nimplemented in Python can be connected to other applications.\nV. CONCLUSION\nAlthough the classical approach to teaching mathematics\nis still relevant for certain student cohorts, it is outdated for\nengineering students. Modern engineering is increasingly re-\nliant on computing [9], [22]. Therefore, universities must equip\nthe student with appropriate computing skills. In particular,\nmathematics courses must be revised to include numerical\ncomputing content.\nGiven the efﬁciency of computer-based calculations, numer-\nical computing provides a convenient approach to problem\nsolving in engineering mathematics. It can be integrated into\nthe existing curriculum with little hassle and cost. In this paper,\nwe proposed a framework for integrating numerical computing\ninto the existing mathematics curriculum. We demonstrated\nhow numerical approaches can be used some of the most\ncommon problems encountered in calculus. The proposed\nframework can be customized by individual universities to ﬁt\ntheir special needs.\n",
            "pdfUrl" : "",
            "reference" : "[1] Abdul Majid, M., Huneiti, Z., Balachandran, W., & Al-Naafa, M. A.\n(2012) A study of the effects of using MATLAB as a pedagogical tool\nfor engineering mathematics students. 15th International Conference on\nInteractive Collaborative Learning (ICL), 10.1109/ICL.2012.6402183,\nVillach, Austria.\n[2] Abdul Majid, M., Huneiti, Z. A., Balachandran, W., & Balarabe, Y.\n(2013) MATLAB as a teaching and learning tool for Mathematics: A\nliterature review. International Journal of Arts and Sciences, 6(3), 23-44.\n[3] Brake, M. L. (2007) MATLAB as a Tool to Increase the Math Self-\nConﬁdence and the Math Ability of First-Year Engineering Technology\nStudents. The Scholarship of Teaching and Learning at EMU: Vol. 1,\nArticle 5.\n[4] Chen, J., Kolmos, A., & Du, X. (2021). Forms of implementation and\nchallenges of PBL in engineering education: a review of literature.\nEuropean Journal of Engineering Education, 46(1), 90-115.\n[5] Cretchley, P., Harman, C., Ellerton, N., & Fogarty, G. (2000) MATLAB\nin Early Undergraduate Mathematics: An investigation into the Effects\nof Scientiﬁc Software on Learning. Mathematics Education Research\nJournal, 12(3), 219-233.\n[6] Hadgraft, R. G., & Kolmos, A. (2020). Emerging learning environments\nin engineering education. Australasian Journal of Engineering Educa-\ntion, 25(1), 3-16.\n[7] Hernandez-de-Menendez, M., & Morales-Menendez, R. (2019). Tech-\nnological innovations and practices in engineering education: a review.\nInternational Journal on Interactive Design and Manufacturing (IJIDeM),\n13(2), 713-728.\n[8] Hern´andez-de-Men´endez, M., Guevara, A. V., Mart´ınez, J. C. T.,\nAlc´antara, D. H., & Morales-Menendez, R. (2019). Active learning in\nengineering education. A review of fundamentals, best practices and ex-\nperiences. International Journal on Interactive Design and Manufacturing\n(IJIDeM), 13(3), 909-922.\n[9] Kamalov, F., Moussa, S., Zgheib, R., & Mashaal, O. (2020, December).\nFeature selection for intrusion detection systems. In 2020 13th Interna-\ntional Symposium on Computational Intelligence and Design (ISCID)\n(pp. 265-269). IEEE.\n[10] Kamalov, F., Sulieman, H., & Santandreu Calonge, D. (2021). Machine\nlearning based approach to exam cheating detection. Plos one, 16(8),\ne0254340.\n[11] Kilicman, A., Hassan, M. A., & Said Husain, S. K. (2010) Teaching and\nLearning using Mathematics Software ’The New Challenge’. Procedia\nSocial and Behavioral Sciences, 8, 613-619.\n[12] Lorenz, M., R¨ußmann, M., Strack, R., Lueth, K. L., & Bolle, M. (2015).\nMan and machine in industry 4.0: How will technology transform the\nindustrial workforce through 2025. The Boston Consulting Group, 2.\n[13] Maur´ıcio, R. D. A., Veado, L., Moreira, R. T., Figueiredo, E., & Costa,\nH. (2018). A systematic mapping study on game-related methods for\nsoftware engineering education. Information and software technology,\n95, 201-218.\n[14] Mezhennaya, N. M. & Pugachev, O. V. (2019) On perception of\ncomputer algebra systems and microsoft excel by engineering students.\nProblems on Education in the 21st Century, 77(3), 379-395.\n[15] Miranda, J., Navarrete, C., Noguez, J., Molina-Espinosa, J. M., Ram´ırez-\nMontoya, M. S., Navarro-Tuch, S. A., ... & Molina, A. (2021). The core\ncomponents of education 4.0 in higher education: Three case studies in\nengineering education. Computers & Electrical Engineering, 93, 107278.\n[16] Moore, K., & Frazier, R. S. (2017). Engineering education for generation\nZ. American Journal of Engineering Education (AJEE), 8(2), 111-126.\n[17] Ortiz-Rojas, M., Chiluiza, K., & Valcke, M. (2019). Gamiﬁcation\nthrough leaderboards: An empirical study in engineering education.\nComputer Applications in Engineering Education, 27(4), 777-788.\n[18] Puhak, R. I. (2011). Teaching applied Calculus utilizing MATLAB,\nProceedings of the Twenty-Third Annual International Conference on\nTechnology in Collegiate Mathematics, ISBN 0-321-68984-4, Copyright\n(C) 2012 by Pearson Education, Inc.\n[19] Ramirez-Mendoza, R. A., Morales-Menendez, R., Iqbal, H., & Parra-\nSaldivar, R. (2018, April). Engineering Education 4.0:—proposal for a\nnew Curricula. In 2018 IEEE Global Engineering Education Conference\n(EDUCON) (pp. 1273-1282). IEEE.\n[20] Salah, B., Abidi, M. H., Mian, S. H., Krid, M., Alkhalefah, H., &\nAbdo, A. (2019). Virtual reality-based engineering education to enhance\nmanufacturing sustainability in industry 4.0. Sustainability, 11(5), 1477.\n[21] Strayhorn, T. L. (2006). College in the information age: Gains associated\nwith students’ use of technology. Journal of Interactive Online Learning,\n5(2), 143-155.\n[22] Thabtah, F., Kamalov, F., & Rajab, K. (2018). A new computational\nintelligence approach to detect autistic features for autism screening.\nInternational journal of medical informatics, 117, 112-124.\n[23] Van den Beemt, A., MacLeod, M., Van der Veen, J., Van de Ven,\nA., van Baalen, S., Klaassen, R., & Boon, M. (2020). Interdisciplinary\nengineering education: A review of vision, teaching, and support. Journal\nof engineering education, 109(3), 508-555.\n",
            "keyWords" : "engineering mathematics; numerical computing;\neducation; Industry 4.0\n"
          }
        }
      ]
    }
  }